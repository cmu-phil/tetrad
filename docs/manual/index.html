<!DOCTYPE html>
<html>
<head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="ie=edge">
    <title>Tetrad Single HTML Manual</title>
    <meta name="description" content="">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <link rel="stylesheet" href="css/normalize.css">
    <link rel="stylesheet" href="css/tetrad.css">
</head>
<body>
<!--[if lte IE 9]>
<p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade
    your browser</a> to improve your experience and security.</p>
<![endif]-->

<div class="inner">

    <div class="header">
        <h1>Tetrad Manual</h1>
        <p>Last updated: March 27th, 2019</p>
    </div>

    <!-- Table of Contents, give each section a unique id -->
    <div class="toc_container">

        <b>Table of Contents</b>
        <ul class="ul">
            <li><a href="#graph_box">Graph Box</a></li>
            <li><a href="#compare_box">Compare Box</a></li>
            <li><a href="#parametric_model_box">Parametric Model Box</a></li>
            <li><a href="#instantiated_model_box">Instantiated Model Box</a></li>
            <li><a href="#data_box">Data Box</a></li>
            <li><a href="#estimator_box">Estimator Box</a></li>
            <li><a href="#updater_box">Updater Box</a></li>
            <!--
<li><a href="#classify_box">Classify Box</a></li>
-->
            <li><a href="#knowledge_box">Knowledge Box</a></li>
            <li><a href="#simulation_box">Simulation Box</a></li>
            <li><a href="#search_box">Search Box</a></li>
            <li><a href="#regression_box">Regression Box</a></li>
            <li><a href="#appendix">Appendix</a></li>
        </ul>

    </div>

    <!-- Assign id with the section name, this will be linked in the table of contents -->
    <h1 id="graph_box"><span class="section_heading">Graph Box</span></h1>

    <p>The graph box can be used to create a new graph, or to copy or edit a graph from another box.</p>

    <!-- Follow this example to create a list of items -->
    <h2>Possible Parent Boxes of the Graph Box</h2>

    <!-- Assign a class="ul" for pretty look -->
    <ul class="ul">
        <li>Another graph box</li>
        <li>A parametric model box</li>
        <li>An instantiated model box</li>
        <li>An estimator box</li>
        <li>A data box</li>
        <li>A simulation box</li>
        <li>A search box</li>
        <li>An updater box</li>
        <li>A regression box</li>
    </ul>

    <!-- Follow this example to create a list of items -->
    <h2>Possible Child Boxes of the Graph Box</h2>

    <!-- Assign a class="ul" for pretty look -->
    <ul class="ul">
        <li>Another graph box</li>
        <li>A compare box</li>
        <li>A parametric model box</li>
        <li>A data box</li>
        <li>A simulation box</li>
        <li>A search box</li>
        <li>A knowledge box</li>
    </ul>

    <h2>Creating a New Graph</h2>

    <p>When you first open a graph box with no parent, you will be presented with several options for which kind of
        graph you would like to create: a directed acyclic graph (DAG), a structural equation model (SEM)graph, a
        general graph, or a time lag graph. Once you have selected the type of graph you want to create, an empty graph
        box will open.</p>

    <p>You can add variables to your graph by clicking on the variable button on the left, then clicking inside the
        graph area. Add edges by clicking on an edge type, then clicking and dragging from one variable to another.
        Variables may be measured (represented by rectangular icons) or latents (represented by elliptical icons). Edges
        may be directed, undirected, bidirected, or uncertain (represented by circles at the ends of an edge). Depending
        on the type of graph you choose to create, your choice of edges may be limited.</p>

    <p><i>DAGs</i> allow only directed, bidirected, and uncertain edges. If an edge would create a cycle (or potential
        cycle, in the case of uncertain edges) it will not be accepted. A graph box containing a DAG can be used as
        input for any parametric model box, and is the only kind of graph box that can be used as input for a Bayes
        parametric model.</p>

    <p><i>SEM graphs</i> allow only directed and bidirected edges. A graph box containing a SEM graph can be used as
        input to a SEM parametric model or generalized SEM parametric model, where a bidirected edge between two
        variables X and Y will be interpreted as X and Y having correlated error terms.</p>


    <p><i>Time lag graphs</i> allow only directed edges. New variables that you add will be initialized with a single
        lag. (The number of lags in the graph may be changed under “Edit—Configuration…”) Edges from later lags to
        earlier lags will not be accepted. Edges added within one lag will automatically be replicated in later lags.
    </p>

    <p>The general <i>graph</i> option allows all edge types and configurations.</p>


    <h2>Creating a Random Graph </h2>

    <p>Instead of manually creating a new graph, you can randomly create one. To do so, open up a new empty graph box
        and click on “Graph—Random Graph.” This will open up a dialog box from which you can choose the type of random
        graph you would like to create by clicking through the tabs at the top of the window. Tetrad will randomly
        generate a DAG, a multiple indicator model (MIM) graph, or a scale-free graph. Each type of graph is associated
        with a number of parameters (including but not limited to the number of nodes and the maximum degree) which you
        can set.</p>

    <p>Once a graph has been randomly generated, you can directly edit it within the same graph box by adding or
        removing any variables or edges that that type of graph box allows. So, for instance, although you cannot
        randomly generate a graph with bidirected edges, you can manually add bidirected edges to a randomly generated
        DAG in a SEM graph box.</p>

    <p>Random graph generation is not available for time lag graphs. </p>


    <h2>Loading a Saved Graph</h2>

    <p>If you have previously saved a graph from Tetrad, you can load it into a new graph box by clicking “File—Load…,”
        and then clicking on the file type of the saved graph. Tetrad can load graphs from XML, from text, and from JSON
        files.</p>

    <p>To save a graph to file, click “File—Save…,” then click on the file type you would like to save your graph as.
        Tetrad can save graphs to XML, text, JSON, R and dot files. (If you save your graph to R or dot, you will not be
        able to load that file back into Tetrad.)</p>

    <p>You can also save an image of your graph by clicking “File—Save Graph Image…” Tetrad cannot load graphs from
        saved image files.</p>


    <h2>Copying a Graph</h2>

    <p>There are two ways to copy a graph. </p>

    <p>The first method allows you to copy a graph from any box which contains one. First, create a new graph box in the
        workspace, and draw an arrow from the box whose graph you want to copy to the new graph box. When opened, the
        new graph box will automatically contain a direct copy of the graph its parent box contains. </p>

    <p>The second method allows you to copy a graph directly from most types of graph box.
        First, highlight the graph in the old graph box and click “Edit—Copy Selected Graph.”
        Then open up your new graph box and click “Edit—Paste Selected Graph.”
        (Some types of graph box do not have this functionality; see “Manipulating a Graph.”)</p>


    <h2>Manipulating a Graph</h2>

    <p>If you create a graph box as a child of another box, you can also choose to perform a graph manipulation on the
        parent graph. Your graph box will then contain the manipulated version of the parent graph.</p>

    <p>The available graph manipulations are:</p>

    <h3>Display Subgraphs</h3>

    <p>This option allows you to isolate a subgraph from the parent graph. Add variables to the subgraph by highlighting
        the variable name in the “Unselected” pane and clicking on the right arrow. The hiighlighted variable will then
        show up in the “Selected” pane. (You may also define which variables go in the “Selected” pane by clicking on
        the “Text Input…” button and typing the variable names directly into the window.) Choose the type of subgraph
        you want to display from the drop-down panel below. Then click “Graph It!” and the resulting subgraph of the
        selected variables will appear in the pane on the right. (Some types of subgraph, such as “Markov Blanket,” will
        include unselected variables if they are part of the subgraph as defined on the selected variables. So, for
        instance, an unselected variable that is in the Markov blanket of a selected variable will appear in the Markov
        Blanket subgraph. Edges between unselected variables will not be shown.) For large or very dense graphs, it may
        take a long time to isolate and display subgraphs.</p>

    <p>The types of subgraphs that can be displayed are:</p>

    <ul class="ul">
        <li>Subgraph (displays the selected nodes and all edges between them)</li>
        <li>Adjacents (displays the selected nodes and all edges between them, as well as nodes adjacent to the selected
            nodes)
        </li>
        <li>Adjacents of adjacents (displays the selected nodes and all edges between them, as well as nodes adjacent to
            the selected nodes and nodes adjacent to adjacencies of the selected nodes)
        </li>
        <li>Adjacents of adjacents of adjacents (displays the selected nodes and all edges between them, as well as
            nodes adjacent to the selected nodes, nodes adjacent to adjacencies of the selected nodes, and nodes
            adjacent to adjacencies of adjacencies of the selected nodes)
        </li>
        <li>Markov Blankets (displays the selected nodes and all edges between them, as well as the Markov blankets of
            each selected node)
        </li>
        <li>Treks (displays the selected nodes, with an edge between each pair if and only if a trek exists between them
            in the full graph)
        </li>
        <li>Trek Edges (displays the selected nodes, and any treks between them, including nodes not in the selected set
            if they are part of a trek)
        </li>
        <li>Paths (displays the selected nodes, with an edge between each pair if and only if a path exists between them
            in the full graph)
        </li>
        <li>Path Edges (displays the selected nodes, and any paths between them, including nodes not in the selected set
            if they are part of a path)
        </li>
        <li>Directed Paths (displays the selected nodes, with a directed edge between each pair if and only if a
            directed path exists between them in the full graph)
        </li>
        <li>Directed Path Edges (displays the selected nodes, and any directed paths between them, including nodes not
            in the selected set if they are part of a path)
        </li>
        <li>Y Structures (displays any Y structures involving at least two of the selected nodes)</li>
        <li>Indegree (displays the selected nodes and their parents)</li>
        <li>Outdegree (displays the selected nodes and their children)</li>
        <li>Degree (displays the selected nodes and their parents and children)</li>
    </ul>

    <p>The “Graph Properties” and “Paths” functions are available in this type of graph box, but they will display
        information about the full graph, not the currently displayed subgraph.
        To see graph properties for the subgraph, first copy it into a new graph box.</p>

    <h3>Choose DAG in Pattern</h3>

    <p>If given a pattern as input, this chooses a random DAG from the Markov equivalence class of the pattern to
        display. The resulting DAG functions as a normal graph box.</p>

    <h3>Choose MAG in PAG</h3>

    <p>If given a partial ancestral graph (PAG) as input, this chooses a random mixed ancestral graph (MAG) from the
        equivalence class of the PAG to display. The resulting MAG functions as a normal graph box.</p>

    <h3>Show DAGs in Pattern</h3>

    <p>If given a pattern as input, this displays all DAGs in the pattern’s Markov equivalence class. Each DAG is
        displayed in its own tab. Most graph box functionality is not available in this type of graph box, but the DAG
        currently on display can be copied by clicking “Copy Selected Graph.”</p>

    <h3>Generate Pattern from DAG</h3>

    <p>If given a DAG as input, this displays the pattern of the Markov equivalence class to which the parent graph
        belongs. The resulting pattern functions as a normal graph box.</p>

    <h3>Generate PAG from DAG</h3>

    <p>Converts an input graph from partial ancestral to directed acyclic format. The resulting DAG functions as a
        normal graph box.</p>

    <h3>Generate PAG from tsDAG</h3>

    <p>Converts an input graph from partial ancestral to time series DAG format. The resulting DAG functions as a normal
        graph box.</p>

    <h3>Make Bidirected Edges Undirected</h3>

    <p>Replaces all bidirected edges in the input graph with undirected edges.</p>

    <h3>Make Undirected Edges Bidirected</h3>

    <p>Replaces all undirected edges in the input graph with bidirected edges.</p>

    <h3>Make All Edges Undirected</h3>

    <p>Replaces all edges in the input graph with undirected edges.</p>

    <h3>Generate Complete Graph</h3>

    <h3>Extract Structure Model</h3>


    <h2>Other Graph Box Functions</h2>

    <h3>Layout</h3>

    <p>You can change the layout of your graph by clicking on the “Layout” tab and choosing between several common
        layouts. You can also rearrange the layout of one graph box to match the layout of another graph box (so long as
        the two graphs have identical variables) by clicking “Layout—Copy Layout” and “Layout—Paste Layout.” You do not
        need to a highlight the graph in order to copy the layout.</p>

    <h3>Graph Properties</h3>

    <p>Clicking on “Graph—Graph Properties” will give you a text box containing the following properties of your
        graph:</p>

    <ul class="ul">
        <li>Number of nodes</li>
        <li>Number of latent nodes</li>
        <li>Number of edges</li>
        <li>Number of directed edges</li>
        <li>Number of bidirected edges</li>
        <li>Number of undirected edges</li>
        <li>Max degree</li>
        <li>Max indegree</li>
        <li>Max outdegree</li>
        <li>Cyclicity</li>
    </ul>

    <h3>Paths</h3>

    <p>Clicking on “Graph—Paths” opens a dialog box that allows you to see all the paths between any two variables.
        You can specify whether you want to see only adjacencies, only directed paths, only semidirected paths,
        or all treks between the two variables of interest, and the maximum length of the paths you are interested in
        using drop boxes at the top of the pane.
        To apply those settings, click “update.”</p>

    <h3>Meek Orientation</h3>

    <p>Clicking “Meek Orientation” will orient a pattern according to the Meek orientation rules.</p>

    <h3>Correlation</h3>

    <p>You can automatically correlate or uncorrelated exogenous variables under the Graph tab.</p>

    <h3>Highlighting</h3>

    <p>You can highlight bidirected edges, undirected edges, and latent nodes under the Graph tab.</p>

    <h1 id="compare_box"><span class="section_heading">Compare Box</span></h1>

    <p>The compare box compares two or more graphs.</p>

    <h2>Possible Parent Boxes of the Compare box:</h2>

    <ul class="ul">
        <li>A graph box</li>
        <li>An instantiated model box</li>
        <li>An estimator box</li>
        <li>A simulation box</li>
        <li>A search box</li>
        <li>A regression box</li>
    </ul>

    <h2>Possible Child Boxes of the Compare box:</h2>

    <ul class="ul">
        <li>None</li>
    </ul>

    <h2>Edgewise Comparisons</h2>

    <p>An edgewise comparison compares two graphs, and gives a textual list of the edges which must be added to or taken
        away from one to make it identical to the other.</p>

    <p>Take, for example, the following two graphs. The first is the reference graph, the second is the graph to be
        compared to it. </p>

    <!-- Follow this image example to add an image -->
    <img src="images/compare_box_1.png" alt="" width="360">

    <img src="images/compare_box_2.png" alt="" width="360">

    <p>When these two graphs are input into the graph compare box, a window appears which allows you to specify which of
        the two graphs is the reference graph. When the comparison is complete, the following window results</p>

    <img src="images/compare_box_3.png" alt="" width="450">


    <p>When the listed changes have been made to the second graph, it will be identical to the first graph.</p>

    <p>If one of the parent boxes contains multiple graphs, each graph will be compared separately to the reference
        graph (or the estimated graph will be compared separately to each reference graph, depending on which parent box
        is selected as the reference), and each comparison will be housed in its own tab, located on the left side of
        the window.</p>

    <h2>Tabular Graph Comparisons</h2>

    <p>A tabular graph comparison tallies up and presents counts of the differences and similarities between a true
        graph and a reference graph. Consider the example used in the above section; once again, we’ll let graph one be
        the true graph. Just as above, when the graphs are input to the tabular graph compare box, we must specify which
        of the graphs is the reference graph, and whether it contains latent variables. When the comparison is complete,
        the following window results:</p>

    <img src="images/compare_box_4.png" alt="" width="650">


    <p>The first column lists the number of adjacencies in the reference graph that are also in the true graph. The
        second column lists the number of adjacencies in the reference graph which are not in the compared graph. The
        third column lists the number of adjacencies in the comparison graph which are not in the reference graph. The
        next three columns list analogous information for arrowpoints (orientations of edges).</p>

    <p>If one of the parent boxes contains multiple graphs, each graph will be compared separately to the reference
        graph (or the estimated graph will be compared separately to each reference graph, depending on which parent box
        is selected as the reference), and the results listed in a separate row of the table.</p>

    <h2>Misclassifications</h2>

    <p>A misclassification procedure organizes a graph comparison by edge type. The edge types (undirected, directed,
        uncertain, partially uncertain, bidirected, and null) are listed as the rows and columns of a matrix, with the
        reference graph edges as the row headers and the estimate graph edges as the column headers. If, for example,
        there are three pairs of variables that are connected by undirected edges in the reference graph, but are
        connected by directed edges in the estimated graph, then there will be a 3 in the (undirected, directed) cell of
        the matrix. An analogous method is used to represent endpoint errors. For example:</p>

    <img src="images/compare_box_5.png" alt="" width="650">

    <p>If one of the parent boxes contains multiple graphs, then each estimated graph will be individually compared to
        the reference graph (or vice versa), and the results housed in their own tab, found on the left.</p>

    <h2>Graph Intersections</h2>

    <p>A graph intersection compares two or more graphs in the same comparison. It does so by ranking adjacencies (edges
        without regard to direction) and orientations based on how many of the graphs they appear in. In an n-graph
        comparison, it first lists any adjacencies found in all n graphs. Then it lists all adjacencies found in n – 1
        graphs, then adjacencies found in n – 2 graphs, and so on. </p>

    <p>After it has listed all adjacencies, it lists any orientations that are not contradicted among the graphs, again
        in descending order of how many graphs the orientation appears in. An uncontradicted orientation is one on which
        all graphs either agree or have no opinion. So if the edge X  Y appears in all n graphs, it will be listed
        first. If the edge X  Z appears in n – 1 graphs, it will be listed next, but only if the nth graph doesn’t
        contradict it—that is, only if the edge Z  X does not appear in the final graph. If the undirected edge Z – X
        appears in the final graph, the orientation X  Z is still considered to be uncontradicted.</p>

    <p>Finally, any contradicted orientations (orientations that the graphs disagree on) are listed.</p>

    <h2>Independence Facts Comparison</h2>

    <p>Rather than comparing edges or orientation, this option directly compares the implied dependencies in two graphs.
        When you initially open the box,
        you will see the following window:</p>

    <img src="images/compare_box_6.png" alt="" width="650">

    <p>The drop-down menu allows you to choose which variables you want to check the dependence of. If you select more
        than two variables, an subsequent variables will be considered members of the conditioning set. So, if you
        select variables X1, X2, and X3, in that order, the box will determine whether X1 is independent of X2,
        conditional on X3, in each of the graphs being compared. When you click “List,” in the bottom right of the
        window, the results will be displayed in the center of the window: </p>

    <img src="images/compare_box_7.png" alt="" width="650">

    <h2>Edge Weight Similarity Comparisons</h2>

    <p>Edge weight (linear coefficient) similarity comparisons compare two linear SEM instantiated models. The output is
        a score equal to the sum of the squares of the differences between each corresponding edge weight in each model.
        Therefore, the lower the score, the more similar the two graphs are. The score has peculiarities: it does not
        take account of the variances of the variables, and may therefore best be used with standardized models; the
        complete absence of an edge is scored as 0—so a negative coefficient compares less well with a positive
        coefficient than does no edge at all.</p>

    <p>Consider, for example, an edge weight similarity comparison between the following two SEM IMs:</p>

    <img src="images/compare_box_8.png" alt="" width="360">

    <img src="images/compare_box_9.png" alt="" width="360">

    <p>When they are input into an edge weight similarity comparison, the following window results: </p>


    <img src="images/compare_box_10.png" alt="" width="450">

    <p>This is, unsurprisingly, a high score; the input models have few adjacencies in common, let alone similar
        parameters.</p>

    <h2>Model Fit</h2>

    <p>A model fit comparison takes a simulation box and a search box (ideally, a search that has been run on the
        simulated data in the simulation box), and provides goodness-of-fit statistics for the output graph and the
        data, as well as estimating the values of any parameters. It looks and functions identically to the estimator
        box, but unlike the estimator box, it takes the search box directly as a parent, without needing to isolate and
        parameterize the graph output by the search.</p>


    <h1 id="parametric_model_box"><span class="section_heading">Parametric Model Box</span></h1>

    <p>The parametric model box takes a nonparameterized input graph and creates a causal model.</p>

    <h2>Possible Parent Boxes of the Parametric Model Box:</h2>

    <ul class="ul">
        <li>A graph box</li>
        <li>Another parametric model box</li>
        <li>An instantiated model box</li>
        <li>An estimator box</li>
        <li>A data box</li>
        <li>A simulation box</li>
        <li>A search box</li>
        <li>A regression box</li>
    </ul>


    <h2>Possible Child Boxes of the Parametric Model Box:</h2>

    <ul class="ul">
        <li>A graph box</li>
        <li>Another parametric model box</li>
        <li>An instantiated model box</li>
        <li>An estimator box</li>
        <li>A data box</li>
        <li>A simulation box</li>
        <li>A search box</li>
        <li>A knowledge box</li>
    </ul>

    <h2>Bayes Parametric Models</h2>

    <p>A Bayes parametric model takes as input a DAG. Bayes PMs represent causal structures in which all of the
        variables are categorical.</p>

    <p>Bayes PMs consist of three components: the graphical representation of the causal structure of the model; for
        each named variable, the number of categories which that variable can assume; and the names of the categories
        associated with each variable.</p>

    <p>You may either manually assign categories to the variables or have Tetrad assign them at random. If you choose to
        manually create a Bayes PM, each variable will initially be assigned two categories, named numerically. If you
        choose to have Tetrad assign the categories, you can specify a minimum and maximum number of categories possible
        for any given variable. You can then manually edit the number of categories and category names.</p>

    <p>Take, for example, the following DAG:</p>

    <img src="images/parametric_model_box_1.png" alt="" width="360">

    <p>One possible random Bayes PM that Tetrad might generate from the above DAG, using the default settings, looks
        like this:</p>

    <img src="images/parametric_model_box_2.png" alt="" width="650">

    <p>To view the number and names of the categories associated with each variable, you can click on that variable in
        the graph, or choose it from the drop-down menu on the right. In this graph, X1 and X2 each have three
        categories, and the rest of the variables have four categories. The categories are named numerically by
        default.</p>

    <p>The number of categories associated with a particular variable can be changed by clicking up or down in the
        drop-down menu on the right. Names of categories can be changed by overwriting the text already present.</p>

    <p>Additionally, several commonly-used preset variable names are provided under the “Presets” tab on the right. If
        you choose one of these configurations, the number of categories associated with the current variable will
        automatically be changed to agree with the configuration you have chosen. If you want all of the categories
        associated with a variable to have the same name with a number appended (e.g., x1, x2, x3), choose the “x1, x2,
        x3…” option under Presets.</p>

    <p>You can also copy category names between variables in the same Bayes PM by clicking on “Transfer—Copy categories”
        and “Transfer—Paste categories.”</p>

    <h2>SEM Parametric Models</h2>

    <p>The parametric model of a structural equation model (SEM) will take any type of graph as input, as long as the
        graph contains only directed and bidirected edges. SEM PMs represent causal structures in which all variables
        are continuous. </p>

    <p>A SEM PM has two components: the graphical causal structure of the model, and a list of parameters used in a set
        of linear equations that define the causal relationships int the model. Each variable in a SEM PM is a linear
        function of a subset of the other variables and of an error term drawn from a Normal distribution.</p>

    <p>Here is an example of a SEM graph and the SEM PM that Tetrad creates from it:</p>

    <img src="images/parametric_model_box_3.png" alt="" width="360">

    <img src="images/parametric_model_box_4.png" alt="" width="450">

    <p>You can see the error terms in the model by clicking “Parameters—Show Error Terms.”
        In a SEM model, a bidirected edge indicates that error terms are correlated, so when error terms are visible,
        the edge between X1 and X2 will instead run between their error terms.</p>

    <p>To change a parameter’s name or starting value for estimation, double click on the parameter in the window.</p>

    <h2>Generalized SEM Parametric Models</h2>

    <p>A generalized SEM parametric model takes as input any type of graph, as long as the graph contains only directed
        edges. (The generalized SEM PM cannot currently interpret bidirected edges.) Like a SEM PM, it represents causal
        structures in which all variables are continuous. Also like a SEM PM, a generalized SEM PM contains two
        components: the graphical causal structure of the model, and a set of equations representing the causal
        structure of the model. Each variable in a generalized SEM PM is a function of a subset of the other variables
        and an error term. By default, the functions are linear and the error terms are drawn from a Normal distribution
        (as in a SEM PM), but the purpose of a generalized SEM PM is to allow editing of these features.</p>

    <p>Here is an example of a general graph and the default generalized SEM PM Tetrad creates using it:</p>

    <img src="images/parametric_model_box_5.png" alt="" width="360">

    <img src="images/parametric_model_box_6.png" alt="" width="650">


    <p>You can view the error terms by clicking “Tools: Show Error Terms.”

    <p>The Variables tab contains a list of the variables and the expressions that define them, and a list of the error
        terms and the distributions from which their values will be drawn. Values will be drawn independently for each
        case if the model is instantiated (see IM box) and used to simulate data (see data box).</p>

    <p>The Parameters tab contains a list of the parameters and the distributions from which they are drawn. When the
        model in instantiated in the IM box, a fixed value of each parameter will be selected according to the specified
        distribution. </p>

    <p>To edit an expression or parameter, double click on it (in any tab). This will open up a window allowing you to
        change the function that defines the variable or distribution of the parameter.</p>

    <p>For instance, if you double click on the expression next to X1 (b1*X5+E_X1), the following window opens:</p>

    <img src="images/parametric_model_box_7.png" alt="" width="500">

    <p>The drop-down menu at the top of the window lists valid operators and functions. You could, for example, change
        the expression from linear to quadratic by replacing b1*X5+E_X1 with b1*X5^2+E_X1. You can also form more
        complicated expressions, using, for instance, exponential or sine functions. If the expression you type is
        well-formed, it will appear in black text; if it is invalid, it will appear in red text. Tetrad will not accept
        any invalid changes. </p>

    <p>Parameters are edited in the same way as expressions.</p>

    <p>If you want several expressions or parameters to follow the same non-linear model, you may wish to use the Apply
        Templates tool. This allows you to edit the expressions or parameters associated with several variables at the
        same time. To use the Apply Templates tool, click “Tools: Apply Templates….” This will open the following
        window:</p>

    <img src="images/parametric_model_box_8.png" alt="" width="500">

    <p>You can choose to edit variables, error terms, or parameters by clicking through the “apply to” radio buttons. If
        you type a letter or expression into the “starts with” box, the template you create will apply only to
        variables, error terms, or parameters which begin with that letter for expression. For example, in the given
        generalized PM, there are two types of parameters: the standard deviations s1-s6 and the edge weights b1-b7. If
        you click on the “Parameters” radio button and type “b” into the “Starts with” box, only parameters b1-b7 will
        be affected by the changes you make.</p>

    <p>The “Type Template” box itself works in the same way that the “Type Expression” box works in the “Edit
        Expression” window, with a few additions. If you scroll through the drop-down menu at the top of the window, you
        will see the options NEW, TSUM, and TPROD. Adding NEW to a template creates a new parameter for every variable
        the template is applied to. TSUM means “sum of the values of this variable’s parents,” and TPROD means “product
        of the values of this variable’s parents.” The contents of the parentheses following TSUM and TPROD indicate any
        operations which should be performed upon each variable in the sum or product, with the dollar sign ($)
        functioning as a wild card. For example, in the image above, TSUM(NEW(b)*$) means that, for each parent variable
        of the variable in question, a new “b” will be created and multiplied by the parent variable’s value, and then
        all of the products will be added together.</p>


    <h1 id="instantiated_model_box"><span class="section_heading">Instantiated Model Box</span></h1>

    <p>The instantiated model (IM) box takes a parametric model and assigns values to the parameters.</p>

    <h2>Possible Parent Boxes of the Instantiated Model Box:</h2>

    <ul class="ul">
        <li>A parametric model box</li>
        <li>Another instantiated model box</li>
        <li>An estimator box</li>
        <li>A simulation box</li>
        <li>An updater box</li>
    </ul>

    <h2>Possible Child Boxes of the Instantiated Model Box:</h2>

    <ul class="ul">
        <li>A graph box</li>
        <li>A compare box</li>
        <li>A parametric model box</li>
        <li>Another instantiated model box</li>
        <li>An estimator box</li>
        <li>A simulation box</li>
        <li>A search box</li>
        <li>An updater box</li>
        <li>A classify box</li>
        <li>A knowledge box</li>
    </ul>


    <h2>Bayes Instantiated Models</h2>

    <p>A Bayes IM consists of a Bayes parametric model with defined probability values for all variables. This means
        that, conditional on the values of each of its parent variables, there is a defined probability that a variable
        will take on each of its possible values. For each assignment of a value to each of the parents of a variable X,
        the probabilities of the several values of X must sum to 1.</p>

    <p>You can manually set the probability values for each variable, or have Tetrad assign them randomly. If you choose
        to have Tetrad assign probability values, you can manually edit them later. If you wish for Tetrad to randomly
        reassign probability values each time the box is opened, check “Pick new random values every time this Bayes IM
        is re-initialized.” then if you destroy the model in the box and create a new one, the box will remember the
        random values it created.</p>

    <p>Here is an example of a Bayes PM and its randomly created instantiated model:</p>

    <img src="images/instantiated_model_box_1.png" alt="" width="650">

    <img src="images/instantiated_model_box_2.png" alt="" width="650">

    <p>In the model above, when X4 and X5 are both 0, the probability that X5 is 0 is 0.0346, that X5 is 1 is 0.4425,
        and that X5 is 2 is 0.5229. Since X5 must be 0, 1, or 2, those three values must add up to one, as must the
        values in every row.</p>

    <p>To view the probability values of a variable, either double click on the variable in the graph or choose it from
        the drop-down menu on the right. You can manually set a given probability value by overwriting the text box. Be
        warned that changing the value in one cell will delete the values in all of the other cells in the row. Since
        the values in any row must sum to one, if all of the cells in a row but one are set, Tetrad will automatically
        change the value in the last cell to make the sum correct. For instance, in the above model, if you change the
        first row such that the probability that X5 = 0 is 0.5000 and the probability that X5 = 1 is 0.4000, the
        probability that X5 = 2 will automatically be set to 0.1000.</p>

    <p>If you right click on a cell in the table (or two-finger click on Macs), you can choose to randomize the
        probabilities in the row containing that cell, randomize the values in all incomplete rows in the table,
        randomize the entire table, or randomize the table of every variable in the model. You can also choose to clear
        the row or table.</p>


    <h2>Bayes Instantiated Models: Observed Variables Only</h2>

    <p>This box functions in the same way as a Bayes IM box, but represents only measured variables in the model.</p>

    <h2>Dirichlet Instantiated Models</h2>

    <p>A Dirichlet instantiated model is a specialized form of a Bayes instantiated model. Like a Bayes IM, a Dirichlet
        IM consists of a Bayes parametric model with defined probability values. Unlike a Bayes IM, these probability
        values are not manually set or assigned randomly. Instead, the pseudocount is manually set or assigned
        uniformly, and the probability values are derived from it. The pseudocount of a given value of a variable is the
        number of data points for which the variable takes on that value, conditional on the values of the variable’s
        parents, where these numbers are permitted to take on non-negative real values. Since we are creating models
        without data, we can set the pseudocount to be any number we want. If you choose to create a Dirichlet IM, a
        window will open allowing you to either manually set the pseudocounts, or have Tetrad set all the pseudocounts
        in the model to one number, which you specify.</p>

    <p>Here is an example of a Bayes PM and the Dirichlet IM which Tetrad creates from it when all pseudocounts are set
        to one:</p>

    <img src="images/instantiated_model_box_3.png" alt="" width="650">

    <img src="images/instantiated_model_box_4.png" alt="" width="650">

    <p>In the above model, when X2=0 and X6=0, there is one (pseudo) data point at which X4=0, one at which X4=1, and
        one at which X4=2. There are three total (pseudo) data points in which X2=0 and X6=0. You can view the
        pseudocounts of any variable by clicking on it in the graph or choosing it from the drop-down menu at the top of
        the window. To edit the value of a pseudocount, double click on it and overwrite it. The total count of a row
        cannot be directly edited.</p>

    <p>From the pseudocounts, Tetrad determines the conditional probability of a category. This estimation is done by
        taking the pseudocount of a category and dividing it by the total count for its row. For instance, the total
        count of X4 when X2=0 and X6=0 is 3. So the conditional probability of X4=0 given that X2=0 and X6=0 is 1/3. The
        reasoning behind this is clear: in a third of the data points in which X2 and X6 are both 0, X4 is also 0, so
        the probability that X4=0 given that X2 and X6 also equal 0 is probably one third. This also guarantees that the
        conditional probabilities for any configuration of parent variables add up to one, which is necessary.</p>

    <p>To view the table of conditional probabilities for a variable, click the Probabilities tab. In the above model,
        the Probabilities tab looks like this: </p>

    <img src="images/instantiated_model_box_5.png" alt="" width="650">

    <h2>SEM Instantiated Models</h2>

    <p>A SEM instantiated model is a SEM parametric model in which the parameters and error terms have defined values.
        If you choose to create a SEM IM, the following window will open:</p>

    <img src="images/instantiated_model_box_6.png" alt="" width="450">


    <p>Using this box, you can specify the ranges of values from which you want coefficients, covariances, and variances
        to be drawn for the parameters in the model. In the above box, for example, all linear coefficients will be
        between -1.5 and -0.5 or 0.5 and 1.5. If you uncheck “symmetric about zero,” they will only be between 0.5 and
        1.5.</p>

    <p>Here is an example of a SEM PM and a SEM IM generated from it using the default settings: </p>

    <img src="images/instantiated_model_box_7.png" alt="" width="360">

    <img src="images/instantiated_model_box_8.png" alt="" width="450">

    <p>You can now manually edit the values of parameters in one of two ways. Double clicking on the parameter in the
        graph will open up a small text box for you to overwrite. Or you can click on the Tabular Editor tab, which will
        show all of the parameters in a table which you can edit. The Tabular Editor tab of our SEM IM looks like
        this:</p>

    <img src="images/instantiated_model_box_9.png" alt="" width="450">

    <p>In the Tabular Editor tab of a SEM estimator box (which functions similarly to the SEM IM box), the SE, T, and P
        columns provide statistics showing how robust the estimation of each parameter is. Our SEM IM, however, is in an
        instantiated model box, so these columns are empty.</p>

    <p>The Implied Matrices tab shows matrices of relationships between variables in the model. In the Implied Matrices
        tab, you can view the covariance or correlation matrix for all variables (including latents) or just measured
        variables. In our SEM IM, the Implied Matrices tab looks like this:</p>

    <img src="images/instantiated_model_box_10.png" alt="" width="450">

    <p>You can choose the matrix you wish to view from the drop-down menu at the top of the window. Only half of any
        matrix is shown, because in a well-formed acyclic model, the matrices should be symmetric. The cells in the
        Implied Matrices tab cannot be edited.</p>

    <p>In an estimator box, the Model Statistics tab provides goodness of fit statistics for the SEM IM which has been
        estimated. Our SEM IM, however, is in an instantiated model box, so no estimation has occurred, and the Model
        Statistics tab is empty.</p>


    <h2>Standardized SEM Instantiated Models </h2>

    <p>A standardized SEM instantiated model consists of a SEM parametric model with defined values for its parameters.
        In a standardized SEM IM, each variable (not error terms) has a Normal distribution with 0 mean and unit
        variance. The input PM to a standardized SEM IM must be acyclic.</p>

    <p>Here is an example of an acyclic SEM PM and the standardized SEM IM which Tetrad creates from it</p>

    <img src="images/instantiated_model_box_11.png" alt="" width="360">

    <img src="images/instantiated_model_box_12.png" alt="" width="450">


    <p>To edit a parameter, double click on it. A slider will open at the bottom of the window (shown above for the edge
        parameter between X1 and X2). Click and drag the slider to change the value of the parameter, or enter the
        specific value you wish into the box. The value must stay within a certain range in order for the Normal
        distribution to stay standardized, so if you attempt to overwrite the text box on the bottom right with a value
        outside the listed range, Tetrad will not allow it. In a standardized SEM IM, error terms are not considered
        parameters and cannot be edited, but you can view them by clicking Parameters: Show Error Terms. </p>

    <p>The Implied Matrices tab works in the same way that it does in a normal SEM IM.</p>


    <h2>Generalized SEM Instantiated Models</h2>

    <p>A generalized SEM instantiated model consists of a a generalized SEM parametric model with defined values for its
        parameters. Since the distributions of the parameters were specified in the SEM PM, Tetrad does not give you the
        option of specifying these before it creates the instantiated model.</p>

    <p>Here is an example of a generalized SEM PM and its generalized SEM IM:</p>

    <img src="images/instantiated_model_box_13.png" alt="" width="450">

    <img src="images/instantiated_model_box_14.png" alt="" width="450">

    <p>Note that the expressions for X6 and X2 are not shown, having been replaced with the words “long formula.”
        Formulae over a certain length—the default setting is 25 characters—are hidden to improve visibility. Long
        formulae can be viewed in the Variables tab, which lists all variables and their formulae. You can change the
        cutoff point for long formulae by clicking Tools: Formula Cutoff.</p>

    <p>If you double click on a formula in either the graph or the Variables tab, you can change the value of the
        parameters in that formula. </p>


    <h1 id="data_box"><span class="section_heading">Data Box</span></h1>

    <p>The data box stores or manipulates data sets.</p>

    <h2>Possible Parent Boxes of the Data Box</h2>

    <ul class="ul">
        <li>A graph box</li>
        <li>An estimator box</li>
        <li>Another data box</li>
        <li>A simulation box</li>
        <li>A regression box</li>
    </ul>


    <h2>Possible Child Boxes of the Data Box</h2>

    <ul class="ul">
        <li>A graph box</li>
        <li>A parametric model box</li>
        <li>Another data box</li>
        <li>An estimator box</li>
        <li>A simulation box</li>
        <li>A search box</li>
        <li>A classify box</li>
        <li>A regression box</li>
        <li>A knowledge box</li>
    </ul>

    <h2>Using the Data Box:</h2>

    <p>The data box stores the actual data sets from which causal structures are determined. Data can be loaded into the
        data box from a preexisting source, manually filled in Tetrad, or simulated from an instantiated model.</p>

    <h2>Loading Data</h2>

    <p>Data sets loaded into Tetrad may be categorical, continuous, mixed, or covariance data.</p>

    <h3>General Tabular Data</h3>

    <p>To load data, create a data box with no parent. When you double click it, an empty data window will appear: </p>

    <img src="images/data_box_1.png" alt="" width="650">

    <p>Click "File -> Load Data" and select the text file or files that contain your data. The following window will
        appear:</p>

    <img src="images/data_box_2.png" alt="" width="650">

    <p>The text of the source file appears in the Data Preview window. Above, there are options to describe your file,
        so that Tetrad can load it correctly. If you are loading categorical, continuous, or mixed data values, select
        the “Tabular Data” button. If you are loading a covariance matrix, select “Covariance Data.” Note that if you
        are loading a covariance matrix, your text file should contain only the lower half of the matrix, as Tetrad will
        not accept an entire matrix.</p>

    <p>Below the file type, you can specify a number of other details about your file, including information about the
        type of data (categorical/continuous/mixed), metadata JSON file, delimiter between data values, variable names,
        and more. If your data is mixed (some variables categorical, and some continuous), you must specify the maximum
        number of categories discrete variables in your data can take on. All columns with more than that number of
        values will be treated as continuous; the others will be treated as categorical. If you do not list the variable
        names in the file, you should uncheck “First row variable names.” If you provide case IDs, check the box for the
        appropriate column in the “Case ID column to ignore” area. If the case ID column is labeled, provide the name of
        the label; otherwise, the case ID column should be the first column, and you should check “First column.”</p>

    <p>Below this, you can specify your comment markers, quote characters, and the character which marks missing data
        values. Tetrad will use that information to distinguish continuous from discrete variables. You may also choose
        more files to load (or remove files that you do not wish to load) in the “Files” panel on the lower left.</p>

    <h3>Metadata JSON File</h3>
    <p>
        Metadata is optional in general data handling. But it can be very helpful if you want to overwrite the data type
        of a given variable column. And the metadata MUST be a JSON file like the following example.
    </p>

    <pre>
{
"domains": [
{
"name": "raf",
"discrete": false
},
{
"name": "mek",
"discrete": true
}
]
}
</pre>

    <p>
        You can specify the name and data type for each variable. Variables that are not in the metadata file will be
        treated as domain variables and their data type will be the default data type when reading in columns described
        previously.
    </p>

    <p>When you are satisfied with your description of your data, click “Validate” at the bottom of the window. Tetrad
        will check that your file is correctly formatted. If it is, you will receive a screen telling you that
        validation has passed with no error. At this point, you can revisit the settings page, or click “Load” to load
        the data. </p>

    <img src="images/data_box_3.png" alt="" width="650">

    <img src="images/data_box_4.png" alt="" width="650">

    <p>You can now save this data set to a text file by clicking File: Save Data.</p>

    <p>In addition to loading data from a file, you can manually enter data values and variable names by overwriting
        cells in the data table.</p>


    <h3>Covariance Data</h3>
    <p>Covariance matrices loaded into Tetrad should be ascii text files. The first row contains the sample size, the
        second row contains the names of the variables. The first two rows are followed by a lower triangular matrix.
        For example:</p>

    <pre>
1000
X1  X2  X3  X4  X5  X6
1.0000
0.0312  1.0000
-0.5746 0.4168  1.0000
-0.5996 0.4261  0.9544  1.0000
0.8691  0.0414  -0.4372 -0.4487 1.0000
0.6188  0.0427  -0.1023 -0.0913 0.7172  1.0000
</pre>


    <p>Categorical, continuous, or mixed data should also be an ascii text file, with columns representing variables and
        rows representing cases. Beyond that, there is a great deal of flexibility in the layout: delimiters may be
        commas, colons, tabs, spaces, semicolons, pipe symbols, or whitespace; comments and missing data may be marked
        by any symbol you like; there may be a row of variable names or not; and case IDs may be present or not. There
        should be no sample size row. For example:</p>

    <pre>
X1  X2  X3  X4  X5
-3.0133 1.0361  0.2329  2.7829  -0.2878
0.5542  0.3661  0.2480  1.6881  0.0775
3.5579  -0.7431 -0.5960 -2.5502 1.5641
-0.0858 1.0400  -0.8255 0.3021  0.2654
-0.9666 -0.5873 -0.6350 -0.1248 1.1684
-1.7821 1.8063  -0.9814 1.8505  -0.7537
-0.8162 -0.6715 0.3339  2.6631  0.9014
-0.3150 -0.5103 -2.2830 -1.2462 -1.2765
-4.1204 2.9980  -0.3609 4.8079  0.6005
1.4658  -1.4069 1.7234  -1.7129 -3.8298
</pre>

    <h3>Handling Tabular Data With Interventions</h3>

    <p>This is advanced topic for dataset that contains interventional variables. Below is a sample dataset, in which
        `raf`, `mek`, `pip2`, `erk`, `atk` are the 5 domain variables, and `cd3_s` and `cd3_v` are an interventional
        pair (status and value variable respectively). `icam` in another intervention variable, but it's a combined
        variable that doesn't have status.</p>

    <pre>
raf mek pip2    erk akt cd3_s   cd3_v   icam
3.5946  3.1442  3.3429  2.81    3.2958  0   1.2223  *
3.8265  3.2771  3.2884  3.3534  3.7495  0   2.3344  *
4.2399  3.9908  3.0057  3.2149  3.7495  1   0   3.4423
4.4188  4.5304  3.157   2.7619  3.0819  1   3.4533  1.0067
3.7773  3.3945  2.9821  3.4372  4.0271  0   4.0976  *
</pre>

    <p>And the sample metadata JSON file looks like this:</p>

    <pre>
{
"interventions": [
{
"status": {
"name": "cd3_s",
"discrete": true
},
"value": {
"name": "cd3_v",
"discrete": false
}
},
{
"status": null,
"value": {
"name": "icam",
"discrete": false
}
}
],
"domains": [
{
"name": "raf",
"discrete": false
},
{
"name": "mek",
"discrete": false
}
]
}
</pre>

    <p>Each intervention consists of a status variable and value variable. There are cases that you may have a combined
        interventional variable that doesn't have the status variable. In this case, just use `null`. The data type of
        each variable can either be discrete or continuous. We use a boolean flag to indicate the data type. From the
        above example, we only specified two domain variables in the metadata JSON, any variables not specifed in the
        metadata will be treated as domain variables.</p>


    <h2>Manipulating Data</h2>

    <p>The data box can also be used to manipulate data sets that have already been loaded or simulated. If you create a
        data box as the child of another box containing a data set, you will be presented with a list of operations that
        can be performed on the data. The available data manipulations are:</p>

    <h3>Discretize Dataset</h3>

    <p>This operation allows you to make some or all variables in a data set discrete. If you choose it, a window will
        open. </p>

    <img src="images/data_box_5.png" alt="" width="650">

    <p>When the window first opens, no variables are selected, and the right side of the window appears blank; in this
        case, we have already selected X1 ourselves. In order to discretize a variable, Tetrad assigns all data points
        within a certain range to a category. You can tell Tetrad to break the range of the dataset into approximately
        even sections (Evenly Distributed Intervals) or to break the data points themselves into approximately even
        chunks (Evenly Distributed Values). Use the scrolling menu to increase or decrease the number of categories to
        create. You can also rename categories by overwriting the text boxes on the left, or change the ranges of the
        categories by overwriting the text boxes on the right. To discretize another variable, simply select it from the
        left. If you want your new data set to include the variables you did not discretize, check the box at the bottom
        of the window.</p>

    <p>You may discretize multiple variables at once by selecting multiple variables. In this case, the ranges are not
        shown, as they will be different from variable to variable.</p>

    <h3>Convert Numerical Discrete to Continuous</h3>

    <p>If you choose this option, any discrete variables with numerical category values will be treated as continuous
        variables with real values. For example, “1” will be converted to “1.0.”</p>

    <h3>Calculator</h3>

    <p>The Calculator option allows you to add and edit relationships between variables in your data set, and to add new
        variables to the data set. </p>

    <img src="images/data_box_6.png" alt="" width="650">

    <p>In many ways, this tool works like the Edit Expression window in a generalized SEM parametric model. To edit the
        formula that defines a variable (which will change that variable’s values in the table) type that variable name
        into the text box to the left of the equals sign. To create a new variable, type a name for that variable into
        the text box to the left of the equals sign. Then, in the box on the right, write the formula by which you wish
        to define a new variable in place of, or in addition to, the old variable. You can select functions from the
        scrolling menu below. (For an explanation of the meaning of some the functions, see the section on generalized
        SEM models in the Parametric Model Box chapter.) To edit or create several formulae at once, click the “Add
        Expression” button, and another blank formula will appear. To delete a formula, check the box next to it and
        click the “Remove Selected Expressions” button.</p>

    <p>When you click “Save” a table will appear listing the data. Values of variables whose formulae you changed will
        be changed, and any new variables you created will appear with defined values.</p>

    <h3>Merge Deterministic Interventional Variables</h3>

    <p>This option looks for pairs of interventional variables (currently only discrete variables) that are
        deterministic and merges them into one combined variable. For domain variables that are fully determinised,
        we'll add an attribute to them. Later in the knowledge box (Edges and Tiers), all the interventional variables
        (both status and value variables) and the fully-determinised domain variables will be automatically put to top
        tier. And all other domain variables will be placed in the second tier.</p>

    <h3>Merge Datasets</h3>

    <p>This operation takes two or more data boxes as parents and creates a data box containing all data sets in the
        parent boxes. Individual data sets will be contained in their own tabs in the resulting box.</p>

    <h3>Convert to Correlation Matrix</h3>

    <p>This operation takes a tabular data set and outputs the lower half of the correlation matrix of that data
        set.</p>

    <h3>Convert to Covariance Matrix</h3>

    <p>This operation takes a tabular data set and outputs the lower half of the covariance matrix of that data set.</p>

    <h3>Inverse Matrix</h3>

    <p>This operation takes a covariance or correlation matrix and outputs its inverse. (Note: The output will not be
        acceptable in Tetrad as a covariance or correlation matrix, as it is not lower triangular.)</p>

    <h3>Simulate Tabular from Covariance</h3>

    <p>This operation takes a covariance matrix and outputs a tabular data set whose covariances comply with the
        matrix.</p>

    <h3>Difference of Covariance Matrices</h3>

    <p>This operation takes two covariance matrices and outputs their difference. The resulting matrix will be a
        well-formatted Tetrad covariance matrix data set.</p>

    <h3>Sum of Covariance Matrices</h3>

    <p>This operation takes two covariance matrices and outputs their sum. The resulting matrix will be a well-formatted
        Tetrad covariance matrix data set.</p>

    <h3>Average of Covariance Matrices</h3>

    <p>This operation takes two or more covariance matrices and outputs their average. The resulting matrix will be a
        well-formatted Tetrad covariance matrix data set.</p>

    <h3>Convert to Time Lag Data</h3>

    <p>This operation takes a tabular data set and outputs a time lag data set, in which each variable is recorded
        several times over the course of an experiment. You can specify the number of lags in the data. Each contains
        the same data, shifted by one “time unit.” For instance, if the original data set had 1000 cases, and you
        specify that the time lag data set should contain two lags, then the third stage variable values will be those
        of cases 1 to 998, the second stage variable values will be those of cases 2 to 999, and the first stage
        variable values will be those of cases 3 to 1000.</p>

    <h3>Convert to Time Lag Data with Index</h3>

    <p>This operation takes a tabular data set and outputs a time lag data set in the same manner as “Convert to Time
        Lag Data,” then adds an index variable.</p>

    <h3>Convert to AR Residuals</h3>

    <p>This operation is performed on a time lag data set. Tetrad performs a linear regression on each variable in each
        lag with respect to each of the variables in the previous lag, and derives the error terms. The output data set
        contains only the error terms.</p>

    <h3>Whiten</h3>

    <p>Takes a continuous tabular data set and converts it to a data set whose covariance matrix is the identity
        matrix.</p>

    <h3>Nonparanormal Transform</h3>

    <p>Takes a continuous tabular data set and increases its Gaussianity, using a nonparanormal transformation to smooth
        the variables. (Note: This operation increases only marginal Gaussanity, not the joint, and in linear systems
        may eliminate information about higher moments that can aid in non-Gaussian orientation procedures.) </p>

    <h3>Convert to Residuals</h3>

    <p>The input for this operation is a directed acyclic graph (DAG) and a data set. Tetrad performs a linear
        regression on each variable in the data set with respect to all of the variables that the graph shows to be its
        parents, and derives the error terms. The output data set contains only the error terms.</p>

    <h3>Standardize Data</h3>

    <p>This operation manipulates the data in your data set such that each variable has 0 mean and unit variance.</p>

    <h3>Remove Cases with Missing Values</h3>

    <p>If you choose this operation, Tetrad will remove any row in which one or more of the values is missing.</p>

    <h3>Replace Missing Values with Column Mode</h3>

    <p>If you choose this operation, Tetrad will replace any missing value markers with the most commonly used value in
        the column.</p>

    <h3>Replace Missing Values with Column Mean</h3>

    <p>If you choose this operation, Tetrad will replace any missing value markers with the average of all of the values
        in the column.
        Replace Missing Values with Regression Predictions: If you choose this operation, Tetrad will perform a linear
        regression on the data in order to estimate the most likely value of any missing value.</p>

    <h3>Replace Missing Values by Extra Category</h3>

    <p>This operation takes as input a discrete data set. For every variable which has missing values, Tetrad will
        create an extra category for that variable (named by default “Missing”) and replace any missing data markers
        with that category.</p>

    <h3>Replace Missing with Random</h3>

    <p>For discrete data, replaces missing values at random from the list of categories the variable takes in other
        cases. For continuous data, finds the minimum and maximum values of the column (ignoring the missing values) and
        picks a random number from U(min, max)</p>

    <h3>Inject Missing Data Randomly</h3>

    <p>If you choose this operation, Tetrad will replace randomly selected data values with a missing data marker. You
        can set the probability with which any particular value will be replaced (that is, approximately the percentage
        of values for each variable which will be replaced with missing data markers).</p>

    <h3>Bootstrap Sample</h3>

    <p>This operation draws a random subset of the input data set (you specify the size of the subset) with replacement
        (that is, cases which appear once in the original data set can appear multiple times in the subset). The
        resulting data set can be used along with similar subsets to achieve more accurate estimates of parameters.</p>

    <h3>Split by Cases</h3>

    <p>This operation allows you to split a data set into several smaller data sets. When you choose it, a window
        opens. </p>

    <img src="images/data_box_7.png" alt="" width="360">


    <p>If you would like the subsets to retain the ordering they had in the original set, click “Original Order.”
        Otherwise, the ordering of the subsets will be assigned at random. You can also increase and decrease the number
        of subsets created, and specify the range of each subset.</p>

    <h3>Permute Rows</h3>

    <p>This operation randomly reassigns the ordering of a data set’s cases.</p>

    <h3>First Differences</h3>

    <p>This operation takes a tabular data set and outputs the first differences of the data (i.e., if X is a variable
        in the original data set and X’ is its equivalent in the first differences data set, X’1 = X2 – X1). The
        resulting data set will have one fewer row than the original.</p>

    <h3>Concatenate Datasets</h3>

    <p>This operation takes two or more datasets and concatenates. The parent datasets must have the same number of
        variables.</p>

    <h3>Copy Continuous Variables</h3>

    <p>This operation takes as input a data set and creates a new data set containing only the continuous variables
        present in the original.</p>

    <h3>Copy Discrete Variables</h3>

    <p>This operation takes as input a data set and creates a new data set containing only the discrete variables
        present in the original.</p>

    <h3>Remove Selected Variables</h3>

    <h3>Copy Selected Variables</h3>

    <p>As explained above, you can select an entire column in a data set by clicking on the C1, C2, C3, etc… cell above
        the column. To select multiple columns, press and hold the “control” key while clicking on the cells. Once you
        have done so, you can use the Copy Selected Variables tool to create a data set in which only those columns
        appear.</p>

    <h3>Remove Constant Columns</h3>

    <p>This operation takes a data set as input, and creates a data set which contains all columns in the original data
        set except for those with constant values (such as, for example, a column containing nothing but 2’s).</p>

    <h3>Randomly Reorder Columns</h3>

    <p>This operation randomly reassigns the ordering of a data set’s variables.</p>

    <h2>Manually Editing Data</h2>

    <p>Under the Edit tab, there are several options to manipulate data. If you select a number of cells and click
        “Clear Cells,” Tetrad will replace the data values in the selected cells with a missing data marker. If you
        select an entire row or column and click “Delete selected rows or columns,” Tetrad will delete all data values
        in the row or column, and the name of the row or column. (To select an entire column, click on the category
        number above it, labeled C1, C2, C3, and so on. To select an entire row, click on the row number to the left of
        it, labeled 1, 2, 3, and so on.) You can also copy, cut, and paste data values to and from selected cells. You
        can choose to show or hide category names, and if you click on “Set Constants Col to Missing,” then in any
        column in which the variable takes on only one value (for example, a column in which every cell contains the
        number 2) Tetrad will set every cell to the missing data marker.</p>

    <p>Under the Tools tab, the Calculator tool allows you add and edit relationships between variables in the graph.
        For more information on how the Calculator tool works, see “Manipulating Data” section above.</p>

    <h2>Data Information</h2>

    <p>Under the Tools tab, there are options to view information about your data in several different formats.</p>

    <p>The Histograms tool shows histograms of the variables in the data set.</p>


    <img src="images/data_box_8.png" alt="" width="650">


    <p>These show the distribution of data for each variable, with the width of each bar representing a range of values,
        and height of each bar representing how many data points fall into that range. Using histograms, you can
        determine whether each variable has a distribution that is approximately Normal. To select a variable to view,
        choose it from the drop-down menu on the right. You can increase or decrease the number of bars in the histogram
        (and therefore decrease or increase the range of each bar, and increase or decrease the accuracy of the
        histogram) using the menu on the right. You can also view only ranges with a certain amount of the data using
        the “cull bins” menu.</p>

    <p>The Scatter Plots tool allows you to view scatter plots of two variables plotted against each other.</p>

    <img src="images/data_box_9.png" alt="" width="650">

    <p>To view a variable as the x- or y-axis of the graph, select it from one the drop-down menus to the right. To view
        the regression line of the graph, check the box on the right.</p>

    <p>You can see the correlation of two variables conditional on a third variable by using the Add New Conditional
        Variable button at the bottom of the window. This will open up a slider and a box in which you can set the
        granularity of the slider. By moving the slider to the left or right, you can change the range of values of the
        conditional variable for which the scatter plot shows the correlation of the variables on the x- and y- axes.
        You can increase and decrease the width of the ranges by changing the granularity of the slider. A slider with
        granularity 1 will break the values of the conditional variable into sections one unit long, etc. The
        granularity cannot be set lower than one.</p>

    <p>In a well-formed model, the scatter plot of a variable plotted against itself should appear as a straight line
        along the line y = x.</p>

    <p>The Q-Q Plot tool is a test for normality of distribution. </p>

    <img src="images/data_box_10.png" alt="" width="650">

    <p>If a variable has a distribution which is approximately Normal, its Q-Q plot should appear as a straight line
        with a positive slope. You can select the variable whose Q-Q plot you wish to view from the drop-down menu on
        the right.</p>

    <p>The Normality Tests tool gives a text box with the results of the Kolmogorov and Anderson Darling Tests for
        normality for each variable. The Descriptive Statistics tool gives a text box with statistical information such
        as the mean, median, and variance of each variable.</p>


    <h1 id="estimator_box"><span class="section_heading">Estimator Box</span></h1>

    <p>The estimator box takes as input a data box (or simulation box) and a parametric model box and estimates, tests,
        and outputs an instantiated model for the data. With the exception of the EM Bayes estimator, Tetrad estimators
        do not accept missing values. If your data set contains missing values, the missing values can interpolated or
        removed using the data box. (Note that missing values are allowed in various Tetrad search procedures; see the
        section on the search box.)</p>

    <h2>Possible Parent Boxes of the Estimator Box:</h2>

    <ul class="ul">
        <li>A parametric model box</li>
    </ul>


    <h2>Possible Child Boxes of the Estimator Box:</h2>

    <ul class="ul">
        <li>A graph box</li>
        <li>A simulation box</li>
        <li>An updater box</li>
    </ul>

    <h2>ML Bayes Estimations</h2>

    <p>Bayes nets are acyclic graphical models parameterized by the conditional probability distribution of each
        variable on its parents' values, as in the instantiated model box. When the model contains no latent variables,
        the joint distribution of the variables equals the product of the distributions of the variables conditional on
        their respective parents. The maximum likelihood (ML) estimate of the joint probability distribution under a
        model is the product of the corresponding frequencies in the sample. </p>

    <p>The ML Bayes estimator, because it estimates Bayes IMs, works only on models with discrete variables. The model
        estimated must not include latent variables, and the input data set must not include missing data values. A
        sample estimate looks like this:</p>

    <img src="images/estimator_box_1.png" alt="" width="650">

    <p>The Model tab works exactly as it does in a Bayes instantiated model. The Model Statistics tab provides the
        p-value for a chi square test of the model, degrees of freedom, the chi square value, and the Bayes Information
        Criterion (BIC) score of the model.</p>

    <h2>Dirichlet Estimations</h2>

    <p>A Dirichlet estimate estimates a Bayes instantiated model using a Dirichlet distribution for each category. In a
        Dirichlet estimate, the probability of each value of a variable (conditional on the values of the variable’s
        parents) is estimated by adding together a prior pseudo count (which is 1, by default, of cases and the number
        of cases in which the variable takes that value in the data, and then dividing by the total number of cases in
        the pseudocounts and in the data with that configuration of values of parent variables. The default prior
        pseudo-count can be changed inside the box. (For a full explanation of pseudocounts and Dirichlet estimate, see
        the section on Dirichlet instantiated models.) </p>

    <p>The Dirichlet estimator in TETRAD does not work if the input data set contains missing data values.</p>

    <h2>EM Bayes Estimations</h2>

    <p>The EM Bayes estimator takes the same input and gives the same output as the ML Bayes estimator, but is designed
        to handle data sets with missing data values, and input models with latent variables.</p>

    <h2>SEM Estimates</h2>

    <p>A SEM estimator estimates the values of parameters for a SEM parametric model. SEM estimates do not work if the
        input data set contains missing data values. A sample output looks like this: </p>

    <img src="images/estimator_box_2.png" alt="" width="650">

    <p>Tetrad provides five parameter optimizers: RICF,( Drton, M., &amp; Richardson, T. S. (2004, July). Iterative
        conditional fitting for Gaussian ancestral graph models. <i>In Proceedings of the 20th conference on Uncertainty
            in artificial intelligence</i> (pp. 130-137). AUAI Press). expectation­-maximization (EM), regression,
        Powell Journal of Econometrics 25 (1984) 303-325) and random search. Accurate regression estimates assume that
        the input parametric model is a DAG, and that its associated statistics are based on a linear, Gaussian model.
        The EM optimizer has the same input constraints as regression, but can handle latent variables. </p>

    <p>Tetrad also provides two scores that can be used in estimation: feasible generalized least squares (FGLS) and
        Full Information Maximum Likelihood (FML). </p>

    <p>If the graph for the SEM is a DAG, and we may assume that the SEM is linear with Gaussian error terms, we use
        multilinear regression to estimate coefficients and residual variances. Otherwise, we use a standard maximum
        likelihoood fitting function (see Bollen, Structural Equations with Latent Variables, Wiley, 1989, pg. 107) to
        minimize the distance between (a) the covariance over the variables as implied by the coefficient and error
        covariance parameter values of the model and (b) the sample covariance matrix. Following Bollen, we denote this
        function Fml; it maps points in parameter values space to real numbers, and, when minimized, yields the maximum
        likelihood estimation point in parameter space.</p>

    <p>In either case, an Fml value may be obtained for the maximum likelihood point in parameter space, either by
        regression or by direct minimization of the Fml function itself. The value of Fml at this minimum (maximum
        likelihood) point, multiplied by N - 1 (where N is the sample size), yields a chi square statistics (ch^2) for
        the model, which when referred to the chi square table with appropriate degrees of freedom, yields a model p
        value. The degrees of freedom (dof) in this case is equal to the m(m-1)/2 - f, where m is the number of measured
        variables, and f is the number of free parameters, equal to the number of coefficient parameters plus the number
        of covariance parameters. (Note that the degrees of freedom many be negative, in which case estimation should
        not be done.) The BIC score is calculated as ch^2 - dof * log(N).</p>

    <p>You can change which score optimizer Tetrad uses by choosing them from the drop-down menus at the bottom of the
        window and clicking “Estimate Again.”</p>

    <p>The Tabular Editor and Implied Matrices tabs function exactly as they do in the instantiated model box, but in
        the estimator box, the last three columns of the table in the Tabular Editor tab are filled in. The SE, T, and P
        columns provide the standard errors, t statistics, and p values of the estimation.</p>

    <p>The Model Statistics tab provides the degrees of freedom, chi square, p value, comparative fit index (CFI), root
        mean square error of approximation (RMSEA) and BIC score of a test of the model. It should be noted that while
        these test statistics are standard, they are not in general correct. See Mathias Drton, 2009, Likelihood ratio
        tests and singularities. Annals of Statistics 37(2):979-1012. arXiv:math.ST/0703360. </p>

    <p>When the EM algorithm is used with latent variable models, we recommend multiple random restarts. The number of
        restarts can be set in the lower right hand corner of the Estimator Box. The figure on the left shows the EM
        results for a SEM model with 1 restart. The figure on the right shows the EM results with 20 restarts. The
        results are very different. The estimates with 20 restarts are much closer to the true values. 100 restrarts
        gives estimates that are within .1 of the first decimal and .2 of the second decimal.</p>


    <h2>Generalized Estimator</h2>

    <p>A generalized graphical model may have non-linear relations and non-Gaussian distributions. These models are
        automatically estimated by the Powell method, which seeks a maximum likelihood solution.</p>


    <h1 id="updater_box"><span class="section_heading">Updater Box</span></h1>

    <p>The updater box takes an instantiated model as input, and, given information about the values of parameters in
        that model, updates the information about the values and relationships of other parameters.</p>

    <p>The Updater allows the user to specify values of variables as “Evidence.” The default is that the conditional
        probabilities (Bayes net models; categorical variables) or conditional means (SEM models; continuous variables)
        are computed. For any variable for which evidence is specified, the user can click on “Manipulated,” in which
        case the Updater will calculate the conditional probabilities or conditional means for other variables when the
        evidence variables are forced to have their specified values.. In manipulated calculations, all connections into
        a measured variable are discarded, the manipulated variables are treated as independent of their causes in the
        graph, and probabilities for variables that are causes of the maniputated variables are unchanged. </p>

    <p>There are four available updater algorithms in Tetrad: the approximate updater, the row summing exact updater,
        the CPT invariant updater, and the SEM updater. All except for the SEM updater function only when given Bayes
        instantiated models as input; the SEM updater functions when given a SEM instantiated model as input. None of
        the updaters work on cyclic models.</p>

    <h2>Possible Parent Boxes of the Updater Box:</h2>

    <ul class="ul">
        <li>An instantiated model box</li>
        <li>An estimator box</li>
    </ul>


    <h2>Possible Child Boxes of the Updater Box:</h2>

    <ul class="ul">
        <li>An instantiated model box (Note that the instantiated model will have the updated parameters)</li>
    </ul>

    <h2>Approximate Updater</h2>

    <p>The approximated updater is a fast but inexact algorithm. It randomly draws a sample data set from the
        instantiated model and calculates the conditional frequency of the variable to be estimated.</p>

    <p>Take, for example, the following instantiated model: </p>

    <img src="images/updater_box_1.png" alt="" width="650">

    <p>When it is input into the approximate updater, the following window results:</p>

    <img src="images/updater_box_2.png" alt="" width="650">

    <p>If we click “Do Update Now” now, without giving the updater any evidence, the right side of the screen changes to
        show us the marginal probabilities of the variables.</p>

    <img src="images/updater_box_3.png" alt="" width="360">

    <p>The blue lines, and the values listed across from them, indicate the probability that the variable takes on the
        given value in the input instantiated model. The red lines indicate the probability that the variable takes on
        the given value, given the evidence we’ve added to the updater. </p>

    <p>Since we have added no evidence to the updater, the red and blue lines are very similar in length. To view the
        marginal probabilities for a variable, either click on the variable in the graph to the left, or choose it from
        the scrolling menu at the top of the window. At the moment, they should all be very close to the marginal
        probabilities taken from the instantiated model.</p>

    <p>Now, we’ll return to the original window. We can do so by clicking “Edit Evidence” under the Evidence tab.
        Suppose we know that X1 takes on the value 1 in our model, or suppose we merely want to see how X1 taking that
        value affects the values of the other variables. We can click on the box that says “1” next to X1. When we click
        “Do Update Now,” we again get a list of the marginal probabilities for X1.</p>

    <img src="images/updater_box_4.png" alt="" width="360">

    <p>Now that we have added evidence, the “red line” marginal probabilities have changed; for X1, the probability that
        X1=1 is 1, because we’ve told Tetrad that that is the case. Likewise, the probabilities that X1=0 and X1=2 are
        both 0.</p>

    <p>Now, let’s look at the updated marginal probabilities for X2, a parent of X1.</p>

    <img src="images/updater_box_5.png" alt="" width="360">

    <img src="images/updater_box_6.png" alt="" width="360">

    <p>The first image is the marginal probabilities before we added the evidence that X1=1. The second image is the
        updated marginal probabilities. They have changed; in particular, it has become much more likely that X2=0.</p>

    <p>Under the Mode tab, we can change the type of information that the updater box gives us. The mode we have been
        using so far is “Marginals Only (Multiple Variables).” We can switch the mode to “In-Depth Information (Single
        Variable).” Under this mode, when we perform the update, we receive more information (such as log odds and
        joints, when supported; joint probabilities are not supported by the approximate updater), but only about the
        variable which was selected in the graph when we performed the update. To view information about a different
        variable, we must re-edit the evidence with that variable selected.</p>

    <p>If the variable can take one of several values, or if we know the values of more than one variable, we can select
        multiple values by pressing and holding the Shift key and then making our selections. For instance, in the model
        above, suppose that we know that X1 can be 1 or 2, but not 0. We can hold the Shift key and select the boxes for
        1 and 2, and when we click “Do Update Now,” the marginal probabilities for X2 look like this: </p>

    <img src="images/updater_box_7.png" alt="" width="650">

    <p>Since X1 must be 1 or 2, the updated probability that it is 0 is now 0. The marginal probabilities of X2 also
        change: </p>

    <img src="images/updater_box_8.png" alt="" width="650">

    <p>The updated marginal probabilities are much closer to their original values than they were when we knew that X1
        was 1.</p>

    <p>Finally, if we are arbitrarily setting the value of a variable—that is, the values of its parents have no effect
        on its value—we can check the “Manipulated” box next to it while we are we editing evidence, and the update will
        reflect this information.</p>

    <p>Note that multiple values cannot be selected for evidence for SEM models.</p>

    <h2>Row Summing Exact Updater</h2>

    <p>The row summing exact updater is a slower but more accurate updater than the approximate updater. The complexity
        of the algorithm depends on the number of variables and the number of categories each variable has. It creates a
        full exact conditional probability table and updates from that. Its window functions exactly as the approximate
        updater does, with two exceptions: in “Multiple Variables” mode, you can see conditional as well as marginal
        probabilities, and in “Single Variable” mode, you can see joint values. </p>

    <h2>CPT Invariant Exact Updater</h2>

    <p>The CPT invariant exact updater is more accurate than the approximate updater, but slightly faster than the row
        summing exact updater. Ifs window functions exactly as the approximate updater down, with one exception: in
        “Multiple Variables” mode, you can see conditional as well as marginal probabilities.</p>

    <h2>SEM Updater</h2>

    <p>The SEM updater does not deal with marginal probabilities; instead, it estimates means.</p>


    <img src="images/updater_box_9.png" alt="" width="360">

    <p>When it is input to the SEM updater, the following window results: </p>

    <img src="images/updater_box_10.png" alt="" width="650">

    <p>Suppose we know that the mean of X1 is .5. When we enter that value into the text box on the left and click “Do
        Update Now,” the model on the right updates to reflect that mean, changing the means of both X1 and several
        other variables. In the new model, the means of X2, X4, and X5 will all have changed. If we click the
        “Manipulated” check box as well, it means that we have arbitrarily set the mean of X1 to .5, and that the value
        of its parent variable, X4, has no effect on it. The graph, as well as the updated means, changes to reflect
        this.</p>

    <p>The rest of the window has the same functionality as a SEM instantiated model window, except as noted above.</p>


    <!-- Disabled on 4/2/2019
<h1 id="classify_box"><span  class="section_heading">Classify Box</span></h1>

<p>The classify box takes as input a categorical data set and a Bayes instantiated model and, for a given variable, tries to predict that variable’s value in each case based on the other variables’ values in that case.</p>

<h2>Possible Parents Boxes of the Classify Box: </h2>

<ul class="ul">
<li>An instantiated model box</li>
<li>A data box</li>
<li>A simulation box</li>
</ul>

<h2>Possible Child Boxes of the Classify Box: </h2>

<ul class="ul">
<li>None</li>
</ul>


<h2>Using the Classify Box:</h2>

<p>Consider the following instantiated model, and a data set derived from it:</p>

<img src="images/classify_box_1.png" alt="" width="650">

<p>When they are input to the classify box, the following window results: </p>

<img src="images/classify_box_2.png" alt="" width="650">

<p>By clicking on the “Test Data” tab, we can see the data set which we input. Now, suppose we want to predict the values of X1 in each case. We select X1 from the scrolling menu at the top and click “Classify.” Three new tabs now appear: “Classification,” “ROC Plot,” and “Confusion Matrix.”  The classification tab, in this case, looks like this: </p>

<img src="images/classify_box_3.png" alt="" width="650">


<p>There is a column for each of the possible values which X1 can take, and for each case, Tetrad has computed the probability that X1 will take each value, based on the configuration of other variables in that case. It then chooses the category with the highest conditional probability, and assigns X1 that value for that case. Comparison to the test data will show that the values are reasonably (though not completely) similar.</p>

<p>The ROC plot tab displays the receiver operating characteristic (ROC) curve for whichever value you specified before classification.</p>

<p>The confusion matrix tab provides information on how similar the estimated values of the target variable are to the true values (if the true values are available). </p>

<p>Because classification is a form of estimation, the variable which is classified does not have to be in the input data set; it merely has to be in the input instantiated model. In this case, the ROC plot and confusion matrix tabs will not appear.</p>
-->


    <h1 id="knowledge_box"><span class="section_heading">Knowledge Box</span></h1>

    <p>The knowledge box takes as input a graph or a data set and imposes additional constraints onto it, to aid with
        search.</p>

    <h2>Possible Parent Boxes of the Knowledge Box:</h2>

    <ul class="ul">
        <li>A graph box</li>
        <li>A parametric model box</li>
        <li>An instantiated model box</li>
        <li>A data box</li>
        <li>A simulation box</li>
        <li>A search box</li>
        <li>Another knowledge box</li>
    </ul>

    <h2>Possible Child Boxes of the Knowledge Box:</h2>

    <ul class="ul">
        <li>A search box</li>
        <li>Another knowledge box</li>
    </ul>

    <h2>Tiers and Edges</h2>

    <p>The tiers and edges option allows you to sort variables into groupings that can or cannot affect each other. It
        also allows you to manually add forbidden and required edges one at a time.</p>

    <h3>Tiers</h3>

    <p>The tiers tab for a graph with ten variables looks like this: </p>

    <img src="images/knowledge_box_1.png" alt="" width="650">

    <p>Tiers separate your variables into a time line. Variables in higher-numbered tiers occur later than variables in
        lower-numbered tiers, which gives Tetrad information about causation. For example, a variable in Tier 3 could
        not possibly be a cause of a variable in Tier 1.</p>

    <p>To place a variable in a tier, click on the variable in the “Not in tier” box, and then click on the box of the
        tier. If you check the “Forbid Within Tier” box for a tier, variables in that tier will not be allowed to be
        causes of each other. To increase or decrease the number of tiers, use the scrolling box in the upper right
        corner of the window.</p>

    <p>You can quickly search, select and place variables in a tier using the Find button associated with each tier.
        Enter a search string into the Find dialogue box using asterisks as wildcard indicators. E.g., "X1*" would find
        and select variables X1 and X10.</p>

    <p>You can also limit the search such that edges from one tier only are added to the next immediate tier e.g,. if
        Tier 1 "Can cause only next tier" is checked then edges from variables in Tier 1 to variables in Tier 3 are
        forbidden.</p>

    <h3>Groups</h3>

    <p>The groups tab for a graph with four variables looks like this: </p>

    <img src="images/knowledge_box_2.png" alt="" width="650">

    <p>In the groups tab, you can specify certain groups of variables which are forbidden or required to cause other
        groups of variables. To add a variable to the “cause” section of a group, click on the variable in the box at
        the top, and then click on the box to the left of the group’s arrow. To add a variable to the “effect” section
        of a group, click on the variable in the box at the top, and then click on the box to the right of the group’s
        arrow. You can add a group by clicking on one of the buttons at the top of the window, and remove one by
        clicking the “remove” button above the group’s boxes.</p>

    <h3>Edges</h3>

    <p>The edges tab for a graph with four variables looks like this: </p>

    <img src="images/knowledge_box_3.png" alt="" width="650">

    <p>In the edges tab, you can require or forbid individual causal edges between variables. To add an edge, click the
        type of edge you’d like to create, and then click and drag from the “cause” variable to the “effect”
        variable.</p>

    <p>You can also use this tab to see the effects of the knowledge you created in the other tabs by checking and
        unchecking the boxes at the bottom of the window. You can adjust the layout to mimic the layout of the source
        (by clicking “source layout”) or to see the variables in their timeline tiers (by clicking “knowledge
        layout”).</p>

    <h2>Forbidden Graph</h2>

    <p>If you use a graph as input to a knowledge box with the “Forbidden Graph” operation, the box will immediately add
        all edges in the parent graph as forbidden edges. It will otherwise work like a Tiers and Edges box.</p>

    <h2>Required Graph</h2>

    <p>If you use a graph as input to a knowledge box with the “Required Graph” operation, the box will immediately add
        all edges in the parent graph as required edges. It will otherwise work like a Tiers and Edges box.</p>

    <h2>Measurement Model</h2>

    <p>This option allows you to build clusters for a measurement model. When first opened, the window looks like
        this:</p>

    <img src="images/knowledge_box_4.png" alt="" width="650">

    <p>You can change the number of clusters using the text box in the upper right hand corner. To place a variable in a
        cluster, click and drag the box with its name into the cluster pane. To move multiple variables at once, shift-
        or command-click on the variables, and (without releasing the shift/command button or the mouse after the final
        click) drag. In the search boxes, these variables will be assumed to be children of a common latent cause.</p>


    <h1 id="simulation_box"><span class="section_heading">Simulation Box</span></h1>

    <p>The simulation box takes a graph, parametric model, or instantiated model and uses it to simulate a data set.</p>

    <h2>Possible Parent Boxes of the Simulation Box</h2>

    <ul class="ul">
        <li>A graph box</li>
        <li>A parametric model box</li>
        <li>An instantiated model box</li>
        <li>An estimator box</li>
        <li>A data box</li>
        <li>Another simulation box</li>
        <li>A search box</li>
        <li>An updater box</li>
        <li>A regression box</li>
    </ul>


    <h2>Possible Child Boxes of the Simulation Box</h2>

    <ul class="ul">
        <li>A graph box</li>
        <li>A compare box</li>
        <li>A parametric model box</li>
        <li>An instantiated model box</li>
        <li>An estimator box</li>
        <li>A data box</li>
        <li>Another simulation box</li>
        <li>A search box</li>
        <li>A classify box</li>
        <li>A regression box</li>
        <li>A knowledge box</li>
    </ul>


    <h2>Using the Simulator Box</h2>

    <p>When you first open the simulation box, you will see some variation on this window:</p>

    <img src="images/simulation_box_1.png" alt="" width="650">

    <p>The “True Graph” tab contains the graph from which data is simulated. </p>


    <h3>The Simulation Box with no Input</h3>

    <p>Because it has no input box to create constraints, a parentless simulation box offers the greatest freedom for
        setting the graph type, model type, and parameters of your simulated data. In particular, it is the only way
        that the simulation box will allow you to create a random graph or graphs within the box. (If you are simulating
        multiple data sets, and want to use a different random graph for each one, you can select “Yes” under “Yes if a
        different graph should be used for each run.”) You can choose the type of graph you want Tetrad to create from
        the “Type of Graph” drop-down list.</p>

    <h5>Random Forward DAG</h5>

    <p> This option creates a DAG by randomly adding forward edges (edges that do not point to a variable’s ancestors)
        one at a time. You can specify graph parameters such as number of variables, maximum and minimum degrees, and
        connectedness.</p>

    <h5>Scale Free DAG</h5>

    <p> This option creates a DAG whose variable’s degrees obey a power law. You can specify graph parameters such as
        number of variables, alpha, beta, and delta values.</p>

    <h5>Cyclic, constructed from small loops</h5>

    <p> This option creates a cyclic graph. You can specify graph parameters such as number of variables, maximum and
        average degrees, and the probability of the graph containing at least one cycle.</p>

    <h5>Random One Factor MIM</h5>

    <p> This option creates a one-factor multiple indicator model. You can specify graph parameters such as number of
        latent nodes, number of measurements per latent, and number of impure edges.</p>

    <h5>Random Two Factor MIM</h5>

    <p> This option creates a two-factor multiple indicator model. You can specify graph parameters such as number of
        latent nodes, number of measurements per latent, and number of impure edges.</p>

    <p>In addition to the graph type, you can also specify the type of model you would like Tetrad to simulate.</p>

    <h5>Bayes net</h5>

    <p> Simulates a Bayes instantiated model. You can specify model parameters including maximum and minimum number of
        categories for each variable.</p>

    <h5>Structural Equation Model</h5>

    <p> Simulates a SEM instantiated model. You can specify model parameters including coefficient, variance, and
        covariance ranges.</p>

    <h5>Linear Fisher Model</h5>

    <p>Simulates data using a linear Markov 1 DBN without concurrent edges. The Fisher model suggests that shocks should
        be applied at intervals and the time series be allowed to move to convergence between shocks. This simulation
        has many parameters that can be adjusted, as indicated in the interface. The ones that require some explanation
        are as follows.</p>

    <ul class="ul">
        <li>Low end of coefficient range, high end of coefficient range, low end of variance range, high end of variance
            range. Each variable is a linear function of the parents of the variable (in the previous time lag) plus
            Gaussian noise. The coefficients are drawn randomly from U(a, b) where a is the low end of the coefficient
            range and b is the high end of the coefficient range. Here, a < b. The Gaussian noise is drawn uniformly
            from U(c, d), where c is the low end of the variance range and d is the high end of the variance range.
            Here, c < d.
        </li>
        <li>Yes, if negative values should be considered. If no, only positive values will be recorded. This should not
            be used for large numbers of variables, since it is more difficult to find cases with all positive values
            when the number of variables is large.
        </li>
        <li>Percentage of discrete variables. The model generates continuous data, but some or all of the variables may
            be discretized at random. The user needs to indicate the percentage of variables (randomly chosen that one
            wishes to have discretized. The default is zero—i.e., all continuous variables.
        </li>
        <li>Number of categories of discrete variables. For the variables that are discretized, the number of categories
            to use to discretize each of these variables.
        </li>
        <li>Sample size. The number of records to be simulated.</li>
        <li>Interval between shocks. The number of time steps between shocks in the model.</li>
        <li>Interval between data recordings. The data are recorded every so many steps. If one wishes to allow to
            completely converge between steps (i.e., produce equilibrium data), set this interval to some large number
            like 20 and set the interval between shocks likewise to 20 Other values can be used, however.
        </li>
        <li>Epsilon for convergence. Even if you set the interval between data recordings to a large number, you can
            specify an epsilon such that if all values of variables differ from their values one time step back by less
            than epsilon, the series will be taken to have converged, and the remaining steps between data recordings
            will be skipped, the data point being recorded at convergence.
        </li>
    </ul>

    <h5>Lee &amp; Hastie</h5>

    <p> This is a model for simulating mixed data (data with both continuous and discrete variables. The model is given
        in Lee J, Hastie T. 2013, Structure Learning of Mixed Graphical Models, Journal of Machine Learning Research 31:
        388-396. Here, mixtures of continuous and discrete variables are treated as log-linear.</p>

    <ul class="ul">
        <li>Percentage of discrete variables. The model generates continuous data, but some or all of the variables may
            be discretized at random. The user needs to indicate the percentage of variables (randomly chosen that one
            wishes to have discretized. The default is zero—i.e., all continuous variables.
        </li>
        <li>Number of categories of discrete variables. For the variables that are discretized, the number of categories
            to use to discretize each of these variables.
        </li>
        <li>Sample size. The number of records to be simulated.</li>
    </ul>

    <h5>Time Series</h5>

    <p> This is a special simulation for representing time series. Concurrent edges are allowed. This can take a Time
        Series Graph as input, in which variables in the current lag are written as functions of the parents in the
        current and previous lags.</p>

    <ul class="ul">
        <li>Sample size. The number of records to be simulated.</li>
    </ul>

    <h5>Boolean Glass</h5>

    <p> The instantiated model used to simulate the data will be re-parameterized for each run of the simulation.</p>


    <h3>The Simulation Box with a Graph Input</h3>

    <p>If you input a graph, you will be able to simulate any kind of model, with any parameters. But the model will be
        constrained by the graph you have input (or the subgraph you choose in the “True Graph” tab.) Because of this,
        if you create a simulation box with a graph as a parent, you will not see the “Type of Graph” option.</p>

    <h3>The Simulation Box with a Parametric Model Input</h3>

    <p>At the time of writing, a simulation box with a parametric model input acts as though the PM’s underlying graph
        had been input into the box.</p>


    <h3>The Simulation Box with an Instantiated Model Input</h3>

    <p>If you input an instantiated model, your only options will be the sample size of your simulation and the number
        of data sets you want to simulate; Tetrad will simulate every one of them based on the parameters of the IM. The
        model will not be re-parameterized for each run of the simulation.</p>


    <h1 id="search_box"><span class="section_heading">Search Box</span></h1>

    <p>The search box takes as input a data set (in either a data or simulation box) and optionally a knowledge box, and
        searches for causal explanations represented by directed graphs. The result of a search is not necessarily—and
        not usually—a unique graph, but an object such as a pattern that represents a set of graphs, usually a Markov
        Equivalence class. More alternatives can be found by varying the parameters of search algorithms.</p>

    <h2>Possible Parent Boxes of the Search Box</h2>

    <ul class="ul">
        <li>A graph box</li>
        <li>A parametric model box</li>
        <li>An instantiated model box</li>
        <li>An estimator box</li>
        <li>A data box</li>
        <li>A simulation box</li>
        <li>Another search box</li>
        <li>A regression box</li>
        <li>A knowledge box</li>
    </ul>


    <h2>Possible Child Boxes of the Simulation Box</h2>

    <ul class="ul">
        <li>A graph box</li>
        <li>A compare box</li>
        <li>A parametric model box</li>
        <li>A simulation box</li>
        <li>Another search box</li>
        <li>A knowledge box</li>
    </ul>

    <h2>Using the Search Box</h2>

    <p>Using the search box requires you to select an algorithm (optionally select a test/score), confirm/change search
        parameters and finally run the search.</p>

    <img src="images/search_box_1.png" alt="" width="650">

    <p>The search box first asks what algorithm, statistical tests and/or scoring functions you would like to use in the
        search. The upper left panel allows you to filter for different types of search algorithms with the results of
        filtering appearing in the middle panel. Selecting a particular algorithm will update the algorithm description
        on the right panel.</p>

    <p>Choosing the correct algorithm for your needs is an important consideration. Tetrad provides over 30 search
        algorithms (and more are added all of the time) each of which makes different assumptions about the input data,
        uses different parameters, and produces different kinds of output. For instance, some algorithms produce Markov
        blankets or patterns, and some produce full graphs; some algorithms work best with Gaussian or non-Gaussian
        data; some algorithms require an alpha value, some require a penalty discount, and some require both or neither.
        You can narrow down the list using the “Algorithm filter" panel, which allows you to limit the provided
        algorithms according to whichever factor is important to you.</p>

    <p>Depending on the datatype used as input for the search (i.e., continuous, discrete, or mixed data) and algorithm
        selected, the lower left panel will display available statistical tests (i.e., tests of independence) and
        Bayesian scoring functions.</p>

    <p>After selecting the algorithm and desired test/score, click on "Set parameters" which will allow you to
        confirm/change the parameters of the search. </p>

    <p>After optionally changing any search paramaters, click on "Run Search and Generate Graph" which will execute the
        search</p>


    <h2>Search Algorithms</h2>

    <h3>Variants of PC</h3>
    <h3>The PC Algorithm</h3>

    <h4>Description</h4>

    <div id="pc-all">

        <p>PC algorithm (Spirtes and Glymour, Social Science Computer Review, 1991) is a pattern search which assumes
            that the underlying causal structure of the input data is acyclic, and that no two variables are caused by
            the same latent (unmeasured) variable. In addition, it is assumed that the input data set is either entirely
            continuous or entirely discrete; if the data set is continuous, it is assumed that the causal relation
            between any two variables is linear, and that the distribution of each variable is Normal. Finally, the
            sample should ideally be i.i.d.. Simulations show that PC and several of the other algorithms described here
            often succeed when these assumptions, needed to prove their correctness, do not strictly hold. The PC
            algorithm will sometimes output double headed edges. In the large sample limit, double headed edges in the
            output indicate that the adjacent variables have an unrecorded common cause, but PC tends to produce false
            positive double headed edges on small samples.</p>

        <p>The PC algorithm is correct whenever decision procedures for independence and conditional independence are
            available. The procedure conducts a sequence of independence and conditional independence tests, and
            efficiently builds a pattern from the results of those tests. As implemented in TETRAD, PC is intended for
            multinomial and approximately Normal distributions with i.i.d. data. The tests have an alpha value for
            rejecting the null hypothesis, which is always a hypothesis of independence or conditional independence. For
            continuous variables, PC uses tests of zero correlation or zero partial correlation for independence or
            conditional independence respectively. For discrete or categorical variables, PC uses either a chi square or
            a g square test of independence or conditional independence (see Causation, Prediction, and Search for
            details on tests). In either case, the tests require an alpha value for rejecting the null hypothesis, which
            can be adjusted by the user. The procedures make no adjustment for multiple testing. (For PC, CPC, JPC,
            JCPC, FCI, all testing searches.) </p>

    </div>

    <h4>Input Assumptions</h4>

    <p>The algorithm effectively takes conditional independence facts as input. Thus it will work for any type of data
        for which a conditional independence facts are known. In the interface, it will work for linear, Gaussian data
        (the Fisher Z test), discrete multinomial data the Chi Square test) and mixed multinomial/Gaussian data (the
        Conditional Gaussian test).</p>

    <h4>Output Format</h4>

    <p>The graph outputs a pattern (or CP-DAG). This is an equivalence class of directed acyclic graphs (DAGs). Each DAG
        in the equivalence class has all of the adjacencies (and no more) of the pattern. Each oriented edge in the
        pattern is so oriented in each of the DAG in the equivalence class. Unoriented edges in the equivalence class
        cannot be oriented by conditional independence facts. For example, if the model is X->Y->Z, the output will be
        X—Y—Z. There are not collider in this model, so the algorithm will not detect one. Since there are not
        colliders, the Meek cannot orient additional edges. If the model were X<-Y<-Z, the output would also be X—Y—Z;
        this model is in the same equivalence class as X->Y->Z. The model X->Y<-Z would be its own equivalence class,
        since the collider in this model can be oriented. See Spirtes et al. (2000) for more details.</p>

    <h4>Parameters</h4>

    <p><a href="#alpha">alpha</a>, <a href="#depth">depth</a></p>

    <h3>The CPC Algorithm</h3>

    <h4>Description</h4>

    <div id="cpc">

        <p>The CPC (Conservative PC) algorithm (Ramsey et al., ??) modifies the collider orientation step of PC to make
            it more conservative—that is, to increase the precision of collider orientations at the expense of recall.
            It does this as follows. Say you want to orient X—Y—Z as a collider or a noncollider; the PC algorithm looks
            at variables adjacent to X or variables adjacent to Z to find a subset S such that X is independent of Z
            conditional on S. The CPC algorithm considers all possible such sets and records the set on which X is
            conditionally independent of Z. If all of these sets contain Y, it orients X—Y—Z as a noncollider. If none
            of them contains Z, if orient X—Y—Z as a collider. If some contain Z but other don’t, it marks it as
            ambiguous, with an underline. Thus, the output is ambiguous between patterns; in order to get a specific
            pattern out of the output, one needs first to decide whether the underlined triples are colliders or
            noncolliders and then to apply the orientation rules in Meek (1997).</p>

        <p>The PC algorithm is correct whenever decision procedures for independence and conditional independence are
            available. The procedure conducts a sequence of independence and conditional independence tests, and
            efficiently builds a pattern from the results of those tests. As implemented in TETRAD, PC is intended for
            multinomial and approximately Normal distributions with i.i.d. data. The tests have an alpha value for
            rejecting the null hypothesis, which is always a hypothesis of independence or conditional independence. For
            continuous variables, PC uses tests of zero correlation or zero partial correlation for independence or
            conditional independence respectively. For discrete or categorical variables, PC uses either a chi square or
            a g square test of independence or conditional independence (see Causation, Prediction, and Search for
            details on tests). In either case, the tests require an alpha value for rejecting the null hypothesis, which
            can be adjusted by the user. The procedures make no adjustment for multiple testing. (For PC, CPC, JPC,
            JCPC, FCI, all testing searches.) </p>

    </div>

    <h4>Input Assumptions</h4>

    <p>Same as for PC.</p>

    <h4>Output Format</h4>

    <p>An e-pattern (extended pattern), consistent of directed and undirected edges where some of the triple may have
        been marked with underlines to indicate ambiguity, as above. It may be that bidirected edges are oriented as
        X->Y<->X<-W if two adjacent colliders are oriented; this is not ruled out.</p>

    <h4>Parameters</h4>

    <p><a href="#alpha">alpha</a>, <a href="#depth">depth</a></p>

    <h3>The PCStable Algorithm</h3>

    <h4>Description</h4>

    <div id="pc-stable">

        <p>See Drton and Maathuis (2017). The idea is to modify the adjacency search of PC so that if the order of the
            variables is randomized, the adjacency output is not affected.
            This is done as follows. The order of operations for the step where unconditional independencies are
            calculated is not affected; these may be done in any order.
            However, for the step in which one conditions on one variable, the output of that step could be affected by
            the order in which the operations are done.
            So instead of removing edges in this step, one simply records which edges one would remove, and then at the
            end of the step removes them all.
            Similarly for subsequence steps. In this way, the adjacencies of variables in the output of the adjacency
            step are fixed no matter the order
            in which the operations are visited. One them does collider orientation and applies the orientation rules in
            Meek (1997);
            there may be orientation differences from one run to the next still, if the order of the variables in the
            dataset is modified.</p>
    </div>

    <h4>Input Assumptions</h4>

    <p>Same as for PC.</p>

    <h4>Output Format</h4>

    <p>Same as for PC.</p>

    <h4>Parameters</h4>

    <p><a href="#alpha">alpha</a>, <a href="#depth">depth</a></p>

    <h3>The CPCStable Algorithm</h3>

    <h4>Description</h4>

    <div id="cpc-stable">

        <p>CPC, with the PC-Stable adjacency step substituted for the PC adjacency search.</p>

    </div>

    <h4>Input Assumptions</h4>

    <p>Same as for PC.</p>

    <h4>Output Format</h4>

    <p>Same as for CPC (an e-pattern).</p>

    <h4>Parameters</h4>

    <p><a href="#alpha">alpha</a>, <a href="#depth">depth</a></p>

    <h3>The PcMax Algorithm</h3>

    <h4>Description</h4>

    <div id="cpc-stable">

        <p>Similar in spirit to CPC but orients all unshielded triples using maximum likelihood conditioning sets. The
            idea is as follows. The adjacency search is the same as for PC, but colliders are oriented differently. Let
            X—Y—Z be an unshielded triple (X not adjacent to Z) and find all subsets S from among the adjacents of X or
            the adjacents of Z such that X is independent of Z conditional on S. However, instead of using the CPC rule
            to orient the triple, instead just list the p-values for each of these conditional independence judgments
            and pick the set S’ that yields the highest such p-value. Then orient X->Y<-Z if S does not contain Y and
            X—Y—Z otherwise. This orients all unshielded triples. It’s possible (though rare) that adjacent triples both
            both be oriented as 2-cycles, X->Y<->Z<-W. If this happens, pick one of the other of these triples or orient
            as a collider, arbitrarily. This guarantees that the resulting graph will be a pattern.</p>

    </div>

    <h4>Input Assumptions</h4>

    <p>Same as for PC.</p>

    <h4>Output Format</h4>

    <p>Same as PC, a pattern.</p>

    <h4>Parameters</h4>

    <p><a href="#alpha">alpha</a>, <a href="#depth">depth</a>, <a href="#useMaxPOrientationHeuristic">useMaxPOrientationHeuristic</a>,
        <a href="#maxPOrientationMaxPathLength">maxPOrientationMaxPathLength</a></p>

    <h3>The FGES Algorithm</h3>

    <h4>Description</h4>

    <div id="fges">

        <p>
            FGES is an optimized and parallelized version of an algorithm developed by Meek
            [Meek, 1997] called the Greedy Equivalence Search (GES). The algorithm was further developed
            and studied by Chickering [Chickering, 2002]. GES is a Bayesian algorithm that heuristically
            searches the space of CBNs and returns the model with highest Bayesian score it finds. In
            particular, GES starts its search with the empty graph. It then performs a forward stepping search in
            which edges are added between nodes in order to increase the Bayesian score. This process
            continues until no single edge addition increases the score. Finally, it performs a backward
            stepping search that removes edges until no single edge removal can increase the score. For more
            information see
            https://www.ccd.pitt.edu//wp-content/uploads/2018/10/FGES1c-user-documentation-5_21_2016-sample-size.pdf and
            https://www.ccd.pitt.edu//wp-content/uploads/2018/10/FGES1d-user-documentation-7_20_2016-sample-size.pdf.
            The reference is Ramsey et al., 2017.
        </p>

        <p>
            The algorithms requires a decomposable score—that is, a score that for the entire DAG model is a
            sum of logged scores of each variables given its parents in the model. The algorithms can take all
            continuous data (using the SEM BIC score), all discrete data (using the BDeu score) or a mixture
            of continuous and discrete data (using the Conditional Gaussian score); these are all decomposable
            scores.
        </p>

    </div>

    <h4>Input Assumptions</h4>

    <p>Data that’s all continuous, all discrete, or a mixture of continuous and discrete
        variables. Continuous variables will be assumed to be linearly associated; discrete variable will be
        assumed to be associated by multinomial conditional probability tables. Continuous variables for
        the mixed case will be assumed to be jointly Gaussian.</p>

    <h4>Output Format</h4>

    <p>A pattern, same as PC.</p>


    <h4>Parameters</h4>

    <p><a href="#samplePrior">samplePrior</a>, <a href="#structurePrior">structurePrior</a>, <a href="#penaltyDiscount">penaltyDiscount</a>,
        <a href="#symmetricFirstStep">symmetricFirstStep</a>, <a href="#faithfulnessAssumed">faithfulnessAssumed</a>, <a
                href="#maxDegree">maxDegree</a></p>


    <h3>The IMaGES Discrete Algorithm (BDeu Score)</h3>

    <h4>Description</h4>

    <div id="imgs_disc">

        <p>Adjusts the discrete BDeu variable score of FGES so allow for multiple datasets as input. The BDeu scores for
            each data set are averaged at each step of the algorithm, producing a model for al data sets that assumes
            they have the same graphical structure across dataset. Note that in order to use this algorithm in a
            nontrivial way, one needs to have loaded or simulated multiple dataset.</p>

    </div>

    <h4>Input Assumptions</h4>

    <p>A set of discrete datasets with the same variables and sample sizes.</p>

    <h4>Output Format</h4>

    <p>A pattern, interpreted as a common model for all datasets.</p>

    <h4>Parameters</h4>

    <p>All of the parameters from FGES are available for IMaGES. Additionally:</p>

    <p><a href="#numRuns">numRuns</a>, <a href="#randomSelectionSize">randomSelectionSize</a></p>


    <h3>The IMaGES Continuous Algorithm (SEM BIC Score)</h3>

    <h4>Description</h4>

    <div id="imgs_cont">

        <p>Adjusts the continuous variable score (SEM BIC) of FGES so allow for multiple datasets as input.
            The linear, Gaussian BIC scores for each data set are averaged at each step of the algorithm, producing a
            model for all data sets that
            assumes they have the same graphical structure across dataset.</p>

    </div>

    <h4>Input Assumptions</h4>

    <p>A set of continuous datasets with the same variables and sample sizes.</p>

    <h4>Output Format</h4>

    <p>A pattern, interpreted as a common model for all datasets.</p>

    <h4>Parameters</h4>

    <p>All of the parameters from FGES are available for IMaGES. Additionally:</p>

    <p><a href="#numRuns">numRuns</a>, <a href="#randomSelectionSize">randomSelectionSize</a></p>


    <h3>The FCI Algorithm</h3>

    <h4>Description</h4>

    <div id="fci">

        <p>The FCI algorithm is a constraint-based algorithm that takes as input sample data and optional background
            knowledge and in the large sample limit outputs an equivalence class of CBNs that
            (including those with hidden confounders) that entail the set of conditional independence relations judged
            to hold in the population.
            It is limited to several thousand variables, and on realistic sample sizes it is inaccurate in both
            adjacencies and orientations.
            FCI has two phases: an adjacency phase and an orientation phase. The adjacency phase of the algorithm starts
            with a complete undirected graph and then
            performs a sequence of conditional independence tests that lead to the removal of an edge between any two
            adjacent variables that are judged to be independent,
            conditional on some subset of the observed variables; any conditioning set that leads to the removal of an
            adjacency is stored.
            After the adjacency phase, the resulting undirected graph has the correct set of adjacencies, but all of the
            edges are unoriented.
            FCI then enters an orientation phase that uses the stored conditioning sets that led to the removal of
            adjacencies to orient as many of the edges as possible. See [Spirtes, 1993].</p>

    </div>

    <h4>Input Assumptions</h4>

    <p>The data are continuous, discrete, or mixed.</p>

    <h4>Output Format</h4>

    <p>A partial ancestral graph (see Spirtes et al., 2000).</p>

    <h4>Parameters</h4>

    <p>All of the parameters from FCI are below.</p>

    <p><a href="#depth">depth</a>, <a href="#maxPathLength">maxPathLength</a>, <a href="#completeRuleSetUsed">completeRuleSetUsed</a>
    </p>

    <h3>The RFCI Algorithm</h3>

    <h4>Description</h4>

    <div id="rfci">

        <p>A modification of the FCI algorithm in which some expensive steps are finessed and the output is somewhat
            differently interpreted.
            In most cases this runs faster than FCI (which can be slow in some steps) and is almost as informative. See
            Colombo et al., 2012.</p>

    </div>

    <h4>Input Assumptions</h4>

    <p>Data for which a conditional independence test is available.</p>

    <h4>Output Format</h4>

    <p>A partial ancestral graph (PAG). See Spirtes et al., 2000.</p>

    <h4>Parameters</h4>

    <p>All of the parameters from FCI are available for RFCI. Additionally:</p>

    <p><a href="#depth">depth</a>, <a href="#maxPathLength">maxPathLength</a>, <a href="#completeRuleSetUsed">completeRuleSetUsed</a>
    </p>


    <h3>The RFCI-BSC Algorithm</h3>

    <h4>Description</h4>

    <div id="rfci-bsc">

        <p>RFCI-BSC is a combination of the RFCI [Colombo, 2012] algorithm and the Bayesian Scoring of Constraints (BSC)
            method [Jabbari, 2017] that
            can generate and probabilistically score multiple models, outputting the most probable one.
            This search algorithm is a hybrid method that derives a Bayesian probability that
            the set of independence tests associated with a given causal model are jointly correct.
            Using this constraint-based scoring method, we are able to score multiple causal models, which possibly
            contain latent variables,
            and output the most probable one. See [Jabbari, 2017].</p>

    </div>

    <h4>Input Assumptions</h4>

    <p>The data are discrete only.</p>

    <h4>Output Format</h4>

    <p>A partial ancestral graph (PAG). See Spirtes et al., 2000.</p>

    <h4>Parameters</h4>

    <p>All of the parameters from RFCI are available for RFCI-BSC. Additionally:</p>

    <p><a href="#numRandomizedSearchModels">numRandomizedSearchModels</a>, <a href="#thresholdNoRandomDataSearch">thresholdNoRandomDataSearch</a>,
        <a href="#cutoffDataSearch">cutoffDataSearch</a>, <a href="#thresholdNoRandomConstrainSearch">thresholdNoRandomConstrainSearch</a>,
        <a href="#cutoffConstrainSearch">cutoffConstrainSearch</a>, <a href="#numBscBootstrapSamples">numBscBootstrapSamples</a>,
        <a href="#lowerBound">lowerBound</a>, <a href="#upperBound">upperBound</a>, <a href="#outputRBD">outputRBD</a>
    </p>

    <h3>The GFCI Algorithm</h3>

    <h4>Description</h4>

    <div id="gfci">

        <p>GFCI is a combination of the FGES [CCD-FGES, 2016] algorithm and the FCI algorithm [Spirtes, 1993] that
            improves upon the accuracy and efficiency of FCI. In order to understand the basic methodology of GFCI,
            it is necessary to understand some basic facts about the FGES and FCI algorithms.
            The FGES algorithm is used to improve the accuracy of both the adjacency phase and the orientation phase of
            FCI by
            providing a more accurate initial graph that contains a subset of both the non-adjacencies and orientations
            of the final output of FCI.
            The initial set of nonadjacencies given by FGES is augmented by FCI performing a set of conditional
            independence tests that lead to
            the removal of some further adjacencies whenever a conditioning set is found that makes two adjacent
            variables independent.
            After the adjacency phase of FCI, some of the orientations of FGES are then used to provide an initial
            orientation of
            the undirected graph that is then augmented by the orientation phase of FCI to provide additional
            orientations.</p>

    </div>

    <h4>Input Assumptions</h4>

    <p>Same as for FCI.</p>

    <h4>Output Format</h4>

    <p>Same as for FCI.</p>

    <h4>Parameters</h4>

    <p>Uses all of the parameters of FCI (see Spirtes et al., 1993) and FGES (see CCD-FGES et al., 2016).</p>


    <h3>The TsFCI Algorithm</h3>

    <h4>Description</h4>

    <div id="tsfci">

        <p>The tsGFCI algorithm is a version of GFCI for time series data. See the GFCI documentation for a description
            of the GFCI algorithm,
            which allows for unmeasured (hidden, latent) variables in the data-generating process and produces a PAG
            (partial ancestral graph).
            tsGFCI takes as input a “time lag data set,” i.e., a data set which includes time series observations of
            variables X1, X2, X3, ...,
            and their lags X1:1, X2:1, X3:1, ..., X1:2, X2:2,X3:2, ... and so on. X1:n is the nth-lag of the variable
            X1.
            To create a time lag data set from a standard tabular data set (i.e., a matrix of observations of X1, X2,
            X3, ...),
            use the “create time lag data” function in the data manipulation toolbox. The user will be prompted to
            specify the number of lags (n),
            and a new data set will be created with the above naming convention. The new sample size will be the old
            sample size minus n.</p>

    </div>

    <h4>Input Assumptions</h4>

    <p>The (continuous) data has been generated by a time series.</p>

    <h4>Output Format</h4>

    <p>(Need to get this from Dan.)</p>

    <h4>Parameters</h4>

    <p><a href="#alpha">alpha</a></p>


    <h3>The TsGFCI Algorithm</h3>

    <h4>Description</h4>

    <div id="ts-gfci">

        <p>tsGFCI uses a BIC score to search for a skeleton. Thus, the only user-specified parameter is an optional
            “penalty score” to bias the search
            in favor of more sparse models. See the description of the GES algorithm for discussion of the penalty
            score.
            For the traditional definition of the BIC score, set the penalty to 1.0. The orientation rules are the same
            as for FCI.
            As is the case with tsFCI, tsGFCI will automatically respect the time order of the variables and impose a
            repeating structure.
            Firstly, it puts lagged variables in appropriate tiers so, e.g., X3:2 can cause X3:1 and X3 but X3:1 cannot
            cause X3:2 and X3 cannot cause either X3:1 or X3:2.
            Also, it will assume that the causal structure is the same across time, so that if the edge between X1 and
            X2 is removed because this increases the BIC score,
            then also the edge between X1:1 and X2:1 is removed, and so on for additional lags if they exist.
            When some edge is removed as the result of a score increase, all similar (or “homologous”) edges are also
            removed.
        </p>

    </div>

    <h4>Input Assumptions</h4>

    <p>The (continuous) data has been generated by a time series.</p>

    <h4>Output Format</h4>

    <p>(Need to get this from Dan.)</p>

    <h4>Parameters</h4>

    <p>Uses all of the parameters of FCI (see Spirtes et al., 1993) and FGES (see CCD-FGES et al., 2016).</p>


    <h3>The TsIMaGES Algorithm</h3>

    <h4>Description</h4>

    <div id="ts-imgs">

        <p>tsIMAGES is a version of tsGFCI which averages BIC scores across multiple data sets. Thus, it is used to
            search for a PAG (partial ancestral graph)
            from time series data from multiple units (subjects, countries, etc). tsIMAGES allows both for unmeasured
            (hidden, latent) variables
            and the possibility that different subjects have different causal parameters, though they share the
            same qualitative causal structure. As with IMAGES, the user can specify a “penalty score” to produce more
            sparse models.
            For the traditional definition of the BIC score, set the penalty to 1.0.
            See the documentation for IMAGES and tsGFCI.

        </p>

    </div>

    <h4>Input Assumptions</h4>

    <p>The (continuous) data has been generated by a time series.</p>

    <h4>Output Format</h4>

    <p>(Need to get this from Dan.)</p>

    <h4>Parameters</h4>

    <p>Uses the parameters of IMaGES.</p>

    <h3>The FGES-MB Algorithm</h3>

    <h4>Description</h4>

    <div id="fges-mb">

        <p>This is a restriction of the FGES algorithm to union of edges over the combined Markov blankets of a set of
            targets, including the targets.
            In the interface, just one target may be specified. See Ramsey et al., 2017 for details. In the general
            case,
            finding the graph over the Markov blanket variables of a target (including the target) is far faster than
            finding the pattern for all of the variables.</p>

    </div>

    <h4>Input Assumptions</h4>

    <p>The same as FGES</p>

    <h4>Output Format</h4>

    <p>A graph over a selected group of nodes that includes the target and each node in the Markov blanket of the
        target.
        This will be the same as if FGES were run and the result restricted to just these variables,
        so some edges may be oriented in the returned graph that may not have been oriented in a pattern over the
        selected nodes.</p>

    <h4>Parameters</h4>

    <p>Uses the parameters of FGES (see CCD-FGES et al., 2016). </p>

    <p><a href="#targetName">targetName</a></p>

    <h3>The MBFS Algorithm</h3>

    <h4>Description</h4>

    <div id="mbfs">

        <p>Markov blanket fan search. Similar to FGES-MB (see CCD-FGES, 2016) but using PC as the basic search instead
            of FGES.
            The rules of the PC search are restricted to just the variables in the Markov blanket of a target T,
            including T;
            the result is a graph that is a pattern over these variables.</p>

    </div>

    <h4>Input Assumptions</h4>

    <p>Same as for PC</p>

    <h4>Output Format</h4>

    <p>A pattern over a selected group of nodes that includes the target and each node in the Markov blanket of the
        target.</p>

    <h4>Parameters</h4>

    <p>Uses the parameters of PC.</p>

    <p><a href="#targetName">targetName</a></p>


    <h3>The FAS Algorithm</h3>

    <h4>Description</h4>

    <div id="fas">

        <p>This is just the adjacency search of the PC algorithm, included here for times when just the adjacency search
            is needed,
            as when one is subsequently just going to orient variables pairwise.</p>

    </div>

    <h4>Input Assumptions</h4>

    <p>Same as for PC</p>

    <h4>Output Format</h4>

    <p>An undirected graph over the variables of the input dataset. In particular, parents of a variables are not
        married by FAS,
        so the resulting graph is not a Markov random field. For example, if X->Y<-Z, the output will be X—Y—Z with X—Z.
        The parents of Y will be joined by an undirected edge, morally, only if they are joined by a trek in the true
        graph.</p>

    <h4>Parameters</h4>

    <p><a href="#alpha">alpha</a>, <a href="#depth">depth</a></p>

    <h3>The MGM Algorithm</h3>

    <h4>Description</h4>

    <div id="mgm">

        <p>Need reference. Finds a Markov random field (with parents married) for a dataset in which continuous and
            discrete variables are mixed together.
            For example, if X->Y<-Z, the output will be X—Y—Z with X—Z. The parents of Y will be joined by an undirected
            edge, morally,
            even though this edge does not occur in the true model.</p>

    </div>

    <h4>Input Assumptions</h4>

    <p>Data are mixed.</p>

    <h4>Output Format</h4>

    <p>A Markov random field for the data.</p>

    <h4>Parameters</h4>

    <p><a href="#mgmParam1">mgmParam1</a>, <a href="#mgmParam2">mgmParam2</a>, <a href="#mgmParam3">mgmParam3</a></p>


    <h3>The GLASSO Algorithm</h3>

    <h4>Description</h4>

    <div id="glasso">

        <p>A translation of the Fortran code for GLASSO (Graphical LASSO—see Friedman, Tibshirani anad Hastie, 2007)
            Like MGM, this produces an undirected graph in which parents are always married.</p>

    </div>

    <h4>Input Assumptions</h4>

    <p>The data are continuous.</p>

    <h4>Output Format</h4>

    <p>A Markov random field.</p>

    <h4>Parameters</h4>

    <p><a href="#maxit">maxit</a>, <a href="#ia">ia</a>, <a href="#is">is</a>, <a href="#itr">itr</a>, <a href="#ipen">ipen</a>,
        <a href="#thr">thr</a></p>

    <!-- Disabled on 4/2/2019
<h3>The BPC Algorithm</h3>

<h4>Description</h4>

<div id="bpc">

<p>Searches for causal structure over latent variables, where the true models are Multiple Indicator Models (MIM’s) as described in the Graphs section.
The idea is this. There is a set of latent (unmeasured) variables over which a directed acyclic model has been defined.
Then for each of these latent L there are 3 (preferably 4) or more measures of that variable—that is,
measured variables that are all children of L.
Under these conditions, one may define tetrad constraints (see Spirtes et al., 2000).
There is a theorem to the effect that if certain patterns of these tetrad constraints hold,
there must be a latent common cause of all of them (the Tetrad Representation Theorem, see Silva et al., 2003,
where the BPC (“Build Pure Clusters”) algorithm is defined and discussed.) Moreover, once one has such a “measurement model,”
once can estimate a covariance matrix over the latent variables that are parents of the measures and use some algorithm such as PC or GES to estimate a pattern over the latents.
The algorithm to run PC or GES on this covariance matrix is called MimBuild (“MIM” is the the graph, Multiple Indicator Model; “Build” means build).
In this way, one may recover causal structure over the latents. The more measures one has for each latent, the better the result is, generally.
The larger the sample size the better. One important issue is that the algorithm is sensitive to so-called “impurities”—that is,
causal edges among the measured variables, or between measured variables and unintended latent.
The algorithm will in effect remove one measure in each impure pair from consideration.</p>

</div>

<h4>Input Assumptions</h4>

<p>Continuous data, a collection of measurements in the above sense, excluding the latent variables (which are to be learned).</p>

<h4>Output Format</h4>

<p>For BPC, a measurement model, in the above sense. This is represented as a clustering of variables; it may be inferred that
there is a single latent for each output cluster. For MimBuild, a pattern over the latent variables, one for each cluster.</p>

<h4>Parameters</h4>

<p><a href="#maxit">alpha</a>, <a href="#useWishart">useWishart</a></p>
-->


    <h3>The FOFC Algorithm</h3>

    <h4>Description</h4>

    <div id="fofc">

        <p>Searches for causal structure over latent variables, where the true models are Multiple Indicator Models
            (MIM’s) as described in the Graphs section.
            The idea is this. There is a set of latent (unmeasured) variables over which a directed acyclic model has
            been defined.
            Then for each of these latent L there are 3 (preferably 4) or more measures of that variable—that is,
            measured variables that are all children of L.
            Under these conditions, one may define tetrad constraints (see Spirtes et al., 2000).
            There is a theorem to the effect that if certain patterns of these tetrad constraints hold,
            there must be a latent common cause of all of them (the Tetrad Representation Theorem).
            The FOFC (Find One Factor Clusters) takes advantage of this fact. The basic idea is to build up clusters one
            at a time by adding variables that keep them pure,
            in the sense that all relevant tetrad constraints still hold.
            There are different ways of going about this. One could try to build one cluster up as far as possible,
            then remove all of those variables from the set, and try to make a another cluster using the remaining
            variables (SAG, Seed and Grow).
            Or one can try in parallel to grow all possible clusters and then choose among the grown clusters using some
            criterion such as cluster size (GAP, Grow and Pick).
            In general, GAP is more accurate. The result is a clustering of variables.
            Moreover, once one has such a “measurement model,”
            once can estimate a covariance matrix over the latent variables that are parents of the measures and use
            some algorithm such as PC or GES to estimate a pattern over the latents.
            The algorithm to run PC or GES on this covariance matrix is called MimBuild (“MIM” is the the graph,
            Multiple Indicator Model; “Build” means build).
            In this way, one may recover causal structure over the latents. The more measures one has for each latent,
            the better the result is, generally.
            The larger the sample size the better. One important issue is that the algorithm is sensitive to so-called
            “impurities”—that is,
            causal edges among the measured variables, or between measured variables and unintended latent.
            The algorithm will in effect remove one measure in each impure pair from consideration</p>

    </div>

    <h4>Input Assumptions</h4>

    <p>Continuous data containing as many measures as are available.</p>

    <h4>Output Format</h4>

    <p>For FOFC, a clustering of variables. For MimBuild, a pattern over latents.</p>

    <h4>Parameters</h4>

    <p><a href="#maxit">alpha</a>, <a href="#useWishart">useWishart</a>, <a href="#useGap">useGap</a></p>

    <h3>The FTFC Algorithm</h3>

    <h4>Description</h4>

    <div id="ftfc">

        <p>FTFC (Find Two Factor Clusters) is similar to FOFC, but instead of each cluster having one latent that is the
            parent of all of the measure in the cluster,
            it instead has two such latents. So each measure has two latent parents; these are two “factors.” Similarly
            to FOFC, constraints are checked for,
            but in this case, the constraints must be sextad constraints, and more of them must be satisfied for each
            pure cluster (see Kummerfelt et al., 2014).
            Thus, the number of measures in each cluster, once impure edges have been taken into account, must be at
            least six, preferably more.</p>

    </div>

    <h4>Input Assumptions</h4>

    <p>Continuous data over the measures with at least six variable variables in each cluster once variables involve in
        impure edges have been removed.</p>

    <h4>Output Format</h4>

    <p>A clustering of measures. It may be assumed that each cluster has at least two factors and that the clusters are
        pure.</p>

    <h4>Parameters</h4>

    <p><a href="#maxit">alpha</a>, <a href="#useWishart">useWishart</a>, <a href="#useGap">useGap</a></p>

    <h3>Orientation Algorithms (EB, R1, R2, R3, R4, RSkew, RSkewE, Skew, SkewE)</h3>

    <h4>Description</h4>

    <div id="">

        <p>These are algorithms that orient edges X—Y for continuous variables pairwise based on non-Gaussian
            information.
            (If the variables are all Gaussian, one cannot orient these edges. That is, these rules will orient left or
            right randomly.)
            For EB, RSkew, RSkewE, Skew and SkewE, see Hyvarinen and Smith, 2013. For R1, R2, R3 and R4, see Ramsey et
            al., 2012.</p>

        <p>The principles governing these rules vary.
            R1 and R2 appeal directly to the Central Limit Theorem to judge which of various conditioning sets yields
            the greatest non-Gaussianity measure.
            (The measure for non-Gaussianity measure used is Anderson-Darling.)
            R4 does as well, but allows coefficients for relevant parameters to be adjusted to achieve maximum
            non-Gaussianity.
            EB works by appealing to entropy for the orientation. R3 uses the same rule as EB except using the
            Anderson-Darling score for a measure of non-Gaussianity.
            RSkew and Skew appeal to measures of skew for the variables and assume positive skewness for all variables.
            The rules for the two are different; please see Hyvarinen and Smith for details.
            SkewE and RSkewE adjust the signs of variables by the signs of their skewnesses to ensure that the
            assumption of positive skewness holds.
            A comparison of all of these methods is given in Ramsey et al., 2012.
            In general, for fMRI data, we find that the RSkew method works the best, followed by the R3 method.
            Cycles can be oriented using these methods, since each edge is oriented independently of the others.</p>

    </div>

    <h4>Input Assumptions</h4>

    <p>Continuous data in which the variables are non-Gaussian. Non-Gaussianity can be assessed using the
        Anderson-Darling score, which is available in the Data box.</p>

    <h4>Output Format</h4>

    <p>Orients all of the edges in the input graph using the selected score.</p>

    <h4>Parameters</h4>

    <p><a href="#maxit">alpha</a>, <a href="#depth">depth</a></p>

    <h2>Statistical Tests</h2>

    <h3>CCI</h3>

    <p>CCI (“Conditional Correlation Independence”) is a fairly general independence test—not completely general, but
        general for additive noise models—that is,
        model in which each variable is equal to a (possibly nonlinear) function of its parents, plus additive noise,
        where the noise may be arbitrarily distributed.
        That is, X = f(parent(X)) + E, where f is any function and E is noise however distributed; the only requirement
        is that there be the “+” in the formula separating the function from the noise.
        The noise can’t for instance, be multiplicative, e.g., X = f(parent(X)) x E.
        The goal of the method is to estimate whether X is independent of Y given variables Z, for some X, Y, and Z.
        It works by calculating the residual of X given Z and the residual of Y given Z and looking to see whether those
        two residuals are independent.
        This test may be used with any constraint-based algorithm (PC, FCI, etc.)</p>

    <h3>KCI</h3>

    <p>KCI (“Kernel Conditional Independence”) is a general independence test for model in which X = f(parents(X), eY);
        here, eY does not need to be additive; it can stand in any functional relationships to the other variables. The
        variables may even be discrete.
        The goal of the method is to estimate whether X is independent of Y given Z, completely generally.
        It uses the kernel trick to estimate this.
        As a result of using the kernel trick, the method is complex in the direction of sample size, meaning that it
        may be very slow for large samples.
        Since it’s slow, individual independence results are always printed to the console so the user knows how far a
        procedure has gotten.
        This test may be used with any constraint-based algorithm (PC, FCI, etc.)</p>

    <h3>FASK</h3>

    <p>FASK (“Fast Adjacency Skewness”) assumes that variables are skewed and linearly related, though the linearity may
        be relaxed to monotonicity more generally.
        It assume each variable, specifically, in the base case, is equal to a linear combination of its parents plus
        skewed noise.
        It operates by first estimating an undirected skeleton using both correlational reasoning and reasoning about
        skewnesses,
        then orienting 2-cycles (X->Y and Y->X) in the model, then orienting the rest of the edges in the model left or
        right.
        It scales well and is applicable wherever one has skewed variables and additive noise.</p>

    <h3>Conditional Gaussian Test</h3>

    <p>Conditional Gaussian Test is a likelihood ratio test based on the conditional Gaussian likelihood function.
        This is intended for use with datasets where there is a mixture of continuous and discrete variables.
        It is assumed that the continuous variables are Gaussian conditional on each combination of values for the
        discrete variables,
        though it will work fairly well even if that assumption does not hold strictly. This test may be used with any
        constraint-based algorithm (PC, FCI, etc.)</p>

    <h2>Scoring Functions</h2>

    <div id="parameters">
        <h2>Search Parameters</h2>

        <!-- Insert the parameter descriptions here, must follow the same structure and naming conventions -->


        <h3 id="addOriginalDataset" class="parameter_description">addOriginalDataset</h3>
        <ul class="parameter_description_list">
            <li>Short Description: <span id="addOriginalDataset_short_desc">Yes, if adding an original dataset as another bootstrapping</span>
            </li>
            <li>Long Description: <span id="addOriginalDataset_long_desc">It has been shown that adding in the algorithm result one would get using the original data to those found by the bootstrap method can improve accuracy of summary graphs. Select “Yes” here to include an extra run using the original dataset.</span>
            </li>
            <li>Default Value: <span id="addOriginalDataset_default_value">false</span></li>
            <li>Lower Bound: <span id="addOriginalDataset_lower_bound"></span></li>
            <li>Upper Bound: <span id="addOriginalDataset_upper_bound"></span></li>
            <li>Value Type: <span id="addOriginalDataset_value_type">Boolean</span></li>
        </ul>

        <h3 id="alpha" class="parameter_description">alpha</h3>
        <ul class="parameter_description_list">
            <li>Short Description: <span id="alpha_short_desc">Cutoff for p values (alpha) (min = 0.0)</span></li>
            <li>Long Description: <span id="alpha_long_desc">Statistical tests often compare a test statistic to a distribution and make a judgment that the null hypothesis has been rejected based on whether the area in the tails for the distribution for that test statistic is greater than some cutoff alpha. For tests of independence, for instance, a lower alpha level makes it easier to judge independence, and a higher alpha makes it harder to judge independence. Thus, a lower alpha for a search generally results in a sparser graph.</span>
            </li>
            <li>Default Value: <span id="alpha_default_value">0.01</span></li>
            <li>Lower Bound: <span id="alpha_lower_bound">0.0</span></li>
            <li>Upper Bound: <span id="alpha_upper_bound">1.0</span></li>
            <li>Value Type: <span id="alpha_value_type">Double</span></li>
        </ul>

        <h3 id="applyR1" class="parameter_description">applyR1</h3>
        <ul class="parameter_description_list">
            <li>Short Description: <span id="applyR1_short_desc">Yes if the orient away from arrow rule should be applied</span>
            </li>
            <li>Long Description: <span id="applyR1_long_desc">The Orient Away from Arrow rule is usually applied for PC if there is a structure X->Y—Z to yield X->Y->Z, to avoid the creation of a collider known not to exist. Set this parameter to “No” if a chain of directed edges pointing in the same direction when only the first few such orientations are justified based on the data.</span>
            </li>
            <li>Default Value: <span id="applyR1_default_value">true</span></li>
            <li>Lower Bound: <span id="applyR1_lower_bound"></span></li>
            <li>Upper Bound: <span id="applyR1_upper_bound"></span></li>
            <li>Value Type: <span id="applyR1_value_type">Boolean</span></li>
        </ul>

        <h3 id="avgDegree" class="parameter_description">avgDegree</h3>
        <ul class="parameter_description_list">
            <li>Short Description: <span id="avgDegree_short_desc">Average degree of graph (min = 1)</span></li>
            <li>Long Description: <span id="avgDegree_long_desc">The average degree of a graph is equal to 2E / V, where E is the number of edges in the graph and V the number of variables (vertices) in the graph, since each edge has two endpoints. This allows one to have control over the density of randomly generated graphs. The default average degree is 2, which corresponds to a graph in which there are the same number of edges as nodes. For denser graphs, larger average degrees can be specified.</span>
            </li>
            <li>Default Value: <span id="avgDegree_default_value">2</span></li>
            <li>Lower Bound: <span id="avgDegree_lower_bound">1</span></li>
            <li>Upper Bound: <span id="avgDegree_upper_bound">2147483647</span></li>
            <li>Value Type: <span id="avgDegree_value_type">Integer</span></td>
        </ul>

        <h3 id="basisType" class="parameter_description">basisType</h3>
        <ul class="parameter_description_list">
            <li>Short Description: <span id="basisType_short_desc">Basis type (1 = Polynomial, 2 = Cosine)</span></li>
            <li>Long Description: <span id="basisType_long_desc">For CCI, this determines which basis type will be used (1 = Polynomial, 2 = Cosine)</span>
            </li>
            <li>Default Value: <span id="basisType_default_value">2</span></li>
            <li>Lower Bound: <span id="basisType_lower_bound">1</span></li>
            <li>Upper Bound: <span id="basisType_upper_bound">2</span></li>
            <li>Value Type: <span id="basisType_value_type">Integer</span></td>
        </ul>

        <h3 id="betaLeftValue" class="parameter_description">betaLeftValue</h3>
        <ul class="parameter_description_list">
            <li>Short Description: <span id="betaLeftValue_short_desc">For Beta(x, y), the 'x'</span></li>
            <li>Long Description: <span id="betaLeftValue_long_desc">If the errors are Beta(x, y), this is the “x”. (For Gaussian errors, this is ignored.)</span>
            </li>
            <li>Default Value: <span id="betaLeftValue_default_value">1</span></li>
            <li>Lower Bound: <span id="betaLeftValue_lower_bound">-2147483648</span></li>
            <li>Upper Bound: <span id="betaLeftValue_upper_bound">2147483647</span></li>
            <li>Value Type: <span id="betaLeftValue_value_type">Integer</span></td>
        </ul>

        <h3 id="betaRightValue" class="parameter_description">betaRightValue</h3>
        <ul class="parameter_description_list">
            <li>Short Description: <span id="betaRightValue_short_desc">For Beta(x, y), the 'y'</span></li>
            <li>Long Description: <span id="betaRightValue_long_desc">If the errors are Beta(x, y), this is the “y”. (For Gaussian errors, this is ignored.)</span>
            </li>
            <li>Default Value: <span id="betaRightValue_default_value">5</span></li>
            <li>Lower Bound: <span id="betaRightValue_lower_bound">-2147483648</span></li>
            <li>Upper Bound: <span id="betaRightValue_upper_bound">2147483647</span></li>
            <li>Value Type: <span id="betaRightValue_value_type">Integer</span></td>
        </ul>

        <h3 id="cciScoreAlpha" class="parameter_description">cciScoreAlpha</h3>
        <ul class="parameter_description_list">
            <li>Short Description: <span id="cciScoreAlpha_short_desc">Cutoff for p values (alpha) (min = 0.0)</span>
            </li>
            <li>Long Description: <span id="cciScoreAlpha_long_desc">Alpha level (0 to 1)</span></li>
            <li>Default Value: <span id="cciScoreAlpha_default_value">0.01</span></li>
            <li>Lower Bound: <span id="cciScoreAlpha_lower_bound">0.0</span></li>
            <li>Upper Bound: <span id="cciScoreAlpha_upper_bound">1.0</span></li>
            <li>Value Type: <span id="cciScoreAlpha_value_type">Double</span></li>
        </ul>

        <h3 id="cgExact" class="parameter_description">cgExact</h3>
        <ul class="parameter_description_list">
            <li>Short Description: <span id="cgExact_short_desc">Yes if the exact algorithm should be used for continuous parents and discrete children</span>
            </li>
            <li>Long Description: <span id="cgExact_long_desc">For the conditional Gaussian likelihood, if the exact algorithm is desired for discrete children and continuous parents, set this parameter to “Yes”.</span>
            </li>
            <li>Default Value: <span id="cgExact_default_value">false</span></li>
            <li>Lower Bound: <span id="cgExact_lower_bound"></span></li>
            <li>Upper Bound: <span id="cgExact_upper_bound"></span></li>
            <li>Value Type: <span id="cgExact_value_type">Boolean</span></li>
        </ul>

        <h3 id="coefHigh" class="parameter_description">coefHigh</h3>
        <ul class="parameter_description_list">
            <li>Short Description: <span id="coefHigh_short_desc">High end of coefficient range (min = 0.0)</span></li>
            <li>Long Description: <span id="coefHigh_long_desc">When simulating data from linear models, one needs to specify the distribution of the coefficient parameters. Here, we draw coefficients from U(-m2, -m1) U U(m1, m2); m2 is what is being called the “high end of the coefficient range” and must be greater than m1.</span>
            </li>
            <li>Default Value: <span id="coefHigh_default_value">0.7</span></li>
            <li>Lower Bound: <span id="coefHigh_lower_bound">0.0</span></li>
            <li>Upper Bound: <span id="coefHigh_upper_bound">1.7976931348623157E308</span></li>
            <li>Value Type: <span id="coefHigh_value_type">Double</span></li>
        </ul>

        <h3 id="coefLow" class="parameter_description">coefLow</h3>
        <ul class="parameter_description_list">
            <li>Short Description: <span id="coefLow_short_desc">Low end of coefficient range (min = 0.0)</span></li>
            <li>Long Description: <span id="coefLow_long_desc">When simulating data from linear models, one needs to specify the distribution of the coefficient parameters. Here, we draw coefficients from U(-m2, -m1) U U(m1, m2); m1 is what is being called the “low end of the coefficient range” and has a minimum value of 0.</span>
            </li>
            <li>Default Value: <span id="coefLow_default_value">0.2</span></li>
            <li>Lower Bound: <span id="coefLow_lower_bound">0.0</span></li>
            <li>Upper Bound: <span id="coefLow_upper_bound">1.7976931348623157E308</span></li>
            <li>Value Type: <span id="coefLow_value_type">Double</span></li>
        </ul>

        <h3 id="coefSymmetric" class="parameter_description">coefSymmetric</h3>
        <ul class="parameter_description_list">
            <li>Short Description: <span id="coefSymmetric_short_desc">Yes if negative coefficient values should be considered</span>
            </li>
            <li>Long Description: <span id="coefSymmetric_long_desc">Usually coefficient values for linear models are chosen from U(-b, -a) U U(a, b) for some a, b; this is called the “symmetric” model (symmetric about zero). If only positive values should be considered, this parameter should be set to false (“No” selected),</span>
            </li>
            <li>Default Value: <span id="coefSymmetric_default_value">true</span></li>
            <li>Lower Bound: <span id="coefSymmetric_lower_bound"></span></li>
            <li>Upper Bound: <span id="coefSymmetric_upper_bound"></span></li>
            <li>Value Type: <span id="coefSymmetric_value_type">Boolean</span></li>
        </ul>

        <h3 id="colliderDiscoveryRule" class="parameter_description">colliderDiscoveryRule</h3>
        <ul class="parameter_description_list">
            <li>Short Description: <span id="colliderDiscoveryRule_short_desc">Collider discovery: 1 = Lookup from adjacency sepsets, 2 = Conservative (CPC), 3 = Max-P</span>
            </li>
            <li>Long Description: <span id="colliderDiscoveryRule_long_desc">For variants of PC, one may choose from one of three different ways for orienting colliders. One may look them up from sepsets, as in the original PC, or estimate them conservatively, as from the Conservative PC algorithm, or by choosing the sepsets with the maximum p-value.</span>
            </li>
            <li>Default Value: <span id="colliderDiscoveryRule_default_value">1</span></li>
            <li>Lower Bound: <span id="colliderDiscoveryRule_lower_bound">1</span></li>
            <li>Upper Bound: <span id="colliderDiscoveryRule_upper_bound">3</span></li>
            <li>Value Type: <span id="colliderDiscoveryRule_value_type">Integer</span></td>
        </ul>

        <h3 id="completeRuleSetUsed" class="parameter_description">completeRuleSetUsed</h3>
        <ul class="parameter_description_list">
            <li>Short Description: <span id="completeRuleSetUsed_short_desc">Yes if the complete FCI rule set should be used</span>
            </li>
            <li>Long Description: <span id="completeRuleSetUsed_long_desc">For the FCI algorithm, to final orientation rules sets are available, one due to P. Spirtes, guaranteeing arrow completeness, and a second due to J. Zhang, guaranteeing additional tail completeness. If this parameter is set to “Yes,” the tail-complete rule set will be used.</span>
            </li>
            <li>Default Value: <span id="completeRuleSetUsed_default_value">false</span></li>
            <li>Lower Bound: <span id="completeRuleSetUsed_lower_bound"></span></li>
            <li>Upper Bound: <span id="completeRuleSetUsed_upper_bound"></span></li>
            <li>Value Type: <span id="completeRuleSetUsed_value_type">Boolean</span></li>
        </ul>

        <h3 id="concurrentFAS" class="parameter_description">concurrentFAS</h3>
        <ul class="parameter_description_list">
            <li>Short Description: <span id="concurrentFAS_short_desc">Yes if a concurrent FAS should be done</span>
            </li>
            <li>Long Description: <span id="concurrentFAS_long_desc">Various versions of the PC adjacency search lend themselves to concurrent processing—that is, doing different independence tests in parallel to speed up the processing. If this parameter is set to ‘Yes’, and this option is available, it will be used.</span>
            </li>
            <li>Default Value: <span id="concurrentFAS_default_value">true</span></li>
            <li>Lower Bound: <span id="concurrentFAS_lower_bound"></span></li>
            <li>Upper Bound: <span id="concurrentFAS_upper_bound"></span></li>
            <li>Value Type: <span id="concurrentFAS_value_type">Boolean</span></li>
        </ul>

        <h3 id="conflictRule" class="parameter_description">conflictRule</h3>
        <ul class="parameter_description_list">
            <li>Short Description: <span id="conflictRule_short_desc">Collider conflicts: 1 = Overwrite, 2 = Orient bidirected, 3 = Prioritize existing colliders</span>
            </li>
            <li>Long Description: <span id="conflictRule_long_desc">It is not possible to avoid collider orientation conflicts in PC entirely. We offer three ways to deal with them. One may use the “overwrite” rule as introduced in the PCALG R package, or one may mark all collider conflicts using bidirected edges, or one may prioritize existing colliders, ignoring subsequent conflicting information.</span>
            </li>
            <li>Default Value: <span id="conflictRule_default_value">1</span></li>
            <li>Lower Bound: <span id="conflictRule_lower_bound">1</span></li>
            <li>Upper Bound: <span id="conflictRule_upper_bound">3</span></li>
            <li>Value Type: <span id="conflictRule_value_type">Integer</span></td>
        </ul>

        <h3 id="connected" class="parameter_description">connected</h3>
        <ul class="parameter_description_list">
            <li>Short Description: <span id="connected_short_desc">Yes if graph should be connected</span></li>
            <li>Long Description: <span id="connected_long_desc">It is possible to generate a random graph in which paths exists from every node to every other. This places some constraints on how the graph may be generated, but it is feasible in most cases. Setting this flag to “Yes” generates connected graphs.</span>
            </li>
            <li>Default Value: <span id="connected_default_value">false</span></li>
            <li>Lower Bound: <span id="connected_lower_bound"></span></li>
            <li>Upper Bound: <span id="connected_upper_bound"></span></li>
            <li>Value Type: <span id="connected_value_type">Boolean</span></li>
        </ul>

        <h3 id="covHigh" class="parameter_description">covHigh</h3>
        <ul class="parameter_description_list">
            <li>Short Description: <span id="covHigh_short_desc">High end of covariance range (min = 0.0)</span></li>
            <li>Long Description: <span id="covHigh_long_desc">When simulating data from linear models, one needs to specify the distribution of the covariance parameters. Here, we draw coefficients from U(-c2, -c1) U U(c1, c2); c2 is what is being called the “high end of the covariance range” and must be greater  than c1. The default value is 1.5.</span>
            </li>
            <li>Default Value: <span id="covHigh_default_value">1.5</span></li>
            <li>Lower Bound: <span id="covHigh_lower_bound">0.0</span></li>
            <li>Upper Bound: <span id="covHigh_upper_bound">1.7976931348623157E308</span></li>
            <li>Value Type: <span id="covHigh_value_type">Double</span></li>
        </ul>

        <h3 id="covLow" class="parameter_description">covLow</h3>
        <ul class="parameter_description_list">
            <li>Short Description: <span id="covLow_short_desc">Low end of covariance range (min = 0.0)</span></li>
            <li>Long Description: <span id="covLow_long_desc">When simulating data from linear models, one needs to specify the distribution of the covariance parameters. Here, we draw coefficients from U(-c2, -c1) U U(c1, c2); c1 is what is being called the “low end of the covariance range” and has a minimum value of 0. The default value is 0.5.</span>
            </li>
            <li>Default Value: <span id="covLow_default_value">0.5</span></li>
            <li>Lower Bound: <span id="covLow_lower_bound">0.0</span></li>
            <li>Upper Bound: <span id="covLow_upper_bound">1.7976931348623157E308</span></li>
            <li>Value Type: <span id="covLow_value_type">Double</span></li>
        </ul>

        <h3 id="covSymmetric" class="parameter_description">covSymmetric</h3>
        <ul class="parameter_description_list">
            <li>Short Description: <span id="covSymmetric_short_desc">Yes if negative covariance values should be considered</span>
            </li>
            <li>Long Description: <span id="covSymmetric_long_desc">
Usually covariance values are chosen from U(-b, -a) U U(a, b) for some a, b; this is called the “symmetric” model (symmetric about zero). If only positive values should be considered, this parameter should be set to false (“No” selected)
</span></li>
            <li>Default Value: <span id="covSymmetric_default_value">true</span></li>
            <li>Lower Bound: <span id="covSymmetric_lower_bound"></span></li>
            <li>Upper Bound: <span id="covSymmetric_upper_bound"></span></li>
            <li>Value Type: <span id="covSymmetric_value_type">Boolean</span></li>
        </ul>

        <h3 id="cutoffConstrainSearch" class="parameter_description">cutoffConstrainSearch</h3>
        <ul class="parameter_description_list">
            <li>Short Description: <span
                    id="cutoffConstrainSearch_short_desc">Constraint-independence cutoff threshold</span></li>
            <li>Long Description: <span id="cutoffConstrainSearch_long_desc">null</span></li>
            <li>Default Value: <span id="cutoffConstrainSearch_default_value">0.5</span></li>
            <li>Lower Bound: <span id="cutoffConstrainSearch_lower_bound">0.0</span></li>
            <li>Upper Bound: <span id="cutoffConstrainSearch_upper_bound">1.0</span></li>
            <li>Value Type: <span id="cutoffConstrainSearch_value_type">Double</span></li>
        </ul>

        <h3 id="cutoffDataSearch" class="parameter_description">cutoffDataSearch</h3>
        <ul class="parameter_description_list">
            <li>Short Description: <span id="cutoffDataSearch_short_desc">Independence cutoff threshold</span></li>
            <li>Long Description: <span id="cutoffDataSearch_long_desc">null</span></li>
            <li>Default Value: <span id="cutoffDataSearch_default_value">0.5</span></li>
            <li>Lower Bound: <span id="cutoffDataSearch_lower_bound">0.0</span></li>
            <li>Upper Bound: <span id="cutoffDataSearch_upper_bound">1.0</span></li>
            <li>Value Type: <span id="cutoffDataSearch_value_type">Double</span></li>
        </ul>

        <h3 id="cutoffIndTest" class="parameter_description">cutoffIndTest</h3>
        <ul class="parameter_description_list">
            <li>Short Description: <span id="cutoffIndTest_short_desc">Independence cutoff threshold</span></li>
            <li>Long Description: <span id="cutoffIndTest_long_desc">null</span></li>
            <li>Default Value: <span id="cutoffIndTest_default_value">0.5</span></li>
            <li>Lower Bound: <span id="cutoffIndTest_lower_bound">0.0</span></li>
            <li>Upper Bound: <span id="cutoffIndTest_upper_bound">1.0</span></li>
            <li>Value Type: <span id="cutoffIndTest_value_type">Double</span></li>
        </ul>

        <h3 id="dataType" class="parameter_description">dataType</h3>
        <ul class="parameter_description_list">
            <li>Short Description: <span id="dataType_short_desc">Categorical or discrete</span></li>
            <li>Long Description: <span id="dataType_long_desc">For a mixed data type simulation, if this is set to “categorical” or “discrete”, all variables are taken to be of that sort. Used internally to the program.</span>
            </li>
            <li>Default Value: <span id="dataType_default_value">categorical</span></li>
            <li>Lower Bound: <span id="dataType_lower_bound"></span></li>
            <li>Upper Bound: <span id="dataType_upper_bound"></span></li>
            <li>Value Type: <span id="dataType_value_type"></span></li>
        </ul>

        <h3 id="depth" class="parameter_description">depth</h3>
        <ul class="parameter_description_list">
            <li>Short Description: <span id="depth_short_desc">Maximum size of conditioning set (unlimited = -1)</span>
            </li>
            <li>Long Description: <span id="depth_long_desc">This variable is usually called “depth” for algorithms such as PC in which conditioning sets are considered of increasing size from zero up to some limit, called “depth”. For example, if depth = 3, conditioning sets will be considered of sizes 0, 1, 2, and 3. In order to express that no limit should be imposed, use the value -1.</span>
            </li>
            <li>Default Value: <span id="depth_default_value">-1</span></li>
            <li>Lower Bound: <span id="depth_lower_bound">-1</span></li>
            <li>Upper Bound: <span id="depth_upper_bound">2147483647</span></li>
            <li>Value Type: <span id="depth_value_type">Integer</span></td>
        </ul>

        <h3 id="determinismThreshold" class="parameter_description">determinismThreshold</h3>
        <ul class="parameter_description_list">
            <li>Short Description: <span id="determinismThreshold_short_desc">Threshold for judging a regression of a variable onto its parents to be deternimistic (min = 0.0)</span>
            </li>
            <li>Long Description: <span id="determinismThreshold_long_desc">When regressing a child variable onto a set of parent variables, one way to test for determinism is to see whether the relevant matrix is singular. We may instead ask how close to singular the matrix is; this gives a threshold for this. The default value is 0.1.</span>
            </li>
            <li>Default Value: <span id="determinismThreshold_default_value">0.1</span></li>
            <li>Lower Bound: <span id="determinismThreshold_lower_bound">0.0</span></li>
            <li>Upper Bound: <span id="determinismThreshold_upper_bound">Infinity</span></li>
            <li>Value Type: <span id="determinismThreshold_value_type">Double</span></li>
        </ul>

        <h3 id="differentGraphs" class="parameter_description">differentGraphs</h3>
        <ul class="parameter_description_list">
            <li>Short Description: <span id="differentGraphs_short_desc">Yes if a different graph should be used for each run</span>
            </li>
            <li>Long Description: <span id="differentGraphs_long_desc">When doing an analysis where, repeatedly, a random graph is chosen, with some further processing downstream, one may either keep using the same graph (with different simulated random datasets based on that graph) or pick a new graph every time. This parameter determines that behavior; if ‘Yes’ a new graph is chosen every time; if ‘No’, the same graph is always used.</span>
            </li>
            <li>Default Value: <span id="differentGraphs_default_value">false</span></li>
            <li>Lower Bound: <span id="differentGraphs_lower_bound"></span></li>
            <li>Upper Bound: <span id="differentGraphs_upper_bound"></span></li>
            <li>Value Type: <span id="differentGraphs_value_type">Boolean</span></li>
        </ul>

        <h3 id="discretize" class="parameter_description">discretize</h3>
        <ul class="parameter_description_list">
            <li>Short Description: <span id="discretize_short_desc">Yes if continuous variables should be discretized when child is discrete</span>
            </li>
            <li>Long Description: <span id="discretize_long_desc">For the conditional Gaussian likelihood, when scoring X->D, where X is continuous and D discrete, it is possible to write out the formula for that longhand, but a fast way to do it (and in fact more accurate usually) is to simply discretize X for just those cases. If this parameter is set to “Yes”, this discretization will be done.</span>
            </li>
            <li>Default Value: <span id="discretize_default_value">true</span></li>
            <li>Lower Bound: <span id="discretize_lower_bound"></span></li>
            <li>Upper Bound: <span id="discretize_upper_bound"></span></li>
            <li>Value Type: <span id="discretize_value_type">Boolean</span></li>
        </ul>

        <h3 id="doColliderOrientation" class="parameter_description">doColliderOrientation</h3>
        <ul class="parameter_description_list">
            <li>Short Description: <span id="doColliderOrientation_short_desc">Yes if unshielded collider orientation should be done</span>
            </li>
            <li>Long Description: <span id="doColliderOrientation_long_desc">Please see the description of this algorithm in Thomas Richardson and Peter Spirtes in Chapter 7 of Computation, Causation, & Discovery by Glymour and Cooper eds.</span>
            </li>
            <li>Default Value: <span id="doColliderOrientation_default_value">true</span></li>
            <li>Lower Bound: <span id="doColliderOrientation_lower_bound"></span></li>
            <li>Upper Bound: <span id="doColliderOrientation_upper_bound"></span></li>
            <li>Value Type: <span id="doColliderOrientation_value_type">Boolean</span></li>
        </ul>

        <h3 id="errorsNormal" class="parameter_description">errorsNormal</h3>
        <ul class="parameter_description_list">
            <li>Short Description: <span id="errorsNormal_short_desc">Yes if errors should be Normal; No if they should be Beta</span>
            </li>
            <li>Long Description: <span id="errorsNormal_long_desc">A “quick and dirty” way to generate linear, non-Gaussian data is to set this parameter to “No”; then the errors will be sampled from a Beta distribution.</span>
            </li>
            <li>Default Value: <span id="errorsNormal_default_value">true</span></li>
            <li>Lower Bound: <span id="errorsNormal_lower_bound"></span></li>
            <li>Upper Bound: <span id="errorsNormal_upper_bound"></span></li>
            <li>Value Type: <span id="errorsNormal_value_type">Boolean</span></li>
        </ul>

        <h3 id="extraEdgeThreshold" class="parameter_description">extraEdgeThreshold</h3>
        <ul class="parameter_description_list">
            <li>Short Description: <span id="extraEdgeThreshold_short_desc">Threshold for including extra edges</span>
            </li>
            <li>Long Description: <span id="extraEdgeThreshold_long_desc">For FASK, this includes an adjacency X—Y in the model if |corr(X, Y | X > 0) – corr(X, Y | Y > 0)| > delta, where delta is this number. The default is 0.3. Sanchez-Romero, Ramsey et al., (2018) Network Neuroscience.</span>
            </li>
            <li>Default Value: <span id="extraEdgeThreshold_default_value">0.3</span></li>
            <li>Lower Bound: <span id="extraEdgeThreshold_lower_bound">0.0</span></li>
            <li>Upper Bound: <span id="extraEdgeThreshold_upper_bound">Infinity</span></li>
            <li>Value Type: <span id="extraEdgeThreshold_value_type">Double</span></li>
        </ul>

        <h3 id="faithfulnessAssumed" class="parameter_description">faithfulnessAssumed</h3>
        <ul class="parameter_description_list">
            <li>Short Description: <span id="faithfulnessAssumed_short_desc">Yes if (one edge) faithfulness should be assumed</span>
            </li>
            <li>Long Description: <span id="faithfulnessAssumed_long_desc">This is a parameter for FGES (“Fast GES”). If this is set to ‘Yes’, it will be assumed that if X _||_ Y, by an independence test, then X _||_ Y | Z for nonempty Z. If the model is faithful to the data, this will necessarily be the case. However, there are some non-faithful examples one can propose where this is not the case. If one is worried about this kind of unfaithfulness, one should set this parameter to ‘No’. If one is willing to tolerate this kind of unfaithfulness, then setting this parameter to ‘Yes’ leads to significantly faster searches.</span>
            </li>
            <li>Default Value: <span id="faithfulnessAssumed_default_value">true</span></li>
            <li>Lower Bound: <span id="faithfulnessAssumed_lower_bound"></span></li>
            <li>Upper Bound: <span id="faithfulnessAssumed_upper_bound"></span></li>
            <li>Value Type: <span id="faithfulnessAssumed_value_type">Boolean</span></li>
        </ul>

        <h3 id="fasRule" class="parameter_description">fasRule</h3>
        <ul class="parameter_description_list">
            <li>Short Description: <span id="fasRule_short_desc">Adjacency search: 1 = PC, 2 = PC-Stable, 3 =f Concurrent PC-Stable</span>
            </li>
            <li>Long Description: <span id="fasRule_long_desc">For variants of PC, one may select either to use the usual PC adjacency search, or the procedure from the PC-Stable algorithm (Diego and Maathuis), or the latter using a concurrent algorithm (that is, one that runs in parallel on multiple processors).</span>
            </li>
            <li>Default Value: <span id="fasRule_default_value">1</span></li>
            <li>Lower Bound: <span id="fasRule_lower_bound">1</span></li>
            <li>Upper Bound: <span id="fasRule_upper_bound">3</span></li>
            <li>Value Type: <span id="fasRule_value_type">Integer</span></td>
        </ul>

        <h3 id="faskDelta" class="parameter_description">faskDelta</h3>
        <ul class="parameter_description_list">
            <li>Short Description: <span id="faskDelta_short_desc">Threshold for judging negative coefficient edges as X->Y (range (-1, 0))</span>
            </li>
            <li>Long Description: <span id="faskDelta_long_desc">For FASK, a dataset dependent threshold that affects accuracy for negatively skewed variables, in the range (-1, 0); the default value is -0.2. Sanchez-Romero, Ramsey et al., (2018) Network Neuroscience.</span>
            </li>
            <li>Default Value: <span id="faskDelta_default_value">-0.2</span></li>
            <li>Lower Bound: <span id="faskDelta_lower_bound">-1.0</span></li>
            <li>Upper Bound: <span id="faskDelta_upper_bound">1.0</span></li>
            <li>Value Type: <span id="faskDelta_value_type">Double</span></li>
        </ul>

        <h3 id="faskDelta2" class="parameter_description">faskDelta2</h3>
        <ul class="parameter_description_list">
            <li>Short Description: <span id="faskDelta2_short_desc">Threshold for judging negative coefficient edges as X->Y</span>
            </li>
            <li>Long Description: <span id="faskDelta2_long_desc">For FASK, a dataset dependent threshold that affects accuracy for negatively skewed variables, in the range (-1, 0); the default value is -0.2. Sanchez-Romero, Ramsey et al., (2018) Network Neuroscience.</span>
            </li>
            <li>Default Value: <span id="faskDelta2_default_value">0.0</span></li>
            <li>Lower Bound: <span id="faskDelta2_lower_bound">NaN</span></li>
            <li>Upper Bound: <span id="faskDelta2_upper_bound">Infinity</span></li>
            <li>Value Type: <span id="faskDelta2_value_type">Double</span></li>
        </ul>

        <h3 id="fisherEpsilon" class="parameter_description">fisherEpsilon</h3>
        <ul class="parameter_description_list">
            <li>Short Description: <span id="fisherEpsilon_short_desc">Epsilon where |xi.t - xi.t-1| < epsilon, criterion for convergence</span>
            </li>
            <li>Long Description: <span id="fisherEpsilon_long_desc">This is a parameter for the linear Fisher option. The idea of Fisher model (for the linear case) is to shock the system every so often and let it converge by applying the rules of transformation (that is, the linear model) repeatedly until convergence. This sets the criterion for convergence—the process continues until the differences from one time step to the next fall below this epsilon.</span>
            </li>
            <li>Default Value: <span id="fisherEpsilon_default_value">0.001</span></li>
            <li>Lower Bound: <span id="fisherEpsilon_lower_bound">4.9E-324</span></li>
            <li>Upper Bound: <span id="fisherEpsilon_upper_bound">1.7976931348623157E308</span></li>
            <li>Value Type: <span id="fisherEpsilon_value_type">Double</span></li>
        </ul>

        <h3 id="generalSemErrorTemplate" class="parameter_description">generalSemErrorTemplate</h3>
        <ul class="parameter_description_list">
            <li>Short Description: <span id="generalSemErrorTemplate_short_desc">General function for error terms</span>
            </li>
            <li>Long Description: <span id="generalSemErrorTemplate_long_desc">This template specifies how distributions for error terms are to be generated. For help in constructing such templates, see the Generalized SEM PM model.</span>
            </li>
            <li>Default Value: <span id="generalSemErrorTemplate_default_value">Beta(2, 5)</span></li>
            <li>Lower Bound: <span id="generalSemErrorTemplate_lower_bound"></span></li>
            <li>Upper Bound: <span id="generalSemErrorTemplate_upper_bound"></span></li>
            <li>Value Type: <span id="generalSemErrorTemplate_value_type"></span></li>
        </ul>

        <h3 id="generalSemFunctionTemplateLatent" class="parameter_description">generalSemFunctionTemplateLatent</h3>
        <ul class="parameter_description_list">
            <li>Short Description: <span id="generalSemFunctionTemplateLatent_short_desc">General function template for latent variables</span>
            </li>
            <li>Long Description: <span id="generalSemFunctionTemplateLatent_long_desc">This template specifies how equations for latent variables are to be generated. For help in constructing such templates, see the Generalized SEM PM model.</span>
            </li>
            <li>Default Value: <span id="generalSemFunctionTemplateLatent_default_value">TSUM(NEW(B)*$)</span></li>
            <li>Lower Bound: <span id="generalSemFunctionTemplateLatent_lower_bound"></span></li>
            <li>Upper Bound: <span id="generalSemFunctionTemplateLatent_upper_bound"></span></li>
            <li>Value Type: <span id="generalSemFunctionTemplateLatent_value_type"></span></li>
        </ul>

        <h3 id="generalSemFunctionTemplateMeasured" class="parameter_description">
            generalSemFunctionTemplateMeasured</h3>
        <ul class="parameter_description_list">
            <li>Short Description: <span id="generalSemFunctionTemplateMeasured_short_desc">General function template for measured variables</span>
            </li>
            <li>Long Description: <span id="generalSemFunctionTemplateMeasured_long_desc">This template specifies how equations for measured variables are to be generated. For help in constructing such templates, see the Generalized SEM PM model.</span>
            </li>
            <li>Default Value: <span id="generalSemFunctionTemplateMeasured_default_value">TSUM(NEW(B)*$)</span></li>
            <li>Lower Bound: <span id="generalSemFunctionTemplateMeasured_lower_bound"></span></li>
            <li>Upper Bound: <span id="generalSemFunctionTemplateMeasured_upper_bound"></span></li>
            <li>Value Type: <span id="generalSemFunctionTemplateMeasured_value_type"></span></li>
        </ul>

        <h3 id="generalSemParameterTemplate" class="parameter_description">generalSemParameterTemplate</h3>
        <ul class="parameter_description_list">
            <li>Short Description: <span
                    id="generalSemParameterTemplate_short_desc">General function for parameters</span></li>
            <li>Long Description: <span id="generalSemParameterTemplate_long_desc">This template specifies how distributions for parameter terms are to be generated. For help in constructing such templates, see the Generalized SEM PM model.</span>
            </li>
            <li>Default Value: <span id="generalSemParameterTemplate_default_value">Split(-1.0, -0.5, 0.5, 1.0)</span>
            </li>
            <li>Lower Bound: <span id="generalSemParameterTemplate_lower_bound"></span></li>
            <li>Upper Bound: <span id="generalSemParameterTemplate_upper_bound"></span></li>
            <li>Value Type: <span id="generalSemParameterTemplate_value_type"></span></li>
        </ul>

        <h3 id="ia" class="parameter_description">ia</h3>
        <ul class="parameter_description_list">
            <li>Short Description: <span id="ia_short_desc">IA parameter (GLASSO)</span></li>
            <li>Long Description: <span id="ia_long_desc">The R Fortan implementation of GLASSO (https://CRAN.R-project.org/package=glasso) includes a number of parameters, of which this is one. This is the maximum number of iterations of the optimization loop.</span>
            </li>
            <li>Default Value: <span id="ia_default_value">false</span></li>
            <li>Lower Bound: <span id="ia_lower_bound"></span></li>
            <li>Upper Bound: <span id="ia_upper_bound"></span></li>
            <li>Value Type: <span id="ia_value_type">Boolean</span></li>
        </ul>

        <h3 id="includeNegativeCoefs" class="parameter_description">includeNegativeCoefs</h3>
        <ul class="parameter_description_list">
            <li>Short Description: <span id="includeNegativeCoefs_short_desc">Yes if negative coefficients should be included in the model</span>
            </li>
            <li>Long Description: <span id="includeNegativeCoefs_long_desc">One may include positive coefficients, negative coefficients, or both, in the model. To include negative coefficients, set this parameter to “Yes”.</span>
            </li>
            <li>Default Value: <span id="includeNegativeCoefs_default_value">true</span></li>
            <li>Lower Bound: <span id="includeNegativeCoefs_lower_bound"></span></li>
            <li>Upper Bound: <span id="includeNegativeCoefs_upper_bound"></span></li>
            <li>Value Type: <span id="includeNegativeCoefs_value_type">Boolean</span></li>
        </ul>

        <h3 id="includeNegativeSkewsForBeta" class="parameter_description">includeNegativeSkewsForBeta</h3>
        <ul class="parameter_description_list">
            <li>Short Description: <span id="includeNegativeSkewsForBeta_short_desc">Yes if negative skew values should be included in the model, if Beta errors are chosen</span>
            </li>
            <li>Long Description: <span id="includeNegativeSkewsForBeta_long_desc">Yes if negative skew values should be included in the model, if Beta errors are chosen.</span>
            </li>
            <li>Default Value: <span id="includeNegativeSkewsForBeta_default_value">true</span></li>
            <li>Lower Bound: <span id="includeNegativeSkewsForBeta_lower_bound"></span></li>
            <li>Upper Bound: <span id="includeNegativeSkewsForBeta_upper_bound"></span></li>
            <li>Value Type: <span id="includeNegativeSkewsForBeta_value_type">Boolean</span></li>
        </ul>

        <h3 id="includePositiveCoefs" class="parameter_description">includePositiveCoefs</h3>
        <ul class="parameter_description_list">
            <li>Short Description: <span id="includePositiveCoefs_short_desc">Yes if positive coefficients should be included in the model</span>
            </li>
            <li>Long Description: <span id="includePositiveCoefs_long_desc">e may include positive coefficients, negative coefficients, or both, in the model. To include positive coefficients, set this parameter to “Yes”.</span>
            </li>
            <li>Default Value: <span id="includePositiveCoefs_default_value">true</span></li>
            <li>Lower Bound: <span id="includePositiveCoefs_lower_bound"></span></li>
            <li>Upper Bound: <span id="includePositiveCoefs_upper_bound"></span></li>
            <li>Value Type: <span id="includePositiveCoefs_value_type">Boolean</span></li>
        </ul>

        <h3 id="includePositiveSkewsForBeta" class="parameter_description">includePositiveSkewsForBeta</h3>
        <ul class="parameter_description_list">
            <li>Short Description: <span id="includePositiveSkewsForBeta_short_desc">Yes if positive skew values should be included in the model, if Beta errors are chosen</span>
            </li>
            <li>Long Description: <span id="includePositiveSkewsForBeta_long_desc">Yes if positive skew values should be included in the model, if Beta errors are chosen.</span>
            </li>
            <li>Default Value: <span id="includePositiveSkewsForBeta_default_value">true</span></li>
            <li>Lower Bound: <span id="includePositiveSkewsForBeta_lower_bound"></span></li>
            <li>Upper Bound: <span id="includePositiveSkewsForBeta_upper_bound"></span></li>
            <li>Value Type: <span id="includePositiveSkewsForBeta_value_type">Boolean</span></li>
        </ul>

        <h3 id="intervalBetweenRecordings" class="parameter_description">intervalBetweenRecordings</h3>
        <ul class="parameter_description_list">
            <li>Short Description: <span id="intervalBetweenRecordings_short_desc">Interval between data recordings for the linear Fisher model (min = 1)</span>
            </li>
            <li>Long Description: <span id="intervalBetweenRecordings_long_desc"></span></li>
            <li>Default Value: <span id="intervalBetweenRecordings_default_value">10</span></li>
            <li>Lower Bound: <span id="intervalBetweenRecordings_lower_bound">1</span></li>
            <li>Upper Bound: <span id="intervalBetweenRecordings_upper_bound">2147483647</span></li>
            <li>Value Type: <span id="intervalBetweenRecordings_value_type">Integer</span></td>
        </ul>

        <h3 id="intervalBetweenShocks" class="parameter_description">intervalBetweenShocks</h3>
        <ul class="parameter_description_list">
            <li>Short Description: <span id="intervalBetweenShocks_short_desc">Interval beween shocks (R. A. Fisher simulation model) (min = 1)</span>
            </li>
            <li>Long Description: <span id="intervalBetweenShocks_long_desc">This is a parameter for the linear Fisher option. The idea of Fisher model (for the linear case) is to shock the system every so often and let it converge by applying the rules of transformation (that is, the linear model) repeatedly until convergence. This sets the number of step between shocks.</span>
            </li>
            <li>Default Value: <span id="intervalBetweenShocks_default_value">10</span></li>
            <li>Lower Bound: <span id="intervalBetweenShocks_lower_bound">1</span></li>
            <li>Upper Bound: <span id="intervalBetweenShocks_upper_bound">2147483647</span></li>
            <li>Value Type: <span id="intervalBetweenShocks_value_type">Integer</span></td>
        </ul>

        <h3 id="ipen" class="parameter_description">ipen</h3>
        <ul class="parameter_description_list">
            <li>Short Description: <span id="ipen_short_desc">IPEN parameter (GLASSO)</span></li>
            <li>Long Description: <span id="ipen_long_desc">The R Fortan implementation of GLASSO (https://CRAN.R-project.org/package=glasso) includes a number of parameters, of which this is one. This is the maximum number of iterations of the optimization loop.</span>
            </li>
            <li>Default Value: <span id="ipen_default_value">false</span></li>
            <li>Lower Bound: <span id="ipen_lower_bound"></span></li>
            <li>Upper Bound: <span id="ipen_upper_bound"></span></li>
            <li>Value Type: <span id="ipen_value_type">Boolean</span></li>
        </ul>

        <h3 id="is" class="parameter_description">is</h3>
        <ul class="parameter_description_list">
            <li>Short Description: <span id="is_short_desc">IS parameter (GLASSO)</span></li>
            <li>Long Description: <span id="is_long_desc">The R Fortan implementation of GLASSO (https://CRAN.R-project.org/package=glasso) includes a number of parameters, of which this is one. This is the maximum number of iterations of the optimization loop.</span>
            </li>
            <li>Default Value: <span id="is_default_value">false</span></li>
            <li>Lower Bound: <span id="is_lower_bound"></span></li>
            <li>Upper Bound: <span id="is_upper_bound"></span></li>
            <li>Value Type: <span id="is_value_type">Boolean</span></li>
        </ul>

        <h3 id="itr" class="parameter_description">itr</h3>
        <ul class="parameter_description_list">
            <li>Short Description: <span id="itr_short_desc">ITR parameter (GLASSO)</span></li>
            <li>Long Description: <span id="itr_long_desc">The R Fortan implementation of GLASSO (https://CRAN.R-project.org/package=glasso) includes a number of parameters, of which this is one. This is the maximum number of iterations of the optimization loop.</span>
            </li>
            <li>Default Value: <span id="itr_default_value">false</span></li>
            <li>Lower Bound: <span id="itr_lower_bound"></span></li>
            <li>Upper Bound: <span id="itr_upper_bound"></span></li>
            <li>Value Type: <span id="itr_value_type">Boolean</span></li>
        </ul>

        <h3 id="kciAlpha" class="parameter_description">kciAlpha</h3>
        <ul class="parameter_description_list">
            <li>Short Description: <span id="kciAlpha_short_desc">Cutoff for p values (alpha) (min = 0.0)</span></li>
            <li>Long Description: <span id="kciAlpha_long_desc">Alpha level (0 to 1)</span></li>
            <li>Default Value: <span id="kciAlpha_default_value">0.05</span></li>
            <li>Lower Bound: <span id="kciAlpha_lower_bound">0.0</span></li>
            <li>Upper Bound: <span id="kciAlpha_upper_bound">1.0</span></li>
            <li>Value Type: <span id="kciAlpha_value_type">Double</span></li>
        </ul>

        <h3 id="kciCutoff" class="parameter_description">kciCutoff</h3>
        <ul class="parameter_description_list">
            <li>Short Description: <span id="kciCutoff_short_desc">Cutoff</span></li>
            <li>Long Description: <span id="kciCutoff_long_desc">Cutoff for p-values.</span></li>
            <li>Default Value: <span id="kciCutoff_default_value">6</span></li>
            <li>Lower Bound: <span id="kciCutoff_lower_bound">1</span></li>
            <li>Upper Bound: <span id="kciCutoff_upper_bound">2147483647</span></li>
            <li>Value Type: <span id="kciCutoff_value_type">Integer</span></td>
        </ul>

        <h3 id="kciEpsilon" class="parameter_description">kciEpsilon</h3>
        <ul class="parameter_description_list">
            <li>Short Description: <span
                    id="kciEpsilon_short_desc">Epsilon for Proposition 5, a small positive number</span></li>
            <li>Long Description: <span id="kciEpsilon_long_desc">We have a number of parameters here for the Kernel Conditional Independence Test (KCI). In order to understand the parameters, it is necessary to read the paper on which this test is based, here: Zhang, K., Peters, J., Janzing, D., & Schölkopf, B. (2012). Kernel-based conditional independence test and application in causal discovery. arXiv preprint arXiv:1202.3775. This parameter is the epsilon for Proposition 5, a small positive number. The default value is 0.001; it must be a positive real number.</span>
            </li>
            <li>Default Value: <span id="kciEpsilon_default_value">0.001</span></li>
            <li>Lower Bound: <span id="kciEpsilon_lower_bound">0.0</span></li>
            <li>Upper Bound: <span id="kciEpsilon_upper_bound">Infinity</span></li>
            <li>Value Type: <span id="kciEpsilon_value_type">Double</span></li>
        </ul>

        <h3 id="kciNumBootstraps" class="parameter_description">kciNumBootstraps</h3>
        <ul class="parameter_description_list">
            <li>Short Description: <span id="kciNumBootstraps_short_desc">Number of bootstraps for Theorems 4 and Proposition 5 for KCI</span>
            </li>
            <li>Long Description: <span id="kciNumBootstraps_long_desc">We have a number of parameters here for the Kernel Conditional Independence Test (KCI). In order to understand the parameters, it is necessary to read the paper on which this test is based, here: Zhang, K., Peters, J., Janzing, D., & Schölkopf, B. (2012). Kernel-based conditional independence test and application in causal discovery. arXiv preprint arXiv:1202.3775. This parameter is the number of bootstraps for Theorems 4 and Proposition 5. The default is 5000; it must be positive integer.</span>
            </li>
            <li>Default Value: <span id="kciNumBootstraps_default_value">5000</span></li>
            <li>Lower Bound: <span id="kciNumBootstraps_lower_bound">1</span></li>
            <li>Upper Bound: <span id="kciNumBootstraps_upper_bound">2147483647</span></li>
            <li>Value Type: <span id="kciNumBootstraps_value_type">Integer</span></td>
        </ul>

        <h3 id="kciUseAppromation" class="parameter_description">kciUseAppromation</h3>
        <ul class="parameter_description_list">
            <li>Short Description: <span id="kciUseAppromation_short_desc">Use the approximate Gamma approximation algorithm</span>
            </li>
            <li>Long Description: <span id="kciUseAppromation_long_desc">We have a number of parameters here for the Kernel Conditional Independence Test (KCI). In order to understand the parameters, it is necessary to read the paper on which this test is based, here: Zhang, K., Peters, J., Janzing, D., & Schölkopf, B. (2012). Kernel-based conditional independence test and application in causal discovery. arXiv preprint arXiv:1202.3775. If this parameter is set to ‘Yes’, the Gamma approximation algorithm is used, as described in this paper; otherwise, the non-approximate procedure is used.</span>
            </li>
            <li>Default Value: <span id="kciUseAppromation_default_value">true</span></li>
            <li>Lower Bound: <span id="kciUseAppromation_lower_bound"></span></li>
            <li>Upper Bound: <span id="kciUseAppromation_upper_bound"></span></li>
            <li>Value Type: <span id="kciUseAppromation_value_type">Boolean</span></li>
        </ul>

        <h3 id="kernelMultiplier" class="parameter_description">kernelMultiplier</h3>
        <ul class="parameter_description_list">
            <li>Short Description: <span id="kernelMultiplier_short_desc">Bowman and Azzalini (1997) default kernel bandwidhts should be multiplied by...</span>
            </li>
            <li>Long Description: <span id="kernelMultiplier_long_desc">For the conditional correlation algorithm. Bowman, A. W., & Azzalini, A. (1997, Applied smoothing techniques for data analysis: the kernel approach with S-Plus illustrations (Vol. 18), OUP Oxford), give a formula for default optimal kernel widths. We allow these defaults to be multiplied by some factor, which we call the “kernel multiplier”, to capture more or less than this optimal signal. This multiplier must be a positive real number.</span>
            </li>
            <li>Default Value: <span id="kernelMultiplier_default_value">1.0</span></li>
            <li>Lower Bound: <span id="kernelMultiplier_lower_bound">4.9E-324</span></li>
            <li>Upper Bound: <span id="kernelMultiplier_upper_bound">Infinity</span></li>
            <li>Value Type: <span id="kernelMultiplier_value_type">Double</span></li>
        </ul>

        <h3 id="kernelRegressionSampleSize" class="parameter_description">kernelRegressionSampleSize</h3>
        <ul class="parameter_description_list">
            <li>Short Description: <span id="kernelRegressionSampleSize_short_desc">Minimum sample size to use per conditioning for kernel regression</span>
            </li>
            <li>Long Description: <span id="kernelRegressionSampleSize_long_desc">Kernel regression for X _||_ Y | Z looks for dependencies between X and Y for Z values near to some particular Z values of interest. One can find the m nearest points to a given Z = z’ by expanding the search radius until you get that many points. This parameter specifies the smallest such set of nearest points on which to allow a judgment to be based.</span>
            </li>
            <li>Default Value: <span id="kernelRegressionSampleSize_default_value">100</span></li>
            <li>Lower Bound: <span id="kernelRegressionSampleSize_lower_bound">-2147483648</span></li>
            <li>Upper Bound: <span id="kernelRegressionSampleSize_upper_bound">2147483647</span></li>
            <li>Value Type: <span id="kernelRegressionSampleSize_value_type">Integer</span></td>
        </ul>

        <h3 id="kernelType" class="parameter_description">kernelType</h3>
        <ul class="parameter_description_list">
            <li>Short Description: <span id="kernelType_short_desc">Kernel type (1 = Gaussian, 2 = Epinechnikov)</span>
            </li>
            <li>Long Description: <span id="kernelType_long_desc">For CCI, this determine which kernel type will be used (1 = Gaussian, 2 = Epinechnikov).</span>
            </li>
            <li>Default Value: <span id="kernelType_default_value">2</span></li>
            <li>Lower Bound: <span id="kernelType_lower_bound">1</span></li>
            <li>Upper Bound: <span id="kernelType_upper_bound">2</span></li>
            <li>Value Type: <span id="kernelType_value_type">Integer</span></td>
        </ul>

        <h3 id="kernelWidth" class="parameter_description">kernelWidth</h3>
        <ul class="parameter_description_list">
            <li>Short Description: <span id="kernelWidth_short_desc">Kernel width</span></li>
            <li>Long Description: <span id="kernelWidth_long_desc">A larger kernel width means that more information will be taken into account but possibly less focused information.</span>
            </li>
            <li>Default Value: <span id="kernelWidth_default_value">1.0</span></li>
            <li>Lower Bound: <span id="kernelWidth_lower_bound">4.9E-324</span></li>
            <li>Upper Bound: <span id="kernelWidth_upper_bound">Infinity</span></li>
            <li>Value Type: <span id="kernelWidth_value_type">Double</span></li>
        </ul>

        <h3 id="latentMeasuredImpureParents" class="parameter_description">latentMeasuredImpureParents</h3>
        <ul class="parameter_description_list">
            <li>Short Description: <span id="latentMeasuredImpureParents_short_desc">Number of Latent --> Measured impure edges</span>
            </li>
            <li>Long Description: <span id="latentMeasuredImpureParents_long_desc">It is possible for structural nodes to have as children measured variables that are children of other structural nodes. These edges in the graph will be considered impure.</span>
            </li>
            <li>Default Value: <span id="latentMeasuredImpureParents_default_value">0</span></li>
            <li>Lower Bound: <span id="latentMeasuredImpureParents_lower_bound">-2147483648</span></li>
            <li>Upper Bound: <span id="latentMeasuredImpureParents_upper_bound">2147483647</span></li>
            <li>Value Type: <span id="latentMeasuredImpureParents_value_type">Integer</span></td>
        </ul>

        <h3 id="lowerBound" class="parameter_description">lowerBound</h3>
        <ul class="parameter_description_list">
            <li>Short Description: <span id="lowerBound_short_desc">Lower bound cutoff threshold</span></li>
            <li>Long Description: <span id="lowerBound_long_desc">null</span></li>
            <li>Default Value: <span id="lowerBound_default_value">0.3</span></li>
            <li>Lower Bound: <span id="lowerBound_lower_bound">0.0</span></li>
            <li>Upper Bound: <span id="lowerBound_upper_bound">1.0</span></li>
            <li>Value Type: <span id="lowerBound_value_type">Double</span></li>
        </ul>

        <h3 id="maxCategories" class="parameter_description">maxCategories</h3>
        <ul class="parameter_description_list">
            <li>Short Description: <span id="maxCategories_short_desc">Maximum number of categories (min = 2)</span>
            </li>
            <li>Long Description: <span id="maxCategories_long_desc">The maximum number of categories to be used for randomly generated discrete variables. The default is 2. This needs to be greater or equal to than the minimum number of categories.</span>
            </li>
            <li>Default Value: <span id="maxCategories_default_value">2</span></li>
            <li>Lower Bound: <span id="maxCategories_lower_bound">2</span></li>
            <li>Upper Bound: <span id="maxCategories_upper_bound">2147483647</span></li>
            <li>Value Type: <span id="maxCategories_value_type">Integer</span></td>
        </ul>

        <h3 id="maxDegree" class="parameter_description">maxDegree</h3>
        <ul class="parameter_description_list">
            <li>Short Description: <span id="maxDegree_short_desc">The maximum degree of the graph (min = -1)</span>
            </li>
            <li>Long Description: <span id="maxDegree_long_desc">It is possible for a random graph to have a single node with very high degree—i.e. number of adjacent edges. This parameter places an upper bound on the maximum such degree. If no limit is to be placed on the maximum degree, use the value -1.</span>
            </li>
            <li>Default Value: <span id="maxDegree_default_value">100</span></li>
            <li>Lower Bound: <span id="maxDegree_lower_bound">-1</span></li>
            <li>Upper Bound: <span id="maxDegree_upper_bound">2147483647</span></li>
            <li>Value Type: <span id="maxDegree_value_type">Integer</span></td>
        </ul>

        <h3 id="maxDistinctValuesDiscrete" class="parameter_description">maxDistinctValuesDiscrete</h3>
        <ul class="parameter_description_list">
            <li>Short Description: <span id="maxDistinctValuesDiscrete_short_desc">The maximum number of distinct values in a column for discrete variables (min = 0)</span>
            </li>
            <li>Long Description: <span id="maxDistinctValuesDiscrete_long_desc">Discrete variables will be simulated using any number of categories from 2 up to this maximum. If set to 0 or 1, discrete variables will not be generated.</span>
            </li>
            <li>Default Value: <span id="maxDistinctValuesDiscrete_default_value">0</span></li>
            <li>Lower Bound: <span id="maxDistinctValuesDiscrete_lower_bound">0</span></li>
            <li>Upper Bound: <span id="maxDistinctValuesDiscrete_upper_bound">2147483647</span></li>
            <li>Value Type: <span id="maxDistinctValuesDiscrete_value_type">Integer</span></td>
        </ul>

        <h3 id="maxIndegree" class="parameter_description">maxIndegree</h3>
        <ul class="parameter_description_list">
            <li>Short Description: <span id="maxIndegree_short_desc">Maximum indegree of graph (min = 1)</span></li>
            <li>Long Description: <span id="maxIndegree_long_desc">It is possible for a random graph to have a node in which there is a very large “indegree”—that is, number of parents, or number of edges into that node. This parameter places a bound on the maximum such indegree. If no limit is to be placed on the maximum indegree, use the value -1.</span>
            </li>
            <li>Default Value: <span id="maxIndegree_default_value">100</span></li>
            <li>Lower Bound: <span id="maxIndegree_lower_bound">1</span></li>
            <li>Upper Bound: <span id="maxIndegree_upper_bound">2147483647</span></li>
            <li>Value Type: <span id="maxIndegree_value_type">Integer</span></td>
        </ul>

        <h3 id="maxIterations" class="parameter_description">maxIterations</h3>
        <ul class="parameter_description_list">
            <li>Short Description: <span id="maxIterations_short_desc">The maximum number of iterations the algorithm should go through orienting edges</span>
            </li>
            <li>Long Description: <span id="maxIterations_long_desc">In orienting, this algorith may go through a number of iterations, conditioning on more and more variables until orientations are set. This sets that number.</span>
            </li>
            <li>Default Value: <span id="maxIterations_default_value">15</span></li>
            <li>Lower Bound: <span id="maxIterations_lower_bound">0</span></li>
            <li>Upper Bound: <span id="maxIterations_upper_bound">2147483647</span></li>
            <li>Value Type: <span id="maxIterations_value_type">Integer</span></td>
        </ul>

        <h3 id="maxOutdegree" class="parameter_description">maxOutdegree</h3>
        <ul class="parameter_description_list">
            <li>Short Description: <span id="maxOutdegree_short_desc">Maximum outdegree of graph (min = 1)</span></li>
            <li>Long Description: <span id="maxOutdegree_long_desc">It is possible for a random graph to have a node in which there is a very large “outdegree”—that is, number of children, or number of edges out of that node. This parameter places a bound on the maximum such outdegree. If no limit is to be placed on the max outdegree, use the value -1.</span>
            </li>
            <li>Default Value: <span id="maxOutdegree_default_value">100</span></li>
            <li>Lower Bound: <span id="maxOutdegree_lower_bound">1</span></li>
            <li>Upper Bound: <span id="maxOutdegree_upper_bound">2147483647</span></li>
            <li>Value Type: <span id="maxOutdegree_value_type">Integer</span></td>
        </ul>

        <h3 id="maxPOrientationMaxPathLength" class="parameter_description">maxPOrientationMaxPathLength</h3>
        <ul class="parameter_description_list">
            <li>Short Description: <span id="maxPOrientationMaxPathLength_short_desc">Maximum path length for the unshielded collider heuristic for max P (min = 0)</span>
            </li>
            <li>Long Description: <span id="maxPOrientationMaxPathLength_long_desc">For the Max P “heuristic” to work, it must be the case that X and Z are only weakly associated—that is, that paths between them are not too short. This bounds the length of paths for this purpose.</span>
            </li>
            <li>Default Value: <span id="maxPOrientationMaxPathLength_default_value">3</span></li>
            <li>Lower Bound: <span id="maxPOrientationMaxPathLength_lower_bound">0</span></li>
            <li>Upper Bound: <span id="maxPOrientationMaxPathLength_upper_bound">2147483647</span></li>
            <li>Value Type: <span id="maxPOrientationMaxPathLength_value_type">Integer</span></td>
        </ul>

        <h3 id="maxPathLength" class="parameter_description">maxPathLength</h3>
        <ul class="parameter_description_list">
            <li>Short Description: <span id="maxPathLength_short_desc">The maximum length for any discriminating path. -1 if unlimited (min = -1)</span>
            </li>
            <li>Long Description: <span id="maxPathLength_long_desc">See Spirtes, Glymour, and Scheines (2000), Causation, Prediction, and Search for the definition of discrimination path. Finding discriminating paths can be expensive. This sets the maximum length of such paths that the algorithm tries to find.</span>
            </li>
            <li>Default Value: <span id="maxPathLength_default_value">-1</span></li>
            <li>Lower Bound: <span id="maxPathLength_lower_bound">-1</span></li>
            <li>Upper Bound: <span id="maxPathLength_upper_bound">2147483647</span></li>
            <li>Value Type: <span id="maxPathLength_value_type">Integer</span></td>
        </ul>

        <h3 id="maxit" class="parameter_description">maxit</h3>
        <ul class="parameter_description_list">
            <li>Short Description: <span id="maxit_short_desc">MAXIT parameter (GLASSO) (min = 1)</span></li>
            <li>Long Description: <span id="maxit_long_desc">The R Fortan implementation of GLASSO (https://CRAN.R-project.org/package=glasso) includes a number of parameters, of which this is one. This is the maximum number of iterations of the optimization loop.</span>
            </li>
            <li>Default Value: <span id="maxit_default_value">10000</span></li>
            <li>Lower Bound: <span id="maxit_lower_bound">1</span></li>
            <li>Upper Bound: <span id="maxit_upper_bound">2147483647</span></li>
            <li>Value Type: <span id="maxit_value_type">Integer</span></td>
        </ul>

        <h3 id="meanHigh" class="parameter_description">meanHigh</h3>
        <ul class="parameter_description_list">
            <li>Short Description: <span id="meanHigh_short_desc">High end of mean range (min = 0.0)</span></li>
            <li>Long Description: <span id="meanHigh_long_desc">For a linear model, means of variables may be randomly shifted. The default is for there to be no shift, but shifts from a minimum value to a maximum value may be specified. The minimum must be less than or equal to the maximum.</span>
            </li>
            <li>Default Value: <span id="meanHigh_default_value">1.5</span></li>
            <li>Lower Bound: <span id="meanHigh_lower_bound">0.0</span></li>
            <li>Upper Bound: <span id="meanHigh_upper_bound">1.7976931348623157E308</span></li>
            <li>Value Type: <span id="meanHigh_value_type">Double</span></li>
        </ul>

        <h3 id="meanLow" class="parameter_description">meanLow</h3>
        <ul class="parameter_description_list">
            <li>Short Description: <span id="meanLow_short_desc">Low end of mean range (min = 0.0)</span></li>
            <li>Long Description: <span id="meanLow_long_desc">For a linear model, means of variables may be randomly shifted. The default is for there to be no shift, but shifts from a minimum value to a maximum value may be specified. The minimum must be less than or equal to the maximum.</span>
            </li>
            <li>Default Value: <span id="meanLow_default_value">0.5</span></li>
            <li>Lower Bound: <span id="meanLow_lower_bound">0.0</span></li>
            <li>Upper Bound: <span id="meanLow_upper_bound">1.7976931348623157E308</span></li>
            <li>Value Type: <span id="meanLow_value_type">Double</span></li>
        </ul>

        <h3 id="measuredMeasuredImpureAssociations" class="parameter_description">
            measuredMeasuredImpureAssociations</h3>
        <ul class="parameter_description_list">
            <li>Short Description: <span id="measuredMeasuredImpureAssociations_short_desc">Number of Measured <-> Measured impure edges</span>
            </li>
            <li>Long Description: <span id="measuredMeasuredImpureAssociations_long_desc">It is possible for measures from two different structural nodes to be confounded. These confounding (bidirected) edges will be considered to be impure.</span>
            </li>
            <li>Default Value: <span id="measuredMeasuredImpureAssociations_default_value">0</span></li>
            <li>Lower Bound: <span id="measuredMeasuredImpureAssociations_lower_bound">-2147483648</span></li>
            <li>Upper Bound: <span id="measuredMeasuredImpureAssociations_upper_bound">2147483647</span></li>
            <li>Value Type: <span id="measuredMeasuredImpureAssociations_value_type">Integer</span></td>
        </ul>

        <h3 id="measuredMeasuredImpureParents" class="parameter_description">measuredMeasuredImpureParents</h3>
        <ul class="parameter_description_list">
            <li>Short Description: <span id="measuredMeasuredImpureParents_short_desc">Number of Measured --> Measured impure edges</span>
            </li>
            <li>Long Description: <span id="measuredMeasuredImpureParents_long_desc">It is possible for measures from two different structural nodes to have directed edges between them. These edges will be considered to be impure.</span>
            </li>
            <li>Default Value: <span id="measuredMeasuredImpureParents_default_value">0</span></li>
            <li>Lower Bound: <span id="measuredMeasuredImpureParents_lower_bound">-2147483648</span></li>
            <li>Upper Bound: <span id="measuredMeasuredImpureParents_upper_bound">2147483647</span></li>
            <li>Value Type: <span id="measuredMeasuredImpureParents_value_type">Integer</span></td>
        </ul>

        <h3 id="measurementModelDegree" class="parameter_description">measurementModelDegree</h3>
        <ul class="parameter_description_list">
            <li>Short Description: <span id="measurementModelDegree_short_desc">Number of measurements per Latent</span>
            </li>
            <li>Long Description: <span id="measurementModelDegree_long_desc">Each structural node in the MIM will be created to have this many measured children.</span>
            </li>
            <li>Default Value: <span id="measurementModelDegree_default_value">5</span></li>
            <li>Lower Bound: <span id="measurementModelDegree_lower_bound">-2147483648</span></li>
            <li>Upper Bound: <span id="measurementModelDegree_upper_bound">2147483647</span></li>
            <li>Value Type: <span id="measurementModelDegree_value_type">Integer</span></td>
        </ul>

        <h3 id="measurementVariance" class="parameter_description">measurementVariance</h3>
        <ul class="parameter_description_list">
            <li>Short Description: <span id="measurementVariance_short_desc">Additive measurement noise variance (min = 0.0)</span>
            </li>
            <li>Long Description: <span id="measurementVariance_long_desc">One difficult problem one encounters for analyzing real data is measurement noise—that is, once the actual values V of a variable are determined, there is some additional noise M added on top of that, so that the effect value is V + M, not V. We will assume here what is often assumed, that this noise is additive and Gaussian, with some variance. If this parameter value is set to zero, no measurement noise is added to the dataset per variable. Otherwise, if the value is greater than zero, independent Gaussian noise will be added with mean zero and the given variance.</span>
            </li>
            <li>Default Value: <span id="measurementVariance_default_value">0.0</span></li>
            <li>Lower Bound: <span id="measurementVariance_lower_bound">0.0</span></li>
            <li>Upper Bound: <span id="measurementVariance_upper_bound">1.7976931348623157E308</span></li>
            <li>Value Type: <span id="measurementVariance_value_type">Double</span></li>
        </ul>

        <h3 id="mgmParam1" class="parameter_description">mgmParam1</h3>
        <ul class="parameter_description_list">
            <li>Short Description: <span id="mgmParam1_short_desc">MGM tuning parameter #1 (min = 0.0)</span></li>
            <li>Long Description: <span id="mgmParam1_long_desc">The MGM algorithm has three internal tuning parameters, of which this is one.</span>
            </li>
            <li>Default Value: <span id="mgmParam1_default_value">0.1</span></li>
            <li>Lower Bound: <span id="mgmParam1_lower_bound">0.0</span></li>
            <li>Upper Bound: <span id="mgmParam1_upper_bound">1.7976931348623157E308</span></li>
            <li>Value Type: <span id="mgmParam1_value_type">Double</span></li>
        </ul>

        <h3 id="mgmParam2" class="parameter_description">mgmParam2</h3>
        <ul class="parameter_description_list">
            <li>Short Description: <span id="mgmParam2_short_desc">MGM tuning parameter #2 (min = 0.0)</span></li>
            <li>Long Description: <span id="mgmParam2_long_desc">The MGM algorithm has three internal tuning parameters, of which this is one.</span>
            </li>
            <li>Default Value: <span id="mgmParam2_default_value">0.1</span></li>
            <li>Lower Bound: <span id="mgmParam2_lower_bound">0.0</span></li>
            <li>Upper Bound: <span id="mgmParam2_upper_bound">1.7976931348623157E308</span></li>
            <li>Value Type: <span id="mgmParam2_value_type">Double</span></li>
        </ul>

        <h3 id="mgmParam3" class="parameter_description">mgmParam3</h3>
        <ul class="parameter_description_list">
            <li>Short Description: <span id="mgmParam3_short_desc">MGM tuning parameter #3 (min = 0.0)</span></li>
            <li>Long Description: <span id="mgmParam3_long_desc">The MGM algorithm has three internal tuning parameters, of which this is one.</span>
            </li>
            <li>Default Value: <span id="mgmParam3_default_value">0.1</span></li>
            <li>Lower Bound: <span id="mgmParam3_lower_bound">0.0</span></li>
            <li>Upper Bound: <span id="mgmParam3_upper_bound">1.7976931348623157E308</span></li>
            <li>Value Type: <span id="mgmParam3_value_type">Double</span></li>
        </ul>

        <h3 id="minCategories" class="parameter_description">minCategories</h3>
        <ul class="parameter_description_list">
            <li>Short Description: <span id="minCategories_short_desc">Minimum number of categories (min = 2)</span>
            </li>
            <li>Long Description: <span id="minCategories_long_desc">The minimum number of categories to be used for randomly generated discrete variables. The default is 2.</span>
            </li>
            <li>Default Value: <span id="minCategories_default_value">2</span></li>
            <li>Lower Bound: <span id="minCategories_lower_bound">2</span></li>
            <li>Upper Bound: <span id="minCategories_upper_bound">2147483647</span></li>
            <li>Value Type: <span id="minCategories_value_type">Integer</span></td>
        </ul>

        <h3 id="noRandomlyDeterminedIndependence" class="parameter_description">noRandomlyDeterminedIndependence</h3>
        <ul class="parameter_description_list">
            <li>Short Description: <span id="noRandomlyDeterminedIndependence_short_desc">Yes, if use the cutoff threshold for the independence test.</span>
            </li>
            <li>Long Description: <span id="noRandomlyDeterminedIndependence_long_desc">null</span></li>
            <li>Default Value: <span id="noRandomlyDeterminedIndependence_default_value">false</span></li>
            <li>Lower Bound: <span id="noRandomlyDeterminedIndependence_lower_bound"></span></li>
            <li>Upper Bound: <span id="noRandomlyDeterminedIndependence_upper_bound"></span></li>
            <li>Value Type: <span id="noRandomlyDeterminedIndependence_value_type">Boolean</span></li>
        </ul>

        <h3 id="numBasisFunctions" class="parameter_description">numBasisFunctions</h3>
        <ul class="parameter_description_list">
            <li>Short Description: <span id="numBasisFunctions_short_desc">Number of functions to use in (truncated) basis</span>
            </li>
            <li>Long Description: <span id="numBasisFunctions_long_desc">The types of bases that we’re using here (Gaussian, Epinechnikov) have an infinite number of functions in them, but we’re only using a finite number of them, the most significant ones. This parameter specifies how many of the most significant basis functions to use. The default is 30.</span>
            </li>
            <li>Default Value: <span id="numBasisFunctions_default_value">30</span></li>
            <li>Lower Bound: <span id="numBasisFunctions_lower_bound">1</span></li>
            <li>Upper Bound: <span id="numBasisFunctions_upper_bound">2147483647</span></li>
            <li>Value Type: <span id="numBasisFunctions_value_type">Integer</span></td>
        </ul>

        <h3 id="numBscBootstrapSamples" class="parameter_description">numBscBootstrapSamples</h3>
        <ul class="parameter_description_list">
            <li>Short Description: <span id="numBscBootstrapSamples_short_desc">The number of bootstrappings drawing from posterior dist. (min = 1)</span>
            </li>
            <li>Long Description: <span id="numBscBootstrapSamples_long_desc">null</span></li>
            <li>Default Value: <span id="numBscBootstrapSamples_default_value">50</span></li>
            <li>Lower Bound: <span id="numBscBootstrapSamples_lower_bound">1</span></li>
            <li>Upper Bound: <span id="numBscBootstrapSamples_upper_bound">2147483647</span></li>
            <li>Value Type: <span id="numBscBootstrapSamples_value_type">Integer</span></td>
        </ul>

        <h3 id="numCategories" class="parameter_description">numCategories</h3>
        <ul class="parameter_description_list">
            <li>Short Description: <span id="numCategories_short_desc">Number of categories for discrete variables (min = 2)</span>
            </li>
            <li>Long Description: <span id="numCategories_long_desc">The number of categories to be used for randomly generated discrete variables. The default is 4; the minimum is 2.</span>
            </li>
            <li>Default Value: <span id="numCategories_default_value">4</span></li>
            <li>Lower Bound: <span id="numCategories_lower_bound">2</span></li>
            <li>Upper Bound: <span id="numCategories_upper_bound">2147483647</span></li>
            <li>Value Type: <span id="numCategories_value_type">Integer</span></td>
        </ul>

        <h3 id="numCategoriesToDiscretize" class="parameter_description">numCategoriesToDiscretize</h3>
        <ul class="parameter_description_list">
            <li>Short Description: <span id="numCategoriesToDiscretize_short_desc">The number of categories used to discretize continuous variables, if necessary (min = 2)</span>
            </li>
            <li>Long Description: <span id="numCategoriesToDiscretize_long_desc">If the exact algorithm is desired for discrete children and continuous parents is not used, the conditional Gaussian likelihood needs to keep a copy of all continuous variables on hand, discretized with a certain number of categories. This parameter gives the number of categories to use for this second backup copy of the continuous variables.</span>
            </li>
            <li>Default Value: <span id="numCategoriesToDiscretize_default_value">3</span></li>
            <li>Lower Bound: <span id="numCategoriesToDiscretize_lower_bound">2</span></li>
            <li>Upper Bound: <span id="numCategoriesToDiscretize_upper_bound">2147483647</span></li>
            <li>Value Type: <span id="numCategoriesToDiscretize_value_type">Integer</span></td>
        </ul>

        <h3 id="numLags" class="parameter_description">numLags</h3>
        <ul class="parameter_description_list">
            <li>Short Description: <span id="numLags_short_desc">The number of lags in the time lag model</span></li>
            <li>Long Description: <span id="numLags_long_desc">A time lag model may take variables from previous time steps into account. This determines how many steps back these relevant variables might go.</span>
            </li>
            <li>Default Value: <span id="numLags_default_value">1</span></li>
            <li>Lower Bound: <span id="numLags_lower_bound">-2147483648</span></li>
            <li>Upper Bound: <span id="numLags_upper_bound">2147483647</span></li>
            <li>Value Type: <span id="numLags_value_type">Integer</span></td>
        </ul>

        <h3 id="numLatents" class="parameter_description">numLatents</h3>
        <ul class="parameter_description_list">
            <li>Short Description: <span id="numLatents_short_desc">Number of latent variables (min = 0)</span></li>
            <li>Long Description: <span id="numLatents_long_desc">A latent (or ‘unmeasured’) variable is one for which values are not recorded in the dataset being analyzed. These are variables that affect the measured variables but which are not included in the final dataset. This situation comes up frequently when analyzing real data, so it is important to be able to generate random datasets with this feature, in order to see how the algorithms react to the existence of latent variables. Some algorithms, like FCI, FFCI, FOFC, FTFC, and such, are correct when some variables not measured affect the data.</span>
            </li>
            <li>Default Value: <span id="numLatents_default_value">0</span></li>
            <li>Lower Bound: <span id="numLatents_lower_bound">0</span></li>
            <li>Upper Bound: <span id="numLatents_upper_bound">2147483647</span></li>
            <li>Value Type: <span id="numLatents_value_type">Integer</span></td>
        </ul>

        <h3 id="numMeasures" class="parameter_description">numMeasures</h3>
        <ul class="parameter_description_list">
            <li>Short Description: <span id="numMeasures_short_desc">Number of measured variables (min = 1)</span></li>
            <li>Long Description: <span id="numMeasures_long_desc">A measured variable is one for which values are recorded in the dataset being analyzed. This parameter sets the number of measured variables to be randomly simulated; this will be the number of columns in the dataset.</span>
            </li>
            <li>Default Value: <span id="numMeasures_default_value">10</span></li>
            <li>Lower Bound: <span id="numMeasures_lower_bound">1</span></li>
            <li>Upper Bound: <span id="numMeasures_upper_bound">2147483647</span></li>
            <li>Value Type: <span id="numMeasures_value_type">Integer</span></td>
        </ul>

        <h3 id="numRandomizedSearchModels" class="parameter_description">numRandomizedSearchModels</h3>
        <ul class="parameter_description_list">
            <li>Short Description: <span id="numRandomizedSearchModels_short_desc">The number of search probabilistic model (min = 1)</span>
            </li>
            <li>Long Description: <span id="numRandomizedSearchModels_long_desc">null</span></li>
            <li>Default Value: <span id="numRandomizedSearchModels_default_value">10</span></li>
            <li>Lower Bound: <span id="numRandomizedSearchModels_lower_bound">1</span></li>
            <li>Upper Bound: <span id="numRandomizedSearchModels_upper_bound">2147483647</span></li>
            <li>Value Type: <span id="numRandomizedSearchModels_value_type">Integer</span></td>
        </ul>

        <h3 id="numRuns" class="parameter_description">numRuns</h3>
        <ul class="parameter_description_list">
            <li>Short Description: <span id="numRuns_short_desc">Number of runs (min = 1)</span></li>
            <li>Long Description: <span id="numRuns_long_desc">An analysis(randomly pick graph, randomly simulate a dataset, run an algorithm on it, look at the result) may be run over and over again, repeatedly, and results summarized. This parameter indicates the number of repetitions that should be done for the analysis. The minimum is 1.</span>
            </li>
            <li>Default Value: <span id="numRuns_default_value">1</span></li>
            <li>Lower Bound: <span id="numRuns_lower_bound">1</span></li>
            <li>Upper Bound: <span id="numRuns_upper_bound">2147483647</span></li>
            <li>Value Type: <span id="numRuns_value_type">Integer</span></td>
        </ul>

        <h3 id="numStructuralEdges" class="parameter_description">numStructuralEdges</h3>
        <ul class="parameter_description_list">
            <li>Short Description: <span id="numStructuralEdges_short_desc">Number of structural edges</span></li>
            <li>Long Description: <span id="numStructuralEdges_long_desc">This is a parameter for generating random multiple indictor models (MIMs). A structural edge is an edge connecting two structural nodes.</span>
            </li>
            <li>Default Value: <span id="numStructuralEdges_default_value">3</span></li>
            <li>Lower Bound: <span id="numStructuralEdges_lower_bound">-2147483648</span></li>
            <li>Upper Bound: <span id="numStructuralEdges_upper_bound">2147483647</span></li>
            <li>Value Type: <span id="numStructuralEdges_value_type">Integer</span></td>
        </ul>

        <h3 id="numStructuralNodes" class="parameter_description">numStructuralNodes</h3>
        <ul class="parameter_description_list">
            <li>Short Description: <span id="numStructuralNodes_short_desc">Number of structural nodes</span></li>
            <li>Long Description: <span id="numStructuralNodes_long_desc">This is a parameter for generating random multiple indictor models (MIMs). A structural node is one of the latent variables in the model; each structural node has a number of child measured variables.</span>
            </li>
            <li>Default Value: <span id="numStructuralNodes_default_value">3</span></li>
            <li>Lower Bound: <span id="numStructuralNodes_lower_bound">-2147483648</span></li>
            <li>Upper Bound: <span id="numStructuralNodes_upper_bound">2147483647</span></li>
            <li>Value Type: <span id="numStructuralNodes_value_type">Integer</span></td>
        </ul>

        <h3 id="numberResampling" class="parameter_description">numberResampling</h3>
        <ul class="parameter_description_list">
            <li>Short Description: <span id="numberResampling_short_desc">The number of bootstraps/resampling iterations (min = 0)</span>
            </li>
            <li>Long Description: <span id="numberResampling_long_desc">For bootstrapping, the number of bootstrap iterations that should be done by the algorithm, with results summarized.</span>
            </li>
            <li>Default Value: <span id="numberResampling_default_value">0</span></li>
            <li>Lower Bound: <span id="numberResampling_lower_bound">0</span></li>
            <li>Upper Bound: <span id="numberResampling_upper_bound">2147483647</span></li>
            <li>Value Type: <span id="numberResampling_value_type">Integer</span></td>
        </ul>

        <h3 id="orientTowardDConnections" class="parameter_description">orientTowardDConnections</h3>
        <ul class="parameter_description_list">
            <li>Short Description: <span id="orientTowardDConnections_short_desc">Yes if Richardson's step C (orient toward d-connection) should be used</span>
            </li>
            <li>Long Description: <span id="orientTowardDConnections_long_desc">Please see the description of this algorithm in Thomas Richardson and Peter Spirtes in Chapter 7 of Computation, Causation, & Discovery by Glymour and Cooper eds.</span>
            </li>
            <li>Default Value: <span id="orientTowardDConnections_default_value">true</span></li>
            <li>Lower Bound: <span id="orientTowardDConnections_lower_bound"></span></li>
            <li>Upper Bound: <span id="orientTowardDConnections_upper_bound"></span></li>
            <li>Value Type: <span id="orientTowardDConnections_value_type">Boolean</span></li>
        </ul>

        <h3 id="orientVisibleFeedbackLoops" class="parameter_description">orientVisibleFeedbackLoops</h3>
        <ul class="parameter_description_list">
            <li>Short Description: <span id="orientVisibleFeedbackLoops_short_desc">Yes if visible feedback loops should be oriented</span>
            </li>
            <li>Long Description: <span id="orientVisibleFeedbackLoops_long_desc">Please see the description of this algorithm in Thomas Richardson and Peter Spirtes in Chapter 7 of Computation, Causation, & Discovery by Glymour and Cooper eds.</span>
            </li>
            <li>Default Value: <span id="orientVisibleFeedbackLoops_default_value">true</span></li>
            <li>Lower Bound: <span id="orientVisibleFeedbackLoops_lower_bound"></span></li>
            <li>Upper Bound: <span id="orientVisibleFeedbackLoops_upper_bound"></span></li>
            <li>Value Type: <span id="orientVisibleFeedbackLoops_value_type">Boolean</span></li>
        </ul>

        <h3 id="outputRBD" class="parameter_description">outputRBD</h3>
        <ul class="parameter_description_list">
            <li>Short Description: <span id="outputRBD_short_desc">Output graph: Yes: dependent-constraint RB, No: independent-constraint RB.</span>
            </li>
            <li>Long Description: <span id="outputRBD_long_desc">null</span></li>
            <li>Default Value: <span id="outputRBD_default_value">true</span></li>
            <li>Lower Bound: <span id="outputRBD_lower_bound"></span></li>
            <li>Upper Bound: <span id="outputRBD_upper_bound"></span></li>
            <li>Value Type: <span id="outputRBD_value_type">Boolean</span></li>
        </ul>

        <h3 id="penaltyDiscount" class="parameter_description">penaltyDiscount</h3>
        <ul class="parameter_description_list">
            <li>Short Description: <span id="penaltyDiscount_short_desc">Penalty discount (min = 0.0)</span></li>
            <li>Long Description: <span id="penaltyDiscount_long_desc">A BIC score is of the form 2L – k ln N, where L is the likelihood, k the number of degrees of freedom, and N the sample size. Tests based on this statistic can often yield too dense a graph; to compensate for this, we add a factor c, as follows: 2L – c k ln N, where usually c >= 1. If c is chosen to be greater than 1, say 2, the output graph will be sparser. We call this c the “penalty discount”; similar mechanisms have been proposed elsewhere.</span>
            </li>
            <li>Default Value: <span id="penaltyDiscount_default_value">2.0</span></li>
            <li>Lower Bound: <span id="penaltyDiscount_lower_bound">0.0</span></li>
            <li>Upper Bound: <span id="penaltyDiscount_upper_bound">1.7976931348623157E308</span></li>
            <li>Value Type: <span id="penaltyDiscount_value_type">Double</span></li>
        </ul>

        <h3 id="percentDiscrete" class="parameter_description">percentDiscrete</h3>
        <ul class="parameter_description_list">
            <li>Short Description: <span id="percentDiscrete_short_desc">Percentage of discrete variables (0 - 100) for mixed data</span>
            </li>
            <li>Long Description: <span id="percentDiscrete_long_desc">For a mixed data type simulation, specifies the percentage of variables that should be simulated (randomly) as discrete. The rest will be taken to be continuous. The default is 0—i.e. no discrete variables.</span>
            </li>
            <li>Default Value: <span id="percentDiscrete_default_value">0.0</span></li>
            <li>Lower Bound: <span id="percentDiscrete_lower_bound">0.0</span></li>
            <li>Upper Bound: <span id="percentDiscrete_upper_bound">100.0</span></li>
            <li>Value Type: <span id="percentDiscrete_value_type">Double</span></li>
        </ul>

        <h3 id="percentResampleSize" class="parameter_description">percentResampleSize</h3>
        <ul class="parameter_description_list">
            <li>Short Description: <span
                    id="percentResampleSize_short_desc">The percentage of resample size (min = 0.1)</span></li>
            <li>Long Description: <span id="percentResampleSize_long_desc">Each bootstrap iteration uses a certain portion of the data drawn randomly either with replacement or without replacement. This parameter specifies the percentage of records in the bootstrap (as a percentage of the total original sample size of the data being bootstrapped), in the range 1 to 100.</span>
            </li>
            <li>Default Value: <span id="percentResampleSize_default_value">100</span></li>
            <li>Lower Bound: <span id="percentResampleSize_lower_bound">-2147483648</span></li>
            <li>Upper Bound: <span id="percentResampleSize_upper_bound">2147483647</span></li>
            <li>Value Type: <span id="percentResampleSize_value_type">Integer</span></td>
        </ul>

        <h3 id="possibleDsepDone" class="parameter_description">possibleDsepDone</h3>
        <ul class="parameter_description_list">
            <li>Short Description: <span
                    id="possibleDsepDone_short_desc">Yes if the possible dsep search should be done</span></li>
            <li>Long Description: <span id="possibleDsepDone_long_desc">This algorithm has a possible d-sep path search, which can be time-consuming. See Spirtes, Glymour, and Scheines, Causation, Prediction and Search for details.</span>
            </li>
            <li>Default Value: <span id="possibleDsepDone_default_value">true</span></li>
            <li>Lower Bound: <span id="possibleDsepDone_lower_bound"></span></li>
            <li>Upper Bound: <span id="possibleDsepDone_upper_bound"></span></li>
            <li>Value Type: <span id="possibleDsepDone_value_type">Boolean</span></li>
        </ul>

        <h3 id="probCycle" class="parameter_description">probCycle</h3>
        <ul class="parameter_description_list">
            <li>Short Description: <span id="probCycle_short_desc">The probability of adding a cycle to the graph</span>
            </li>
            <li>Long Description: <span id="probCycle_long_desc">One way to add cycles to a graph is to pick a group of 3, 4, or 5 nodes and create a cycle between those variables. A graph may be constructed in this way consisting entirely of cycles, and this graph may then be used to test algorithms that should be able to handle cycles. This parameter sets the probability that any particular such set of nodes will be used to form a cycle in the graph.</span>
            </li>
            <li>Default Value: <span id="probCycle_default_value">1.0</span></li>
            <li>Lower Bound: <span id="probCycle_lower_bound">0.0</span></li>
            <li>Upper Bound: <span id="probCycle_upper_bound">1.0</span></li>
            <li>Value Type: <span id="probCycle_value_type">Double</span></li>
        </ul>

        <h3 id="probTwoCycle" class="parameter_description">probTwoCycle</h3>
        <ul class="parameter_description_list">
            <li>Short Description: <span id="probTwoCycle_short_desc">The probability of creating a 2-cycles in the graph (0 - 1)</span>
            </li>
            <li>Long Description: <span id="probTwoCycle_long_desc">The types of bases that we’re using here (Gaussian, Epinechnikov) have an infinite number of functions in them, but we’re only using a finite number of them, the most significant ones. This parameter specifies how many of the most significant basis functions to use. The default is 30.</span>
            </li>
            <li>Default Value: <span id="probTwoCycle_default_value">0.0</span></li>
            <li>Lower Bound: <span id="probTwoCycle_lower_bound">0.0</span></li>
            <li>Upper Bound: <span id="probTwoCycle_upper_bound">1.0</span></li>
            <li>Value Type: <span id="probTwoCycle_value_type">Double</span></li>
        </ul>

        <h3 id="randomSelectionSize" class="parameter_description">randomSelectionSize</h3>
        <ul class="parameter_description_list">
            <li>Short Description: <span id="randomSelectionSize_short_desc">The number of datasets that should be taken in each random sample</span>
            </li>
            <li>Long Description: <span id="randomSelectionSize_long_desc">This parameter is for algorithms that take multiple datasets as input, such as IMaGES. The idea is that maybe you have 100 dataset but want to take a random sample of 5 such datasets. This parameter, in this example, is ‘5’. It is the number of dataset that should be taken in each random sample of datasets.</span>
            </li>
            <li>Default Value: <span id="randomSelectionSize_default_value">1</span></li>
            <li>Lower Bound: <span id="randomSelectionSize_lower_bound">-2147483648</span></li>
            <li>Upper Bound: <span id="randomSelectionSize_upper_bound">2147483647</span></li>
            <li>Value Type: <span id="randomSelectionSize_value_type">Integer</span></td>
        </ul>

        <h3 id="randomizeColumns" class="parameter_description">randomizeColumns</h3>
        <ul class="parameter_description_list">
            <li>Short Description: <span id="randomizeColumns_short_desc">Yes if the order of the columns in each datasets should be randomized</span>
            </li>
            <li>Long Description: <span id="randomizeColumns_long_desc">It is usually the case that for graphs that are faithful to the true model the order of the columns in the dataset should not matter; you should always end up with the same model. However, in the real world where unfaithfulness is an issue this may not be true. To test the resilience of methods to random reordering of the columns in the data, set this parameter to “Yes”.</span>
            </li>
            <li>Default Value: <span id="randomizeColumns_default_value">false</span></li>
            <li>Lower Bound: <span id="randomizeColumns_lower_bound"></span></li>
            <li>Upper Bound: <span id="randomizeColumns_upper_bound"></span></li>
            <li>Value Type: <span id="randomizeColumns_value_type">Boolean</span></li>
        </ul>

        <h3 id="rcitNumFeatures" class="parameter_description">rcitNumFeatures</h3>
        <ul class="parameter_description_list">
            <li>Short Description: <span id="rcitNumFeatures_short_desc">The number of random features to use</span>
            </li>
            <li>Long Description: <span id="rcitNumFeatures_long_desc"></span></li>
            <li>Default Value: <span id="rcitNumFeatures_default_value">10</span></li>
            <li>Lower Bound: <span id="rcitNumFeatures_lower_bound">1</span></li>
            <li>Upper Bound: <span id="rcitNumFeatures_upper_bound">2147483647</span></li>
            <li>Value Type: <span id="rcitNumFeatures_value_type">Integer</span></td>
        </ul>

        <h3 id="resamplingEnsemble" class="parameter_description">resamplingEnsemble</h3>
        <ul class="parameter_description_list">
            <li>Short Description: <span id="resamplingEnsemble_short_desc">Ensemble method: Preserved (0), Highest (1), Majority (2)</span>
            </li>
            <li>Long Description: <span id="resamplingEnsemble_long_desc">This parameter governs how summary graphs are generated based on graphs learned from individual bootstrap samples. If “Preserved”, an edge is kept and its orientation is chosen based on the highest probability. If “Highest”, an edge is kept the same way the preserved ensemble one does except when [no edge]'s probability is the highest one, then the edge is ignored. If “Majority”, the edge is kept only if its chosen orientations' probability is more than 0.5. </span>
            </li>
            <li>Default Value: <span id="resamplingEnsemble_default_value">1</span></li>
            <li>Lower Bound: <span id="resamplingEnsemble_lower_bound">0</span></li>
            <li>Upper Bound: <span id="resamplingEnsemble_upper_bound">2</span></li>
            <li>Value Type: <span id="resamplingEnsemble_value_type">Integer</span></td>
        </ul>

        <h3 id="resamplingWithReplacement" class="parameter_description">resamplingWithReplacement</h3>
        <ul class="parameter_description_list">
            <li>Short Description: <span id="resamplingWithReplacement_short_desc">Yes, if sampling with replacement (bootstrapping)</span>
            </li>
            <li>Long Description: <span id="resamplingWithReplacement_long_desc">Resampling can be done with replacement or without replacement. If with replacement, it is possible to have more than one copy of some of the records in the original dataset being included in the bootstrap. This is what is usually meant by “bootstrap”. For this option, select “Yes” here. It is also possible to prevent repetitions and do so-called “random subsampling”; for this option, select “No” here.</span>
            </li>
            <li>Default Value: <span id="resamplingWithReplacement_default_value">true</span></li>
            <li>Lower Bound: <span id="resamplingWithReplacement_lower_bound"></span></li>
            <li>Upper Bound: <span id="resamplingWithReplacement_upper_bound"></span></li>
            <li>Value Type: <span id="resamplingWithReplacement_value_type">Boolean</span></li>
        </ul>

        <h3 id="samplePrior" class="parameter_description">samplePrior</h3>
        <ul class="parameter_description_list">
            <li>Short Description: <span id="samplePrior_short_desc">Sample prior (min = 1.0)</span></li>
            <li>Long Description: <span id="samplePrior_long_desc">For the BDeu score, this sets the prior equivalent sample size. This number is added to the sample size for each conditional probability table in the model and is divided equally among the cells in the table.</span>
            </li>
            <li>Default Value: <span id="samplePrior_default_value">1.0</span></li>
            <li>Lower Bound: <span id="samplePrior_lower_bound">1.0</span></li>
            <li>Upper Bound: <span id="samplePrior_upper_bound">1.7976931348623157E308</span></li>
            <li>Value Type: <span id="samplePrior_value_type">Double</span></li>
        </ul>

        <h3 id="sampleSize" class="parameter_description">sampleSize</h3>
        <ul class="parameter_description_list">
            <li>Short Description: <span id="sampleSize_short_desc">Sample size (min = 1)</span></li>
            <li>Long Description: <span id="sampleSize_long_desc">One of the main features of a dataset is the number of records in the data, or sample size, or N. When simulating random data, this parameter determines now many records should be generated for the data. The minimum number of records is 1; the default is set to 1000.</span>
            </li>
            <li>Default Value: <span id="sampleSize_default_value">1000</span></li>
            <li>Lower Bound: <span id="sampleSize_lower_bound">1</span></li>
            <li>Upper Bound: <span id="sampleSize_upper_bound">2147483647</span></li>
            <li>Value Type: <span id="sampleSize_value_type">Integer</span></td>
        </ul>

        <h3 id="saveLatentVars" class="parameter_description">saveLatentVars</h3>
        <ul class="parameter_description_list">
            <li>Short Description: <span id="saveLatentVars_short_desc">Save latent variables.</span></li>
            <li>Long Description: <span id="saveLatentVars_long_desc">When saving datasets, even though latent variables in simulation are supposed to be left out of the data, if one wishes to see what values those latent variables took on, one may opt to save the latent variables out with the rest of the data.</span>
            </li>
            <li>Default Value: <span id="saveLatentVars_default_value">false</span></li>
            <li>Lower Bound: <span id="saveLatentVars_lower_bound"></span></li>
            <li>Upper Bound: <span id="saveLatentVars_upper_bound"></span></li>
            <li>Value Type: <span id="saveLatentVars_value_type">Boolean</span></li>
        </ul>

        <h3 id="scaleFreeAlpha" class="parameter_description">scaleFreeAlpha</h3>
        <ul class="parameter_description_list">
            <li>Short Description: <span id="scaleFreeAlpha_short_desc">For scale-free graphs, the parameter alpha (min = 0.0)</span>
            </li>
            <li>Long Description: <span id="scaleFreeAlpha_long_desc">We use the algorithm for generating scale free graphs described in B. Bollobas,C. Borgs, J. Chayes, and O. Riordan, Directed scale-free graphs, Proceedings of the fourteenth annual ACM-SIAM symposium on Discrete algorithms, 132--139, 2003. Please see this article for a description of the parameters.</span>
            </li>
            <li>Default Value: <span id="scaleFreeAlpha_default_value">0.05</span></li>
            <li>Lower Bound: <span id="scaleFreeAlpha_lower_bound">0.0</span></li>
            <li>Upper Bound: <span id="scaleFreeAlpha_upper_bound">1.0</span></li>
            <li>Value Type: <span id="scaleFreeAlpha_value_type">Double</span></li>
        </ul>

        <h3 id="scaleFreeBeta" class="parameter_description">scaleFreeBeta</h3>
        <ul class="parameter_description_list">
            <li>Short Description: <span id="scaleFreeBeta_short_desc">For scale-free graphs, the parameter beta (min = 0.0)</span>
            </li>
            <li>Long Description: <span id="scaleFreeBeta_long_desc">We use the algorithm for generating scale free graphs described in B. Bollobas,C. Borgs, J. Chayes, and O. Riordan, Directed scale-free graphs, Proceedings of the fourteenth annual ACM-SIAM symposium on Discrete algorithms, 132--139, 2003. Please see this article for a description of the parameters.</span>
            </li>
            <li>Default Value: <span id="scaleFreeBeta_default_value">0.9</span></li>
            <li>Lower Bound: <span id="scaleFreeBeta_lower_bound">0.0</span></li>
            <li>Upper Bound: <span id="scaleFreeBeta_upper_bound">1.0</span></li>
            <li>Value Type: <span id="scaleFreeBeta_value_type">Double</span></li>
        </ul>

        <h3 id="scaleFreeDeltaIn" class="parameter_description">scaleFreeDeltaIn</h3>
        <ul class="parameter_description_list">
            <li>Short Description: <span id="scaleFreeDeltaIn_short_desc">For scale-free graphs, the parameter delta_in (min = 0.0)</span>
            </li>
            <li>Long Description: <span id="scaleFreeDeltaIn_long_desc">We use the algorithm for generating scale free graphs described in B. Bollobas,C. Borgs, J. Chayes, and O. Riordan, Directed scale-free graphs, Proceedings of the fourteenth annual ACM-SIAM symposium on Discrete algorithms, 132--139, 2003. Please see this article for a description of the parameters.</span>
            </li>
            <li>Default Value: <span id="scaleFreeDeltaIn_default_value">3</span></li>
            <li>Lower Bound: <span id="scaleFreeDeltaIn_lower_bound">-2147483648</span></li>
            <li>Upper Bound: <span id="scaleFreeDeltaIn_upper_bound">2147483647</span></li>
            <li>Value Type: <span id="scaleFreeDeltaIn_value_type">Integer</span></td>
        </ul>

        <h3 id="scaleFreeDeltaOut" class="parameter_description">scaleFreeDeltaOut</h3>
        <ul class="parameter_description_list">
            <li>Short Description: <span id="scaleFreeDeltaOut_short_desc">For scale-free graphs, the parameter delta_out (min = 0.0)</span>
            </li>
            <li>Long Description: <span id="scaleFreeDeltaOut_long_desc">We use the algorithm for generating scale free graphs described in B. Bollobas,C. Borgs, J. Chayes, and O. Riordan, Directed scale-free graphs, Proceedings of the fourteenth annual ACM-SIAM symposium on Discrete algorithms, 132--139, 2003. Please see this article for a description of the parameters.</span>
            </li>
            <li>Default Value: <span id="scaleFreeDeltaOut_default_value">3</span></li>
            <li>Lower Bound: <span id="scaleFreeDeltaOut_lower_bound">-2147483648</span></li>
            <li>Upper Bound: <span id="scaleFreeDeltaOut_upper_bound">2147483647</span></li>
            <li>Value Type: <span id="scaleFreeDeltaOut_value_type">Integer</span></td>
        </ul>

        <h3 id="selfLoopCoef" class="parameter_description">selfLoopCoef</h3>
        <ul class="parameter_description_list">
            <li>Short Description: <span
                    id="selfLoopCoef_short_desc">The coefficient for the self-loop (default 0.0)</span></li>
            <li>Long Description: <span id="selfLoopCoef_long_desc">For simulation time series data, each variable depends on itself one time-step back with a linear edge that has this coefficient.</span>
            </li>
            <li>Default Value: <span id="selfLoopCoef_default_value">0.0</span></li>
            <li>Lower Bound: <span id="selfLoopCoef_lower_bound">0.0</span></li>
            <li>Upper Bound: <span id="selfLoopCoef_upper_bound">Infinity</span></li>
            <li>Value Type: <span id="selfLoopCoef_value_type">Double</span></li>
        </ul>

        <h3 id="skipNumRecords" class="parameter_description">skipNumRecords</h3>
        <ul class="parameter_description_list">
            <li>Short Description: <span id="skipNumRecords_short_desc">Number of records that should be skipped between recordings (min = 0)</span>
            </li>
            <li>Long Description: <span id="skipNumRecords_long_desc">This is a parameter for the linear Fisher option. The idea of Fisher model (for the linear case) is to shock the system every so often and let it converge by applying the rules of transformation (that is, the linear model) repeatedly until convergence. Data recordings are made every so many steps. This is an additional parameter indicating how many data recordings are skipped before actually inserting a record into the returned dataset. This is useful to test the reaction of a method to missing time steps.</span>
            </li>
            <li>Default Value: <span id="skipNumRecords_default_value">0</span></li>
            <li>Lower Bound: <span id="skipNumRecords_lower_bound">0</span></li>
            <li>Upper Bound: <span id="skipNumRecords_upper_bound">2147483647</span></li>
            <li>Value Type: <span id="skipNumRecords_value_type">Integer</span></td>
        </ul>

        <h3 id="stableFAS" class="parameter_description">stableFAS</h3>
        <ul class="parameter_description_list">
            <li>Short Description: <span id="stableFAS_short_desc">Yes if the 'stable' FAS should be done</span></li>
            <li>Long Description: <span id="stableFAS_long_desc">In Colombo, D., & Maathuis, M. H. (2014, Order-independent constraint-based causal structure learning, The Journal of Machine Learning Research, 15(1), 3741-3782), a modification of the adjacency search of PC was proposed that results in invariance under order permutations of the variables in the data. If this parameter is set to ‘Yes’, this version of the PC adjacency search is used.</span>
            </li>
            <li>Default Value: <span id="stableFAS_default_value">false</span></li>
            <li>Lower Bound: <span id="stableFAS_lower_bound"></span></li>
            <li>Upper Bound: <span id="stableFAS_upper_bound"></span></li>
            <li>Value Type: <span id="stableFAS_value_type">Boolean</span></li>
        </ul>

        <h3 id="standardize" class="parameter_description">standardize</h3>
        <ul class="parameter_description_list">
            <li>Short Description: <span id="standardize_short_desc">Yes if the data should be standardized</span></li>
            <li>Long Description: <span id="standardize_long_desc">An operation one often wants to perform on a dataset is to standardize each of its variables by subtracting the mean and dividing the standard deviation. This yields a dataset in which each variable has mean zero and unit variance. If this parameter is set to ‘Yes’, this operation will be performed on the simulated dataset.</span>
            </li>
            <li>Default Value: <span id="standardize_default_value">false</span></li>
            <li>Lower Bound: <span id="standardize_lower_bound"></span></li>
            <li>Upper Bound: <span id="standardize_upper_bound"></span></li>
            <li>Value Type: <span id="standardize_value_type">Boolean</span></li>
        </ul>

        <h3 id="structurePrior" class="parameter_description">structurePrior</h3>
        <ul class="parameter_description_list">
            <li>Short Description: <span id="structurePrior_short_desc">Structure prior coefficient (min = 0.0)</span>
            </li>
            <li>Long Description: <span id="structurePrior_long_desc">For Tetrad, we use as a structure prior the default number of parents for any conditional probability table. Higher weight is accorded to tables with about that number of parents. The prior structure weights are distributed according to a binomial distribution.</span>
            </li>
            <li>Default Value: <span id="structurePrior_default_value">1.0</span></li>
            <li>Lower Bound: <span id="structurePrior_lower_bound">0.0</span></li>
            <li>Upper Bound: <span id="structurePrior_upper_bound">1.7976931348623157E308</span></li>
            <li>Value Type: <span id="structurePrior_value_type">Double</span></li>
        </ul>

        <h3 id="symmetricFirstStep" class="parameter_description">symmetricFirstStep</h3>
        <ul class="parameter_description_list">
            <li>Short Description: <span id="symmetricFirstStep_short_desc">Yes if the first step step for FGES should do scoring for both X->Y and Y->X</span>
            </li>
            <li>Long Description: <span id="symmetricFirstStep_long_desc">For discrete searches, and in some other situations, it may make a difference for an edge X—Y whether you score X->Y or X<-Y, even though theoretically they should have the same score. If this parameter is set to “Yes”, both scores will be calculated and the higher score used. (Recall we are calculating BIC as 2L – c k ln N, where c is the penalty discount.)</span>
            </li>
            <li>Default Value: <span id="symmetricFirstStep_default_value">false</span></li>
            <li>Lower Bound: <span id="symmetricFirstStep_lower_bound"></span></li>
            <li>Upper Bound: <span id="symmetricFirstStep_upper_bound"></span></li>
            <li>Value Type: <span id="symmetricFirstStep_value_type">Boolean</span></li>
        </ul>

        <h3 id="targetName" class="parameter_description">targetName</h3>
        <ul class="parameter_description_list">
            <li>Short Description: <span id="targetName_short_desc">Target variable name</span></li>
            <li>Long Description: <span id="targetName_long_desc">This parameter is for searches, such as Markov blanket searches, that require a target variable. In the case of a Markov blanket search, one is searching the graph over the Markov blanket of some target variable named V—this parameter specifies the name ‘V’.</span>
            </li>
            <li>Default Value: <span id="targetName_default_value"></span></li>
            <li>Lower Bound: <span id="targetName_lower_bound"></span></li>
            <li>Upper Bound: <span id="targetName_upper_bound"></span></li>
            <li>Value Type: <span id="targetName_value_type"></span></li>
        </ul>

        <h3 id="thr" class="parameter_description">thr</h3>
        <ul class="parameter_description_list">
            <li>Short Description: <span id="thr_short_desc">THR parameter (GLASSO) (min = 0.0)</span></li>
            <li>Long Description: <span id="thr_long_desc">The R Fortan implementation of GLASSO (https://CRAN.R-project.org/package=glasso) includes a number of parameters, of which this is one. This is the maximum number of iterations of the optimization loop.</span>
            </li>
            <li>Default Value: <span id="thr_default_value">1.0E-4</span></li>
            <li>Lower Bound: <span id="thr_lower_bound">0.0</span></li>
            <li>Upper Bound: <span id="thr_upper_bound">1.7976931348623157E308</span></li>
            <li>Value Type: <span id="thr_value_type">Double</span></li>
        </ul>

        <h3 id="thresholdForNumEigenvalues" class="parameter_description">thresholdForNumEigenvalues</h3>
        <ul class="parameter_description_list">
            <li>Short Description: <span id="thresholdForNumEigenvalues_short_desc">Threshold to determine how many eigenvalues to use--the lower the more (0 to 1)</span>
            </li>
            <li>Long Description: <span id="thresholdForNumEigenvalues_long_desc">We have a number of parameters here for the Kernel Conditional Independence Test (KCI). In order to understand the parameters, it is necessary to read the paper on which this test is based, here: Zhang, K., Peters, J., Janzing, D., & Schölkopf, B. (2012). Kernel-based conditional independence test and application in causal discovery. arXiv preprint arXiv:1202.3775. This parameter is the threshold to determine how many eigenvalues to use--the lower the more (0 to 1). The default value is 0.001; it must be a positive real number.</span>
            </li>
            <li>Default Value: <span id="thresholdForNumEigenvalues_default_value">0.001</span></li>
            <li>Lower Bound: <span id="thresholdForNumEigenvalues_lower_bound">0.0</span></li>
            <li>Upper Bound: <span id="thresholdForNumEigenvalues_upper_bound">Infinity</span></li>
            <li>Value Type: <span id="thresholdForNumEigenvalues_value_type">Double</span></li>
        </ul>

        <h3 id="thresholdNoRandomConstrainSearch" class="parameter_description">thresholdNoRandomConstrainSearch</h3>
        <ul class="parameter_description_list">
            <li>Short Description: <span id="thresholdNoRandomConstrainSearch_short_desc">Yes, if use the cutoff threshold for the meta-constraints independence test (stage 2).</span>
            </li>
            <li>Long Description: <span id="thresholdNoRandomConstrainSearch_long_desc">null</span></li>
            <li>Default Value: <span id="thresholdNoRandomConstrainSearch_default_value">true</span></li>
            <li>Lower Bound: <span id="thresholdNoRandomConstrainSearch_lower_bound"></span></li>
            <li>Upper Bound: <span id="thresholdNoRandomConstrainSearch_upper_bound"></span></li>
            <li>Value Type: <span id="thresholdNoRandomConstrainSearch_value_type">Boolean</span></li>
        </ul>

        <h3 id="thresholdNoRandomDataSearch" class="parameter_description">thresholdNoRandomDataSearch</h3>
        <ul class="parameter_description_list">
            <li>Short Description: <span id="thresholdNoRandomDataSearch_short_desc">Yes, if use the cutoff threshold for the constraints independence test (stage 1).</span>
            </li>
            <li>Long Description: <span id="thresholdNoRandomDataSearch_long_desc">null</span></li>
            <li>Default Value: <span id="thresholdNoRandomDataSearch_default_value">false</span></li>
            <li>Lower Bound: <span id="thresholdNoRandomDataSearch_lower_bound"></span></li>
            <li>Upper Bound: <span id="thresholdNoRandomDataSearch_upper_bound"></span></li>
            <li>Value Type: <span id="thresholdNoRandomDataSearch_value_type">Boolean</span></li>
        </ul>

        <h3 id="twoCycleAlpha" class="parameter_description">twoCycleAlpha</h3>
        <ul class="parameter_description_list">
            <li>Short Description: <span id="twoCycleAlpha_short_desc">Alpha orienting 2-cycles (min = 0.0)</span></li>
            <li>Long Description: <span id="twoCycleAlpha_long_desc">The alpha level of a T-test used to determine where 2-cycles exist in the graph. A value of zero turns off 2-cycle detection. </span>
            </li>
            <li>Default Value: <span id="twoCycleAlpha_default_value">0.05</span></li>
            <li>Lower Bound: <span id="twoCycleAlpha_lower_bound">0.0</span></li>
            <li>Upper Bound: <span id="twoCycleAlpha_upper_bound">1.0</span></li>
            <li>Value Type: <span id="twoCycleAlpha_value_type">Double</span></li>
        </ul>

        <h3 id="upperBound" class="parameter_description">upperBound</h3>
        <ul class="parameter_description_list">
            <li>Short Description: <span id="upperBound_short_desc">Upper bound cutoff threshold</span></li>
            <li>Long Description: <span id="upperBound_long_desc">null</span></li>
            <li>Default Value: <span id="upperBound_default_value">0.7</span></li>
            <li>Lower Bound: <span id="upperBound_lower_bound">0.0</span></li>
            <li>Upper Bound: <span id="upperBound_upper_bound">1.0</span></li>
            <li>Value Type: <span id="upperBound_value_type">Double</span></li>
        </ul>

        <h3 id="useCorrDiffAdjacencies" class="parameter_description">useCorrDiffAdjacencies</h3>
        <ul class="parameter_description_list">
            <li>Short Description: <span id="useCorrDiffAdjacencies_short_desc">Yes if adjacencies from conditional correlation differences should be used</span>
            </li>
            <li>Long Description: <span id="useCorrDiffAdjacencies_long_desc">FASK can use adjacencies X—Y where |corr(X,Y|X>0) – corr(X,Y|Y>0)| > threshold. This expression will be nonzero only if there is a path between X and Y; heuristically, if the difference is greater than, say, 0.3, we infer an adjacency. To see adjacencies included for this reason, set this parameter to “Yes”. Sanchez-Romero, Ramsey et al., (2018) Network Neuroscience.</span>
            </li>
            <li>Default Value: <span id="useCorrDiffAdjacencies_default_value">true</span></li>
            <li>Lower Bound: <span id="useCorrDiffAdjacencies_lower_bound"></span></li>
            <li>Upper Bound: <span id="useCorrDiffAdjacencies_upper_bound"></span></li>
            <li>Value Type: <span id="useCorrDiffAdjacencies_value_type">Boolean</span></li>
        </ul>

        <h3 id="useFasAdjacencies" class="parameter_description">useFasAdjacencies</h3>
        <ul class="parameter_description_list">
            <li>Short Description: <span id="useFasAdjacencies_short_desc">Yes if adjacencies from the FAS search (correlation) should be used</span>
            </li>
            <li>Long Description: <span id="useFasAdjacencies_long_desc">Determines whether adjacencies found by conditional correlation should be included in the final model.</span>
            </li>
            <li>Default Value: <span id="useFasAdjacencies_default_value">true</span></li>
            <li>Lower Bound: <span id="useFasAdjacencies_lower_bound"></span></li>
            <li>Upper Bound: <span id="useFasAdjacencies_upper_bound"></span></li>
            <li>Value Type: <span id="useFasAdjacencies_value_type">Boolean</span></li>
        </ul>

        <h3 id="useGap" class="parameter_description">useGap</h3>
        <ul class="parameter_description_list">
            <li>Short Description: <span id="useGap_short_desc">Yes if the GAP algorithms should be used. No if the SAG algorithm should be used</span>
            </li>
            <li>Long Description: <span id="useGap_long_desc">This is a parameter for FOFC (Find One Factor Clusters). There are two procedures implemented for growing pure clusters of variables. In principle they give the same answer, but in practice they could give different answers. The first is GAP, “Grow and Pick”, where you specify all the possible initial sets, grown them all to their maximum sizes, and pick a set of non-overlapping such largest sets from these. The second is SAG, “Seed and Grow”, where you grow pure clusters one at a time, excluding variables found in earlier clusters from showing up in later ones. This parameter specifies which of these algorithms should be used, ‘Yes’ for GAP, ‘No’ for SAG.</span>
            </li>
            <li>Default Value: <span id="useGap_default_value">false</span></li>
            <li>Lower Bound: <span id="useGap_lower_bound"></span></li>
            <li>Upper Bound: <span id="useGap_upper_bound"></span></li>
            <li>Value Type: <span id="useGap_value_type">Boolean</span></li>
        </ul>

        <h3 id="useMaxPOrientationHeuristic" class="parameter_description">useMaxPOrientationHeuristic</h3>
        <ul class="parameter_description_list">
            <li>Short Description: <span id="useMaxPOrientationHeuristic_short_desc">Yes if the heuristic for orienting unshielded colliders for max P should be used</span>
            </li>
            <li>Long Description: <span id="useMaxPOrientationHeuristic_long_desc">
The “Max P” method for orienting an unshielded triple X—Y—Z records p-values for X _||_ Z | S for all S in adj(X) or adj(Z), finds the set S0 with the highest p-value, and orients X->Y<-Z just in case Y is not in S0. Another way to do the orientation if X and Z are only weakly dependent, is to simply see whether the p-value for X _||_ Z | Y is greater than the p-value for X _||_ Z. This is the “heuristic” referred to her; the purpose is to speed up the search.
</span></li>
            <li>Default Value: <span id="useMaxPOrientationHeuristic_default_value">false</span></li>
            <li>Lower Bound: <span id="useMaxPOrientationHeuristic_lower_bound"></span></li>
            <li>Upper Bound: <span id="useMaxPOrientationHeuristic_upper_bound"></span></li>
            <li>Value Type: <span id="useMaxPOrientationHeuristic_value_type">Boolean</span></li>
        </ul>

        <h3 id="useSkewAdjacencies" class="parameter_description">useSkewAdjacencies</h3>
        <ul class="parameter_description_list">
            <li>Short Description: <span id="useSkewAdjacencies_short_desc">Yes if adjacencies based on skewness should be used</span>
            </li>
            <li>Long Description: <span id="useSkewAdjacencies_long_desc">FASK can use adjacencies X—Y where |corr(X,Y|X>0) – corr(X,Y|Y>0)| > threshold. This expression will be nonzero only if there is a path between X and Y; heuristically, if the difference is greater than, say, 0.3, we infer an adjacency. To see adjacencies included for this reason, set this parameter to “Yes”. Sanchez-Romero, Ramsey et al., (2018) Network Neuroscience.</span>
            </li>
            <li>Default Value: <span id="useSkewAdjacencies_default_value">true</span></li>
            <li>Lower Bound: <span id="useSkewAdjacencies_lower_bound"></span></li>
            <li>Upper Bound: <span id="useSkewAdjacencies_upper_bound"></span></li>
            <li>Value Type: <span id="useSkewAdjacencies_value_type">Boolean</span></li>
        </ul>

        <h3 id="useWishart" class="parameter_description">useWishart</h3>
        <ul class="parameter_description_list">
            <li>Short Description: <span id="useWishart_short_desc">Yes if the Wishart test shoud be used. No if the Delta test should be used</span>
            </li>
            <li>Long Description: <span id="useWishart_long_desc">This is a parameter for the FOFC (Find One Factor Clusters) algorithm. There are two tests implemented there for testing for tetrads being zero, Wishart and Delta. This parameter picks which of these tests should be use: ‘Yes’ for Wishart and ‘No’ for Delta.</span>
            </li>
            <li>Default Value: <span id="useWishart_default_value">false</span></li>
            <li>Lower Bound: <span id="useWishart_lower_bound"></span></li>
            <li>Upper Bound: <span id="useWishart_upper_bound"></span></li>
            <li>Value Type: <span id="useWishart_value_type">Boolean</span></li>
        </ul>

        <h3 id="varHigh" class="parameter_description">varHigh</h3>
        <ul class="parameter_description_list">
            <li>Short Description: <span id="varHigh_short_desc">High end of variance range (min = 0.0)</span></li>
            <li>Long Description: <span id="varHigh_long_desc">When simulating data from linear models, one needs to specify the distribution of the variance parameters. Here, we draw coefficients from U(v1, v2); v2 is what is being called the “high end of the variance range” and must be greater than v1. The default value is 3.0.</span>
            </li>
            <li>Default Value: <span id="varHigh_default_value">3.0</span></li>
            <li>Lower Bound: <span id="varHigh_lower_bound">0.0</span></li>
            <li>Upper Bound: <span id="varHigh_upper_bound">1.7976931348623157E308</span></li>
            <li>Value Type: <span id="varHigh_value_type">Double</span></li>
        </ul>

        <h3 id="varLow" class="parameter_description">varLow</h3>
        <ul class="parameter_description_list">
            <li>Short Description: <span id="varLow_short_desc">Low end of variance range (min = 0.0)</span></li>
            <li>Long Description: <span id="varLow_long_desc">When simulating data from linear models, one needs to specify the distribution of the variance parameters. Here, we draw coefficients from U(v1, v2); v1 is what is being called the “low end of the variance range” and has a minimum 0. The default value is 1.0.</span>
            </li>
            <li>Default Value: <span id="varLow_default_value">1.0</span></li>
            <li>Lower Bound: <span id="varLow_lower_bound">0.0</span></li>
            <li>Upper Bound: <span id="varLow_upper_bound">1.7976931348623157E308</span></li>
            <li>Value Type: <span id="varLow_value_type">Double</span></li>
        </ul>

        <h3 id="verbose" class="parameter_description">verbose</h3>
        <ul class="parameter_description_list">
            <li>Short Description: <span
                    id="verbose_short_desc">Yes if verbose output should be printed or logged</span></li>
            <li>Long Description: <span id="verbose_long_desc">If this parameter is set to ‘Yes’, extra (“verbose”) output will be printed if available giving some details about the step-by-step operation of the algorithm.</span>
            </li>
            <li>Default Value: <span id="verbose_default_value">true</span></li>
            <li>Lower Bound: <span id="verbose_lower_bound"></span></li>
            <li>Upper Bound: <span id="verbose_upper_bound"></span></li>
            <li>Value Type: <span id="verbose_value_type">Boolean</span></li>
        </ul>

        <h3 id="include_structure_model" class="parameter_description">verbose</h3>
        <ul class="parameter_description_list">
            <li>Short Description: <span id="include_structure_model_short_desc">Yes if the (MimBuild) stucture model should be included in the output graph</span>
            </li>
            <li>Long Description: <span id="include_structure_model_long_desc">FOFC proper yields a measurement model--that is, a set of pure children for each of the discovered latents. One can estimate the structure over the latents (the structure model) using Mimbuild. This struture model is included in the output if this parameter is set to Yes.</span>
            </li>
            <li>Default Value: <span id="include_structure_model_default_value">true</span></li>
            <li>Lower Bound: <span id="include_structure_model_lower_bound"></span></li>
            <li>Upper Bound: <span id="include_structure_model_upper_bound"></span></li>
            <li>Value Type: <span id="include_structure_model_value_type">Boolean</span></li>
        </ul>

    </div>
    <!-- End of search parameters -->


    <h1 id="regression_box"><span class="section_heading">Regression Box</span></h1>

    <p>The regression box performs regression on variables in a data set, in an attempt to discover causal correlations
        between them.
        Both linear and logistic regression are available.</p>

    <h2>Possible Parent Boxes of the Regression Box</h2>

    <ul class="ul">
        <li>A data box</li>
        <li>A simulation box</li>
    </ul>

    <h2>Possible Child Boxes of the Instantiated Model Box:</h2>

    <ul class="ul">
        <li>A graph box</li>
        <li>A compare box</li>
        <li>A parametric model box</li>
        <li>A data box</li>
        <li>A simulation box</li>
        <li>A search box</li>
    </ul>

    <h2>Multiple Linear Regression</h2>

    <p>Linear regression is performed upon continuous data sets. If you have a categorical data set upon which you would
        like to perform linear regression, you can make it continuous using the data manipulation box.</p>

    <p>Take, for example, a data set with the following underlying causal structure:</p>

    <img src="images/regression_box_1.png" alt="" width="360">

    <p>When used as input to the linear regression box, the following window results: </p>

    <img src="images/regression_box_2.png" alt="" width="650">

    <p>To select a variable as the response variable, click on it in the leftmost box, and then click on the top
        right-pointing arrow. If you change your mind about which variable should be the response variable, simply click
        on another variable and click on the arrow again. </p>

    <p>To select a variable as a predictor variable, click on it in the leftmost box, and then click on the second
        right- pointing arrow. To remove a predictor variable, click on it in the predictor box and then click on the
        left-pointing arrow.</p>

    <p>Clicking “Sort Variables” rearranges the variables in the predictor box so that they follow the same order they
        did in the leftmost box. The alpha value in the lower left corner is a threshold for independence; the higher it
        is set, the less discerning Tetrad is when determining the independence of two variables.</p>

    <p>When we click “Execute,” the results of the regression appear in the box to the right. For each predictor
        variable, Tetrad lists the standard error, t value, and p value, and whether its correlation with the response
        variable is significant. </p>

    <p>The Output Graph tab contains a graphical model of the information contained in the Model tab. For the case in
        which X4 is the response variable and X1, X2, and X3 are the predictors, Tetrad finds that only X1 is
        significant, and the output graph looks like this:</p>

    <img src="images/regression_box_3.png" alt="" width="70">

    <p>Comparison to the true causal model shows that this correlation does exist, but that it runs in the opposite
        direction.</p>

    <h2>Logistic Regression</h2>

    <p>Logistic regression may be run on discrete, continuous, or mixed data sets; however, the response variable must
        be binary. In all other ways, the logistic regression box functions like the linear regression box.</p>


    <h1 id="appendix"><span class="section_heading">Appendix</span></h1>
    <h2>An Introduction to PAGs</h2>
    <p>Peter Spirites</p>

    <p>The output of the FCI algorithm [Spirtes, 2001] is a partial ancestral graph (PAG), which is a graphical object
        that represents a set of causal Bayesian networks (CBNs) that cannot be distinguished by the algorithm. Suppose
        we have a set of cases that were generated by random sampling from some CBN. Under the assumptions that FCI
        makes, in the large sample limit of the number of cases, the PAG returned by FCI is guaranteed to include the
        CBN that generated the data.</p>

    <p>An example of a PAG is shown in Figure 2. This PAG represents the pair of CBNs in Figure 1a and 1b (where
        measured variables are in boxes and unmeasured variables are in ovals), as well as an infinite number of other
        CBNs that may have an arbitrarily large set of unmeasured confounders. Despite the fact that there are important
        differences between the CBNs in Figure 1a and 1b (e.g., there is an unmeasured confounder of X1 and X2 in Figure
        1 b but not in Figure 1a), they share a number of important features in common (e.g., in both CBNs, X2 is a
        direct cause of X6, there is no unmeasured confounder of X2 and X6, and X6 is not a cause of X2). It can be
        shown that every CBN that a PAG represents shares certain features in common. The features that all CBNs
        represented by a PAG share in common can be read off of the output PAG according to the rules described
        next.</p>

    <p>There are 4 kinds of edges that occur in a PAG: A -> B, A o-> B, A o–o B, and A <-> B. The edges indicate what
        the CBNs represented by the PAG have in common. A description of the meaning of each edge in a PAG is given in
        Table A1.
    </p>


    <thead>
    <tr>
        <th>Parameter</th>
        <th>Description</th>
    </tr>
    </thead>

    <tbody>
    <tr>
        <td>Cutoff for p-values (alpha)</td>
        <td>Conditional independence tests with p-values greater than this will be judged to be independent (H0).
            Default 0.01.
        </td>
    </tr>

    <tr>
        <td>Maximum size of conditioning set (depth)</td>
        <td>PC in the adjacency phase will consider conditioning sets for conditional independences of increasing size,
            up to this value. For instance, for depth 3, the maximum size of a conditioning set considered will be 3.
        </td>
    </tr>
    </tbody>

    </table>

    <p>Table A1: Types of edges in a PAG.</p>

    <table class="table">
        <thead>
        <tr>
            <th>Edge type</th>
            <th>Relationships that are present</th>
            <th>Relationships that are absent</th>
        </tr>
        </thead>

        <tbody>

        <tr>
            <td>A --> B</td>
            <td>A is a cause of B. It may be a direct or indirect cause that may include other measured variables. Also,
                there may be an unmeasured confounder of A and B.
            </td>
            <td>B is not a cause of A.</td>
        </tr>
        <tr>
            <td>A <-> B</td>
            <td>There is an unmeasured variable (call it L) that is a cause of A and B. There may be measured variables
                along the causal pathway from L to A or from L to B.
            </td>
            <td>A is not a cause of B. B is not a cause of A.</td>
        </tr>
        <tr>
            <td>A o-> B</td>
            <td>Either A is a cause of B, or there is an unmeasured variable that is a cause of A and B, or both.</td>
            <td>B is not a cause of A.</td>
        </tr>
        <tr>
            <td>A o–o B</td>
            <td>Exactly one of the following holds: (a) A is a cause of B, or (b) B is a cause of A, or (c) there is an
                unmeasured variable that is a cause of A and B, or (d) both a and c, or (e) both b and c.
            </td>
            <td></td>
        </tr>

        </tbody>


        <p>Table A1 is sufficient to understand the basic meaning of edge types in PAGs. Nonetheless, it can be helpful
            to know the following additional perspective on the information encoded by PAGs. Each edge has two
            endpoints, one on the A side, and one on the B side. For example A  B has a tail at the A end, and an
            arrowhead at the B end. Altogether, there are three kinds of edge endpoints: a tail "–", an arrowhead ">",
            and a "o." Note that some kinds of combinations of endpoints never occur; for example, A o– B never occurs.
            As a mnemonic device, the basic meaning of each kind of edge can be derived from three simple rules that
            explain what the meaning of each kind of endpoint is. A tail "–" at the A end of an edge between A and B
            means "A is a cause of B"; an arrowhead ">" at the A end of an edge between A and B means "A is not a cause
            of B"; and a circle "o" at the A end of an edge between A and B means "can't tell whether or not A is a
            cause of B". For example A  B means that A is a cause of B, and that B is not a cause of A in all of the
            CBNs represented by the PAG.</p>
        <p>The PAG in Figure 2 shows examples of each type of edge, and the CBNs Figure 1. show some examples of what
            kinds of CBNs can be represented by that PAG.</p>

        <p>Figure 1. Two CBNs that FCI (as well as FCI+, GFCI, and RFCI) cannot distinguish.</p>

        <p>Figure 2. The PAG that represents the CBNs in both Figures 1a and 1b.</p>


    </table>

</div>

<!-- Google Analytics: change UA-XXXXX-Y to be your site's ID. -->
<script>
window.ga=function(){ga.q.push(arguments)};ga.q=[];ga.l=+new Date;
ga('create','UA-XXXXX-Y','auto');ga('send','pageview')



</script>
<script src="https://www.google-analytics.com/analytics.js" async defer></script>

</body>

</html>
