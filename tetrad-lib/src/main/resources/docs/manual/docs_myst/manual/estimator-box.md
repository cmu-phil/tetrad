(estimator-box)=

# Estimator Box

The estimator box takes as input a data box (or simulation box) and a parametric model box and estimates, tests, and outputs an instantiated model for the data. Except for the EM Bayes estimator, Tetrad estimators do not accept missing values. If your data set contains missing values, the missing values can be interpolated or removed using the data box. (Note that missing values are allowed in various Tetrad search procedures; see the section on the search box.)


## Possible Parent Boxes of the Estimator Box:

- A parametric model box


## Possible Child Boxes of the Estimator Box:

- A graph box
- A simulation box
- An updater box


## ML Bayes Estimations

Bayes nets are acyclic graphical models parameterized by the conditional probability distribution of each variable on its parents' values, as in the instantiated model box. When the model contains no latent variables, the joint distribution of the variables equals the product of the distributions of the variables conditional on their respective parents. The maximum likelihood (ML) estimate of the joint probability distribution under a model is the product of the corresponding frequencies in the sample.

The ML Bayes estimator, because it estimates Bayes IMs, works only on models with discrete variables. The model estimated must not include latent variables, and the input data set must not include missing data values. A sample estimate looks like this:

![](/_static/images/estimator_box_1.png)

The Model tab works exactly as it does in a Bayes instantiated model. The Model Statistics tab provides the p-value for a chi square test of the model, degrees of freedom, the chi square value, and the Bayes Information Criterion (BIC) score of the model. Note that BIC is calculated as 2L -


## Dirichlet Estimations

A Dirichlet estimate estimates a Bayes instantiated model using a Dirichlet distribution for each category. In a Dirichlet estimate, the probability of each value of a variable (conditional on the values of the variable’s parents) is estimated by adding together a prior pseudo count (which is 1, by default, of cases and the number of cases in which the variable takes that value in the data, and then dividing by the total number of cases in the pseudocounts and in the data with that configuration of values of parent variables. The default prior pseudo-count can be changed inside the box. (For a full explanation of pseudocounts and Dirichlet estimate, see the section on Dirichlet instantiated models.)

The Dirichlet estimator in TETRAD does not work if the input data set contains missing data values.


## EM Bayes Estimations

The EM Bayes estimator takes the same input and gives the same output as the ML Bayes estimator, but is designed to handle data sets with missing data values, and input models with latent variables.


## SEM Estimates

A SEM estimator estimates the values of parameters for a SEM parametric model. SEM estimates do not work if the input data set contains missing data values. A sample output looks like this:

![](/_static/images/estimator_box_2.png)

Tetrad provides five parameter optimizers: RICF,( Drton, M., & Richardson, T. S. (2004, July). Iterative conditional fitting for Gaussian ancestral graph models. In Proceedings of the 20th conference on Uncertainty in artificial intelligence (pp. 130-137). AUAI Press). expectation­-maximization (EM), regression, Powell Journal of Econometrics 25 (1984) 303-325) and random search. Accurate regression estimates assume that the input parametric model is a DAG, and that its associated statistics are based on a linear, Gaussian model. The EM optimizer has the same input constraints as regression, but can handle latent variables.

Tetrad also provides two scores that can be used in estimation: feasible generalized the least squares (FGLS) and Full Information Maximum Likelihood (FML).

If the graph for the SEM is a DAG, and we may assume that the SEM is linear with Gaussian error terms, we use multilinear regression to estimate coefficients and residual variances. Otherwise, we use a standard maximum likelihood fitting function (see Bollen, Structural Equations with Latent Variables, Wiley, 1989, pg. 107) to minimize the distance between (a) the covariance over the variables as implied by the coefficient and error covariance parameter values of the model and (b) the sample covariance matrix. Following Bollen, we denote this function Fml; it maps points in parameter values space to real numbers, and, when minimized, yields the maximum likelihood estimation point in parameter space.

In either case, a Fml value may be obtained for the maximum likelihood point in parameter space, either by regression or by direct minimization of the Fml function itself. The value of Fml at this minimum (maximum likelihood) point, multiplied by N - 1 (where N is the sample size), yields a chi square statistics (ch^2) for the model, which when referred to the chi square table with appropriate degrees of freedom, yields a model p value. The degrees of freedom (dof) in this case is equal to the m(m-1)/2 - f, where m is the number of measured variables, and f is the number of free parameters, equal to the number of coefficient parameters plus the number of covariance parameters. (Note that the degrees of freedom many be negative, in which case estimation should not be done.) The BIC score is calculated as ch^2 - dof * log(N), so "higher is better.".

You can change which score optimizer Tetrad uses by choosing them from the drop-down menus at the bottom of the window and clicking “Estimate Again.”

The Tabular Editor and Implied Matrices tabs function exactly as they do in the instantiated model box, but in the estimator box, the last three columns of the table in the Tabular Editor tab are filled in. The SE, T, and P columns provide the standard errors, t statistics, and p values of the estimation.

The Model Statistics tab provides the degrees of freedom, chi square, p value, comparative fit index (CFI), root-mean-square error of approximation (RMSEA) and BIC score of a test of the model. It should be noted that while these test statistics are standard, they are not in general correct. See Mathias Drton, 2009, Likelihood ratio tests and singularities. Annals of Statistics 37(2):979-1012. arXiv:math.ST/0703360. Note also that BIC is calculated as 2L - k ln N, so "higher is better."

When the EM algorithm is used with latent variable models, we recommend multiple random restarts. The number of restarts can be set in the lower right hand corner of the Estimator Box. Generalized Estimator A generalized graphical model may have non-linear relations and non-Gaussian distributions. These models are automatically estimated by the Powell method, which seeks a maximum likelihood solution. Updater Box The updater box takes an instantiated model as input, and, given information about the values of parameters in that model, updates the information about the values and relationships of other parameters. The Updater allows the user to specify values of variables as “Evidence.” The default is that the conditional probabilities (Bayes net models; categorical variables) or conditional means (SEM models; continuous variables) are computed. For any variable for which evidence is specified, the user can click on “Manipulated,” in which case the Updater will calculate the conditional probabilities or conditional means for other variables when the evidence variables are forced to have their specified values. In manipulated calculations, all connections into a measured variable are discarded, the manipulated variables are treated as independent of their causes in the graph, and probabilities for variables that are causes of the manipulated variables are unchanged. There are four available updater algorithms in Tetrad: the approximate updater, the row summing exact updater, and the Junction Tree Updater, and the SEM updater. All except for the SEM updater function only when given Bayes instantiated models as input; the SEM updater functions when given a SEM instantiated model as input. None of the updaters work on cyclic models. Possible Parent Boxes of the Updater Box: An instantiated model box An estimator box Possible Child Boxes of the Updater Box: An instantiated model box (Note that the instantiated model will have the updated parameters) Approximate Updater The approximated updater is a fast but inexact algorithm. It randomly draws a sample data set from the instantiated model and calculates the conditional frequency of the variable to be estimated. Take, for example, the following instantiated model: When it is input into the approximate updater, the following window results: If we click “Do Update Now” now, without giving the updater any evidence, the right side of the screen changes to show us the marginal probabilities of the variables. The blue lines, and the values listed across from them, indicate the probability that the variable takes on the given value in the input instantiated model. The red lines indicate the probability that the variable takes on the given value, given the evidence we’ve added to the updater. Since we have added no evidence to the updater, the red and blue lines are very similar in length. To view the marginal probabilities for a variable, either click on the variable in the graph to the left, or choose it from the scrolling menu at the top of the window. At the moment, they should all be very close to the marginal probabilities taken from the instantiated model. Now, we’ll return to the original window. We can do so by clicking “Edit Evidence” under the Evidence tab. Suppose we know that X1 takes on the value 1 in our model, or suppose we merely want to see how X1 taking that value affects the values of the other variables. We can click on the box that says “1” next to X1. When we click “Do Update Now,” we again get a list of the marginal probabilities for X1. Now that we have added evidence, the “red line” marginal probabilities have changed; for X1, the probability that X1=1 is 1, because we’ve told Tetrad that that is the case. Likewise, the probabilities that X1=0 and X1=2 are both 0. Now, let’s look at the updated marginal probabilities for X2, a parent of X1. The first image is the marginal probabilities before we added the evidence that X1=1. The second image is the updated marginal probabilities. They have changed; in particular, it has become much more likely that X2=0. Under the Mode tab, we can change the type of information that the updater box gives us. The mode we have been using so far is “Marginals Only (Multiple Variables).” We can switch the mode to “In-Depth Information (Single Variable).” Under this mode, when we perform the update, we receive more information (such as log odds and joints, when supported; joint probabilities are not supported by the approximate updater), but only about the variable which was selected in the graph when we performed the update. To view information about a different variable, we must re-edit the evidence with that variable selected. If the variable can take one of several values, or if we know the values of more than one variable, we can select multiple values by pressing and holding the Shift key and then making our selections. For instance, in the model above, suppose that we know that X1 can be 1 or 2, but not 0. We can hold the Shift key and select the boxes for 1 and 2, and when we click “Do Update Now,” the marginal probabilities for X2 look like this: Since X1 must be 1 or 2, the updated probability that it is 0 is now 0. The marginal probabilities of X2 also change: The updated marginal probabilities are much closer to their original values than they were when we knew that X1 was 1. Finally, if we are arbitrarily setting the value of a variable—that is, the values of its parents have no effect on its value—we can check the “Manipulated” box next to it while we are we editing evidence, and the update will reflect this information. Note that multiple values cannot be selected for evidence for SEM models. Row Summing Exact Updater The row summing exact updater is a slower but more accurate updater than the approximate updater. The complexity of the algorithm depends on the number of variables and the number of categories each variable has. It creates a full exact conditional probability table and updates from that. Its window functions exactly as the approximate updater does, with two exceptions: in “Multiple Variables” mode, you can see conditional as well as marginal probabilities, and in “Single Variable” mode, you can see joint values. Junction Tree Exact Updater The Junction Tree exact updater is another exact learning algorithm. Its window functions exactly as the approximate updater down, with one exception: in “Multiple Variables” mode, you can see conditional as well as marginal probabilities. SEM Updater The SEM updater does not deal with marginal probabilities; instead, it estimates means. When it is input to the SEM updater, the following window results: Suppose we know that the mean of X1 is .5. When we enter that value into the text box on the left and click “Do Update Now,” the model on the right updates to reflect that mean, changing the means of both X1 and several other variables. In the new model, the means of X2, X4, and X5 will all have changed. If we click the “Manipulated” check box as well, it means that we have arbitrarily set the mean of X1 to .5, and that the value of its parent variable, X4, has no effect on it. The graph, as well as the updated means, changes to reflect this. The rest of the window has the same functionality as a SEM instantiated model window, except as noted above. Knowledge Box The knowledge box takes as input a graph or a data set and imposes additional constraints onto it, to aid with search. Possible Parent Boxes of the Knowledge Box: A graph box A parametric model box An instantiated model box A data box A simulation box A search box Another knowledge box Possible Child Boxes of the Knowledge Box: A search box Another knowledge box Tiers and Edges The tiers and edges option allows you to sort variables into groupings that can or cannot affect each other. It also allows you to manually add forbidden and required edges one at a time. Tiers The tiers tab for a graph with ten variables looks like this: Tiers separate your variables into a timeline. Variables in higher-numbered tiers occur later than variables in lower-numbered tiers, which gives Tetrad information about causation. For example, a variable in Tier 3 could not possibly be a cause of a variable in Tier 1. To place a variable in a tier, click on the variable in the “Not in tier” box, and then click on the box of the tier. If you check the “Forbid Within Tier” box for a tier, variables in that tier will not be allowed to be causes of each other. To increase or decrease the number of tiers, use the scrolling box in the upper right corner of the window. You can quickly search, select and place variables in a tier using the Find button associated with each tier. Enter a search string into the Find dialogue box using asterisks as wildcard indicators. E.g., "X1*" would find and select variables X1 and X10. You can also limit the search such that edges from one tier only are added to the next immediate tier e.g., if Tier 1 "Can cause only next tier" is checked then edges from variables in Tier 1 to variables in Tier 3 are forbidden. Handling of Interventional Variables in Tiers If you have annotated your variables with interventional status and interventional value tags using a metadata JSON file (see Data Box section) the Tiers and Edges panel will automatically place these variables in Tier 1. If you have information about the effects of the intervention variables you can use the groups tab to indicate this. Groups The groups tab for a graph with four variables looks like this: In the groups tab, you can specify certain groups of variables which are forbidden or required to cause other groups of variables. To add a variable to the “cause” section of a group, click on the variable in the box at the top, and then click on the box to the left of the group’s arrow. To add a variable to the “effect” section of a group, click on the variable in the box at the top, and then click on the box to the right of the group’s arrow. You can add a group by clicking on one of the buttons at the top of the window, and remove one by clicking the “remove” button above the group’s boxes. Edges The edges tab for a graph with four variables looks like this: In the edges tab, you can require or forbid individual causal edges between variables. To add an edge, click the type of edge you’d like to create, and then click and drag from the “cause” variable to the “effect” variable. You can also use this tab to see the effects of the knowledge you created in the other tabs by checking and unchecking the boxes at the bottom of the window. You can adjust the layout to mimic the layout of the source (by clicking “source layout”) or to see the variables in their timeline tiers (by clicking “knowledge layout”). Forbidden Graph If you use a graph as input to a knowledge box with the “Forbidden Graph” operation, the box will immediately add all edges in the parent graph as forbidden edges. It will otherwise work like a Tiers and Edges box. Required Graph If you use a graph as input to a knowledge box with the “Required Graph” operation, the box will immediately add all edges in the parent graph as required edges. It will otherwise work like a Tiers and Edges box. Measurement Model This option allows you to build clusters for a measurement model. When first opened, the window looks like this: You can change the number of clusters using the text box in the upper right hand corner. To place a variable in a cluster, click and drag the box with its name into the cluster pane. To move multiple variables at once, shift- or command-click on the variables, and (without releasing the shift/command button or the mouse after the final click) drag. In the search boxes, these variables will be assumed to be children of a common latent cause. Simulation Box The simulation box takes a graph, parametric model, or instantiated model and uses it to simulate a data set. Possible Parent Boxes of the Simulation Box A graph box A parametric model box An instantiated model box An estimator box A data box Another simulation box A search box An updater box A regression box Possible Child Boxes of the Simulation Box A graph box A compare box A parametric model box An instantiated model box An estimator box A data box Another simulation box A search box A classify box A regression box A knowledge box Using the Simulator Box When you first open the simulation box, you will see some variation on this window: The “True Graph” tab contains the graph from which data is simulated. The Simulation Box with no Input Because it has no input box to create constraints, a parentless simulation box offers the greatest freedom for setting the graph type, model type, and parameters of your simulated data. In particular, it is the only way that the simulation box will allow you to create a random graph or graphs within the box. (If you are simulating multiple data sets, and want to use a different random graph for each one, you can select “Yes” under “Yes if a different graph should be used for each run.”) You can choose the type of graph you want Tetrad to create from the “Type of Graph” drop-down list. Random Forward DAG This option creates a DAG by randomly adding forward edges (edges that do not point to a variable’s ancestors) one at a time. You can specify graph parameters such as number of variables, maximum and minimum degrees, and connectedness. Erdos Renyi DAG This option creates a DAG by randomly adding edges with a given edge probability. The graph is then oriented as a DAG by choosing a causal order. Scale Free DAG This option creates a DAG whose variable’s degrees obey a power law. You can specify graph parameters such as number of variables, alpha, beta, and delta values. Cyclic, constructed from small loops This option creates a cyclic graph. You can specify graph parameters such as number of variables, maximum and average degrees, and the probability of the graph containing at least one cycle. It is very important when dealing with cyclic models to realize that the potential exists always to instantiate these models with coefficients that are too large. Always, to keep simulations from "exploding" ("diverging"--i.e., having simulation values that tend to infinity over time), it is necessary to make sure that coefficient values are relatively small, usually less than 1. One can tell whether a model will produce simulations that diverge in value by testing the eigenvalues of the covariance matrix of the data. If any of these eigenvalues are greater than 1, the potential exists for the simulation to "explode" toward infinity over time. Random One Factor MIM This option creates a one-factor multiple indicator model. You can specify graph parameters such as number of latent nodes, number of measurements per latent, and number of impure edges. Random Two Factor MIM This option creates a two-factor multiple indicator model. You can specify graph parameters such as number of latent nodes, number of measurements per latent, and number of impure edges. In addition to the graph type, you can also specify the type of model you would like Tetrad to simulate. Bayes net Simulates a Bayes instantiated model. You can specify model parameters including maximum and minimum number of categories for each variable. Structural Equation Model Simulates a SEM instantiated model. You can specify model parameters including coefficient, variance, and covariance ranges. Linear Fisher Model Simulates data using a linear Markov 1 DBN without concurrent edges. The Fisher model suggests that shocks should be applied at intervals and the time series be allowed to move to convergence between shocks. This simulation has many parameters that can be adjusted, as indicated in the interface. The ones that require some explanation are as follows. Low end of coefficient range, high end of coefficient range, low end of variance range, high end of variance range. Each variable is a linear function of the parents of the variable (in the previous time lag) plus Gaussian noise. The coefficients are drawn randomly from U(a, b) where a is the low end of the coefficient range and b is the high end of the coefficient range. Here, a < b. The Gaussian noise is drawn uniformly from U(c, d), where c is the low end of the variance range and d is the high end of the variance range. Here, c < d. Yes, if negative values should be considered. If no, only positive values will be recorded. This should not be used for large numbers of variables, since it is more difficult to find cases with all positive values when the number of variables is large. Percentage of discrete variables. The model generates continuous data, but some or all of the variables may be discretized at random. The user needs to indicate the percentage of variables (randomly chosen that one wishes to have discretized. The default is zero—i.e., all continuous variables. Number of categories of discrete variables. For the variables that are discretized, the number of categories to use to discretize each of these variables. Sample size. The number of records to be simulated. Interval between shocks. The number of time steps between shocks in the model. Interval between data recordings. The data are recorded every so many steps. If one wishes to allow to completely converge between steps (i.e., produce equilibrium data), set this interval to some large number like 20 and set the interval between shocks likewise to 20 Other values can be used, however. Epsilon for convergence. Even if you set the interval between data recordings to a large number, you can specify an epsilon such that if all values of variables differ from their values one time step back by less than epsilon, the series will be taken to have converged, and the remaining steps between data recordings will be skipped, the data point being recorded at convergence. Lee & Hastie This is a model for simulating mixed data (data with both continuous and discrete variables. The model is given in Lee J, Hastie T. 2013, Structure Learning of Mixed Graphical Models, Journal of Machine Learning Research 31: 388-396. Here, mixtures of continuous and discrete variables are treated as log-linear. Percentage of discrete variables. The model generates continuous data, but some or all of the variables may be discretized at random. The user needs to indicate the percentage of variables (randomly chosen that one wishes to have discretized. The default is zero—i.e., all continuous variables. Number of categories of discrete variables. For the variables that are discretized, the number of categories to use to discretize each of these variables. Sample size. The number of records to be simulated. Time Series This is a special simulation for representing time series. Concurrent edges are allowed. This can take a Time Series Graph as input, in which variables in the current lag are written as functions of the parents in the current and previous lags. Sample size. The number of records to be simulated. Functional–Causal Simulator (Zhang 2015) Generates data from an additive, potentially nonlinear functional-causal model (Zhang 2015). Each variable Xi is produced as Xi := fi(PAi) + Ui, where Ui are mutually independent noise terms. GUI: Simulate ▸ Functional-Causal CLI: -sim-func -n {samples} -dag {graphSpec} Outputs: continuous data set; ground-truth DAG. Additive-Noise Simulator (Peters 2014) Implements the linear/non-linear additive-noise model used by Peters et al., 2014. Noise variance is user-selectable; functions are sampled from Gaussian processes. Post-Non-Linear Simulator (Zhang & Hyvärinen 2009) Samples data from the PNL causal model X := g(f(PA) + U), covering non-monotone g when required. Causal-Perceptron Network (DJI) Experimental simulator for deep causal generative networks (Dji internal research). Currently marked “beta”. The Simulation Box with a Graph Input If you input a graph, you will be able to simulate any kind of model, with any parameters. But the model will be constrained by the graph you have input (or the subgraph you choose in the “True Graph” tab.) Because of this, if you create a simulation box with a graph as a parent, you will not see the “Type of Graph” option. The Simulation Box with a Parametric Model Input At the time of writing, a simulation box with a parametric model input acts as though the PM’s underlying graph had been input into the box. The Simulation Box with an Instantiated Model Input If you input an instantiated model, your only options will be the sample size of your simulation and the number of data sets you want to simulate; Tetrad will simulate every one of them based on the parameters of the IM. The model will not be re-parameterized for each run of the simulation. Search Box The search box takes as input a data set (in either a data or simulation box) and optionally a knowledge box, and searches for causal explanations represented by directed graphs. The result of a search is not necessarily—and not usually—a unique graph, but an object such as a CPDAG that represents a set of graphs, usually a Markov Equivalence class. More alternatives can be found by varying the parameters of search algorithms. Possible Parent Boxes of the Search Box A graph box A parametric model box An instantiated model box An estimator box A data box A simulation box Another search box A regression box A knowledge box Possible Child Boxes of the Simulation Box A graph box A compare box A parametric model box A simulation box Another search box A knowledge box Using the Search Box For more information that in included about the search algorithms than is included in the text below, please see our Javadocs for the Search package. Using the search box requires you to select an algorithm (optionally select a test/score), confirm/change search parameters and finally run the search. The search box first asks what algorithm, statistical tests and/or scoring functions you would like to use in the search. The upper left panel allows you to filter for different types of search algorithms with the results of filtering appearing in the middle panel. Selecting a particular algorithm will update the algorithm description on the right panel. Choosing the correct algorithm for your needs is an important consideration. Tetrad provides over 30 search algorithms (and more are added all the time) each of which makes different assumptions about the input data, uses different parameters, and produces different kinds of output. For instance, some algorithms produce Markov blankets or CPDAGs, and some produce full graphs; some algorithms work best with Gaussian or non-Gaussian data; some algorithms require an alpha value, some require a penalty discount, and some require both or neither. You can narrow down the list using the “Algorithm filter" panel, which allows you to limit the provided algorithms according to whichever factor is important to you. Depending on the datatype used as input for the search (i.e., continuous, discrete, or mixed data) and algorithm selected, the lower left panel will display available statistical tests (i.e., tests of independence) and Bayesian scoring functions. After selecting the algorithm and desired test/score, click on "Set parameters" which will allow you to confirm/change the parameters of the search. After optionally changing any search parameters, click on "Run Search and Generate Graph" which will execute the search. Notably there are some experimental algorithms available in this box. To see these, select File->Settings->Enable Experimental. Regression Box The regression box performs regression on variables in a data set, in an attempt to discover causal correlations between them. Both linear and regression are available. Possible Parent Boxes of the Regression Box A data box A simulation box Possible Child Boxes of the Instantiated Model Box: A graph box A compare box A parametric model box A data box A simulation box A search box Multiple Linear Regression Linear regression is performed upon continuous data sets. If you have a categorical data set upon which you would like to perform linear regression, you can make it continuous using the data manipulation box. Take, for example, a data set with the following underlying causal structure: When used as input to the linear regression box, the following window results: To select a variable as the response variable, click on it in the leftmost box, and then click on the top right-pointing arrow. If you change your mind about which variable should be the response variable, simply click on another variable and click on the arrow again. To select a variable as a predictor variable, click on it in the leftmost box, and then click on the second right-pointing arrow. To remove a predictor variable, click on it in the predictor box and then click on the left-pointing arrow. Clicking “Sort Variables” rearranges the variables in the predictor box so that they follow the same order they did in the leftmost box. The alpha value in the lower left corner is a threshold for independence; the higher it is set, the less discerning Tetrad is when determining the independence of two variables. When we click “Execute,” the results of the regression appear in the box to the right. For each predictor variable, Tetrad lists the standard error, t value, and p value, and whether its correlation with the response variable is significant. The Output Graph tab contains a graphical model of the information contained in the Model tab. For the case in which X4 is the response variable and X1, X2, and X3 are the predictors, Tetrad finds that only X1 is significant, and the output graph looks like this: Comparison to the true causal model shows that this correlation does exist, but that it runs in the opposite direction. Logistic Regression Logistic regression may be run on discrete, continuous, or mixed data sets; however, the response variable must be binary. In all other ways, the logistic regression box functions like the linear regression box. Appendices An Introduction to PAGs Peter Spirtes The output of the FCI algorithm [Spirtes, 2001] is a partial ancestral graph (PAG), which is a graphical object that represents a set of causal Bayesian networks (CBNs) that cannot be distinguished by the algorithm. Suppose we have a set of cases that were generated by random sampling from some CBN. Under the assumptions that FCI makes, in the large sample limit of the number of cases, the PAG returned by FCI is guaranteed to include the CBN that generated the data. An example of a PAG is shown in Figure 2. This PAG represents the pair of CBNs in Figure 1a and 1b (where measured variables are in boxes and unmeasured variables are in ovals), as well as an infinite number of other CBNs that may have an arbitrarily large set of unmeasured confounders. Despite the fact that there are important differences between the CBNs in Figure 1a and 1b (e.g., there is an unmeasured confounder of X1 and X2 in Figure 1 b but not in Figure 1a), they share a number of important features in common (e.g., in both CBNs, X2 is a direct cause of X6, there is no unmeasured confounder of X2 and X6, and X6 is not a cause of X2). It can be shown that every CBN that a PAG represents shares certain features in common. The features that all CBNs represented by a PAG share in common can be read off of the output PAG according to the rules described next. There are 4 kinds of edges that occur in a PAG: A -> B, A o-> B, A o–o B, and A <-> B. The edges indicate what the CBNs represented by the PAG have in common. A description of the meaning of each edge in a PAG is given in Table A1. Table A1: Types of edges in a PAG. Edge type Relationships that are present Relationships that are absent A --> B A is a cause of B. It may be a direct or indirect because that may include other measured variables. Also, there may be an unmeasured confounder of A and B. B is not a cause of A. A <-> B There is an unmeasured variable (call it L) that is a cause of A and B. There may be measured variables along the causal pathway from L to A or from L to B. A is not a cause of B. B is not a cause of A. A o-> B Either A is a cause of B, or there is an unmeasured variable that is a cause of A and B, or both. B is not a cause of A. A o–o B Exactly one of the following holds: (a) A is a cause of B, or (b) B is a cause of A, or (c) there is an unmeasured variable that is a cause of A and B, or (d) both a and c, or (e) both b and c. Table A1 is sufficient to understand the basic meaning of edge types in PAGs. Nonetheless, it can be helpful to know the following additional perspective on the information encoded by PAGs. Each edge has two endpoints, one on the A side, and one on the B side. For example A --> B has a tail at the A end, and an arrowhead at the B end. Altogether, there are three kinds of edge endpoints: a tail "–", an arrowhead ">", and a "o." Note that some kinds of combinations of endpoints never occur; for example, A o– B never occurs. As a mnemonic device, the basic meaning of each kind of edge can be derived from three simple rules that explain what the meaning of each kind of endpoint is. A tail "–" at the A end of an edge between A and B means "A is a cause of B"; an arrowhead ">" at the A end of an edge between A and B means "A is not a cause of B"; and a circle "o" at the A end of an edge between A and B means "can't tell whether A is a cause of B". For example A --> B means that A is a cause of B, and that B is not a cause of A in all the CBNs represented by the PAG. The PAG in Figure 2 shows examples of each type of edge, and the CBNs. Figure 1. show some examples of what kinds of CBNs can be represented by that PAG. Figure 1. Two CBNs that FCI (as well as FCI+, GFCI, and RFCI) cannot distinguish. Figure 2. The PAG that represents the CBN s in both Figures 1a and 1b. Arc Specializations in PAGs This section describes two types of edge specializations that provide additional information about the nature of an arc in a PAG. One edge specialization is colored green and is called definitely visible. In a PAG P without selection bias, a green (definitely visible) arc from A to B denotes that A and B do not have a latent confounder. If an arc is not definitely visible (represented as black) then A and B may have a latent confounder. Another edge specialization is shown as bold and is called definitely direct. In a PAG P without selection bias, a bold (definitely direct) arc from A to B denotes that A is a direct cause of B, relative to the other measured variables. If an arc is not definitely direct (represented as not bolded) then A may not be a direct cause of B, in which case there may be one or more measured variables on every causal path from A to B. In the following examples, the DAG representing a causal process is on the left, and the corresponding PAG is on the right. All variables are observed except for latent variable L. Example of an edge C ➔ D that is definitely visible (green) and definitely direct (bold): Example of an edge (C ➔ E) that is definitely visible (green) and not definitely direct (not bold): Example of an edge (F ➔ E) that is not definitely visible (black) and not definitely direct (not bold): It is conjectured that it is not possible for an edge to be definitely direct (bold) and not definitely visible (black). Solving Out of Memory Errors By default, Java will allocate the smaller option of 1/4 system memory or 1GB to the Java virtual machine (JVM). If you run out of memory (heap memory space) running your analyses you should increase the memory allocated to the JVM with the following switch '-XmxXXG' where XX is the number of gigabytes of ram you allow the JVM to utilize. To run Tetrad with more memory you need to start it from the command line or terminal. For example to allocate 8 gigabytes of ram you would add -Xmx8G immediately after the java command e.g., java -Xmx8G -jar tetrad-gui.jar. Glossary of Terms Adjacent Two vertices in a graph are adjacent if there is a directed, or undirected, or double-headed edge between them. Degree The total number of edges directed both into and out of a vertex. Indegree The number of edges directed into a vertex. Markov Blanket In a variable set V, with joint probability Pr, the Markov Blanket of a variable X in V is the smallest subset M of V \ {X} such that X II V \ M | M. In a DAG model, the Markov Blanket of X is the union of the set of direct causes (parents) of X, the set of direct effects (children) of X, and the set of direct causes of direct effects of X. Markov Equivalent Graphs Two directed acyclic graphs (DAGS) are Markov Equivalent if they have the same adjacencies and for every triple X – Y – Z of adjacent vertices, if X and Z are not adjacent, X -> Y <- Z in both graphs or in neither graph. Meek Orientation Rules Rules for finding all directions of edges implied by a CPDAG, consistent with any specified “knowledge” constraints on directions. See https://arxiv.org/pdf/1302. 4972.pdf Mixed Ancestral Graph (MAG) An acyclic graph with directed and undirected edges. Directed edges have the same interpretation as in DAGs. Undirected edges represent common causes. See Richardson, T. (2003). Markov properties for acyclic directed mixed graphs. Scandinavian Journal of Statistics, 30(1), 145-157. Multiple Indicator Model A graphical model in which unmeasured variables each have multiple measured effects. There may be directed edges between unmeasured variables, but no directed edges from measured variables to unmeasured variables are allowed. Outdegree The number of edges directed out of a vertex. Partial Ancestral Graph (PAG) See PAG description in this manual. CPDAG A graphical representation of a Markov Equivalence Class or Classes, having both directed and undirected edges, with an undirected edge indicating that for each possible direction of the edge, there is a graph in the class or classes having that edge direction. Scale Free Graph A network in which the frequency of nodes with degree k obeys a power law--the relation between log of degree and log of frequency is roughly linear. See https://cs.brynmawr.edu/Courses/cs380/ spring2013/section02/slides/10_ScaleFreeNetworks.pdf. Trek A trek between X and Y is a directed path from X to Y or from Y to X, or two directed paths from a third variable Z into X and Y that do not intersect except at Z.
